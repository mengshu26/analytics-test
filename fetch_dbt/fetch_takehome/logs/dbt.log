2021-05-12 00:46:15.059955 (MainThread): Running with dbt=0.19.1
2021-05-12 00:46:15.175936 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, defer=None, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['brands'], partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', selector_name=None, show=False, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2021-05-12 00:46:15.177637 (MainThread): Tracking: tracking
2021-05-12 00:46:15.202531 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a68eeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6a8670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6a8eb0>]}
2021-05-12 00:46:15.220911 (MainThread): Partial parsing not enabled
2021-05-12 00:46:15.222642 (MainThread): Parsing macros/catalog.sql
2021-05-12 00:46:15.228859 (MainThread): Parsing macros/relations.sql
2021-05-12 00:46:15.231469 (MainThread): Parsing macros/adapters.sql
2021-05-12 00:46:15.263326 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 00:46:15.268474 (MainThread): Parsing macros/core.sql
2021-05-12 00:46:15.274874 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 00:46:15.289504 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 00:46:15.292373 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 00:46:15.321317 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 00:46:15.370621 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 00:46:15.402935 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 00:46:15.406012 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 00:46:15.415325 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 00:46:15.436951 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 00:46:15.448351 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 00:46:15.457789 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 00:46:15.465546 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 00:46:15.467146 (MainThread): Parsing macros/etc/query.sql
2021-05-12 00:46:15.468807 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 00:46:15.471240 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 00:46:15.486655 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 00:46:15.489615 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 00:46:15.492224 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 00:46:15.556502 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 00:46:15.560932 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 00:46:15.563235 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 00:46:15.565657 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 00:46:15.576372 (MainThread): Partial parsing not enabled
2021-05-12 00:46:15.661108 (MainThread): Acquiring new postgres connection "model.fetch_takehome.my_first_dbt_model".
2021-05-12 00:46:15.681976 (MainThread): Acquiring new postgres connection "model.fetch_takehome.my_second_dbt_model".
2021-05-12 00:46:15.806084 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a57e0920-5f0b-4a74-b9c1-86d2f975d39c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a87e8e0>]}
2021-05-12 00:46:15.812995 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a57e0920-5f0b-4a74-b9c1-86d2f975d39c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a862520>]}
2021-05-12 00:46:15.813335 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 00:46:15.813789 (MainThread): The selector 'brands' does not match any nodes and will be ignored
2021-05-12 00:46:15.814239 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-05-12 00:46:15.814511 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a869e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7f8b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7f8370>]}
2021-05-12 00:46:15.814733 (MainThread): Flushing usage events
2021-05-12 00:46:15.942862 (MainThread): Connection 'model.fetch_takehome.my_second_dbt_model' was properly closed.
2021-05-12 00:46:30.024812 (MainThread): Running with dbt=0.19.1
2021-05-12 00:46:30.136968 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, defer=None, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['brands.txt'], partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', selector_name=None, show=False, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2021-05-12 00:46:30.138002 (MainThread): Tracking: tracking
2021-05-12 00:46:30.157273 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e78fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7b56a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7b5ee0>]}
2021-05-12 00:46:30.179505 (MainThread): Partial parsing not enabled
2021-05-12 00:46:30.180877 (MainThread): Parsing macros/catalog.sql
2021-05-12 00:46:30.185524 (MainThread): Parsing macros/relations.sql
2021-05-12 00:46:30.187890 (MainThread): Parsing macros/adapters.sql
2021-05-12 00:46:30.224560 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 00:46:30.229137 (MainThread): Parsing macros/core.sql
2021-05-12 00:46:30.235920 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 00:46:30.254302 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 00:46:30.258572 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 00:46:30.293756 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 00:46:30.352513 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 00:46:30.388847 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 00:46:30.392496 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 00:46:30.403751 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 00:46:30.426363 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 00:46:30.439454 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 00:46:30.449678 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 00:46:30.460511 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 00:46:30.462848 (MainThread): Parsing macros/etc/query.sql
2021-05-12 00:46:30.465421 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 00:46:30.469951 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 00:46:30.493030 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 00:46:30.496890 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 00:46:30.500272 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 00:46:30.576195 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 00:46:30.579786 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 00:46:30.582248 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 00:46:30.585624 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 00:46:30.599475 (MainThread): Partial parsing not enabled
2021-05-12 00:46:30.673494 (MainThread): Acquiring new postgres connection "model.fetch_takehome.my_first_dbt_model".
2021-05-12 00:46:30.691182 (MainThread): Acquiring new postgres connection "model.fetch_takehome.my_second_dbt_model".
2021-05-12 00:46:30.806402 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26382c19-654d-4f00-bb6e-10a134ed6fec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e98c910>]}
2021-05-12 00:46:30.813153 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26382c19-654d-4f00-bb6e-10a134ed6fec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e970550>]}
2021-05-12 00:46:30.813595 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 00:46:30.814274 (MainThread): The selector 'brands.txt' does not match any nodes and will be ignored
2021-05-12 00:46:30.815035 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2021-05-12 00:46:30.815410 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e976310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9059a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9053a0>]}
2021-05-12 00:46:30.815800 (MainThread): Flushing usage events
2021-05-12 00:46:30.951326 (MainThread): Connection 'model.fetch_takehome.my_second_dbt_model' was properly closed.
2021-05-12 17:02:20.636914 (MainThread): Running with dbt=0.19.1
2021-05-12 17:02:20.757644 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:02:20.759335 (MainThread): Tracking: tracking
2021-05-12 17:02:20.785252 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113481d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a75e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a7e20>]}
2021-05-12 17:02:20.800129 (MainThread): Partial parsing not enabled
2021-05-12 17:02:20.801608 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:02:20.806353 (MainThread): Parsing macros/relations.sql
2021-05-12 17:02:20.808560 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:02:20.833119 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:02:20.837482 (MainThread): Parsing macros/core.sql
2021-05-12 17:02:20.842344 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:02:20.852740 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:02:20.855009 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:02:20.878053 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:02:20.914867 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:02:20.936908 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:02:20.939015 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:02:20.945619 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:02:20.960373 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:02:20.967892 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:02:20.975335 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:02:20.981201 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:02:20.982475 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:02:20.983774 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:02:20.985656 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:02:20.994922 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:02:20.997162 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:02:20.999080 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:02:21.042990 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:02:21.045154 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:02:21.047045 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:02:21.049067 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:02:21.056694 (MainThread): Partial parsing not enabled
2021-05-12 17:02:21.111236 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:02:21.171265 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.fetch_takehome.example

2021-05-12 17:02:21.171517 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3f2d4c1-4793-4258-a4ad-816c234f4aa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113671310>]}
2021-05-12 17:02:21.176874 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3f2d4c1-4793-4258-a4ad-816c234f4aa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135ca550>]}
2021-05-12 17:02:21.177145 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:02:21.177689 (MainThread): 
2021-05-12 17:02:21.177998 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:02:21.178753 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:02:21.189942 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:02:21.190069 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:02:21.190165 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:02:21.320494 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.13 seconds
2021-05-12 17:02:21.323261 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:02:21.324255 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:02:21.330168 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:02:21.330296 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:02:21.330379 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:02:21.339258 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:02:21.339401 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:02:21.339581 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:02:21.358321 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.02 seconds
2021-05-12 17:02:21.359040 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:02:21.359412 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:02:21.364513 (MainThread): Using postgres connection "master".
2021-05-12 17:02:21.364632 (MainThread): On master: BEGIN
2021-05-12 17:02:21.364721 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:02:21.372552 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:02:21.372704 (MainThread): Using postgres connection "master".
2021-05-12 17:02:21.372784 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:02:21.406373 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-12 17:02:21.407093 (MainThread): On master: ROLLBACK
2021-05-12 17:02:21.407323 (MainThread): Using postgres connection "master".
2021-05-12 17:02:21.407429 (MainThread): On master: BEGIN
2021-05-12 17:02:21.407706 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:02:21.407855 (MainThread): On master: COMMIT
2021-05-12 17:02:21.407978 (MainThread): Using postgres connection "master".
2021-05-12 17:02:21.408075 (MainThread): On master: COMMIT
2021-05-12 17:02:21.408253 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:02:21.408406 (MainThread): On master: Close
2021-05-12 17:02:21.408743 (MainThread): 13:02:21 | Concurrency: 4 threads (target='dev')
2021-05-12 17:02:21.408867 (MainThread): 13:02:21 | 
2021-05-12 17:02:21.411223 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:02:21.411590 (Thread-1): 13:02:21 | 1 of 1 START view model fetch_takehome.users_json_extract............ [RUN]
2021-05-12 17:02:21.411961 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:02:21.412099 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:02:21.413233 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:02:21.413844 (Thread-1): finished collecting timing info
2021-05-12 17:02:21.437386 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:02:21.437516 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop view if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:02:21.437603 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:02:21.451126 (Thread-1): Postgres error: permission denied for schema fetch_takehome

2021-05-12 17:02:21.451329 (Thread-1): Error running SQL: macro drop_relation
2021-05-12 17:02:21.451405 (Thread-1): Rolling back transaction.
2021-05-12 17:02:21.451513 (Thread-1): finished collecting timing info
2021-05-12 17:02:21.451635 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:02:21.452158 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/compiled/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InsufficientPrivilege: permission denied for schema fetch_takehome


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 44, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/impl.py", line 150, in drop_relation
    self.execute_macro(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 1002, in execute_macro
    result = macro_function(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 30, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/compiled/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:02:21.459944 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3f2d4c1-4793-4258-a4ad-816c234f4aa5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320f850>]}
2021-05-12 17:02:21.460244 (Thread-1): 13:02:21 | 1 of 1 ERROR creating view model fetch_takehome.users_json_extract... [ERROR in 0.05s]
2021-05-12 17:02:21.460363 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:02:21.461419 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:02:21.461556 (MainThread): Using postgres connection "master".
2021-05-12 17:02:21.461637 (MainThread): On master: BEGIN
2021-05-12 17:02:21.461713 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:02:21.469464 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:02:21.469700 (MainThread): On master: COMMIT
2021-05-12 17:02:21.469789 (MainThread): Using postgres connection "master".
2021-05-12 17:02:21.469863 (MainThread): On master: COMMIT
2021-05-12 17:02:21.470060 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:02:21.470177 (MainThread): On master: Close
2021-05-12 17:02:21.470528 (MainThread): 13:02:21 | 
2021-05-12 17:02:21.470696 (MainThread): 13:02:21 | Finished running 1 view model in 0.29s.
2021-05-12 17:02:21.470827 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:02:21.470928 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:02:21.475025 (MainThread): 
2021-05-12 17:02:21.475305 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:02:21.475450 (MainThread): 
2021-05-12 17:02:21.475560 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:02:21.475651 (MainThread):   permission denied for schema fetch_takehome
2021-05-12 17:02:21.475731 (MainThread):   compiled SQL at target/compiled/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:02:21.475817 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:02:21.475998 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11351e130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11359dd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11359dc10>]}
2021-05-12 17:02:21.476196 (MainThread): Flushing usage events
2021-05-12 17:03:28.309505 (MainThread): Running with dbt=0.19.1
2021-05-12 17:03:28.419326 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:03:28.420459 (MainThread): Tracking: tracking
2021-05-12 17:03:28.439642 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd8f8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddbd580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddbd7c0>]}
2021-05-12 17:03:28.459382 (MainThread): Partial parsing not enabled
2021-05-12 17:03:28.461286 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:03:28.467457 (MainThread): Parsing macros/relations.sql
2021-05-12 17:03:28.469995 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:03:28.505850 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:03:28.511291 (MainThread): Parsing macros/core.sql
2021-05-12 17:03:28.518779 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:03:28.534480 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:03:28.538283 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:03:28.571933 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:03:28.645614 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:03:28.707663 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:03:28.713615 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:03:28.728920 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:03:28.774295 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:03:28.858002 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:03:28.879546 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:03:28.888498 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:03:28.890181 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:03:28.892320 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:03:28.896178 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:03:28.914013 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:03:28.916976 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:03:28.919686 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:03:28.997359 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:03:29.003447 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:03:29.006292 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:03:29.009861 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:03:29.021626 (MainThread): Partial parsing not enabled
2021-05-12 17:03:29.093099 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:03:29.174873 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dc45c165-5048-4e2c-9065-0beedee8814c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df89610>]}
2021-05-12 17:03:29.180321 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc45c165-5048-4e2c-9065-0beedee8814c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df066a0>]}
2021-05-12 17:03:29.180636 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:03:29.181355 (MainThread): 
2021-05-12 17:03:29.181773 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:03:29.182756 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:03:29.198232 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:03:29.198394 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:03:29.198511 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:03:29.250995 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.05 seconds
2021-05-12 17:03:29.254749 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:03:29.256334 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:03:29.264193 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:03:29.264344 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:03:29.264447 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:03:29.274064 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:03:29.274275 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:03:29.274411 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:03:29.279185 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:03:29.279941 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:03:29.280281 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:03:29.286825 (MainThread): Using postgres connection "master".
2021-05-12 17:03:29.286966 (MainThread): On master: BEGIN
2021-05-12 17:03:29.287094 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:03:29.296260 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:03:29.296447 (MainThread): Using postgres connection "master".
2021-05-12 17:03:29.296564 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:03:29.304543 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:03:29.305358 (MainThread): On master: ROLLBACK
2021-05-12 17:03:29.305610 (MainThread): Using postgres connection "master".
2021-05-12 17:03:29.305736 (MainThread): On master: BEGIN
2021-05-12 17:03:29.306028 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:03:29.306133 (MainThread): On master: COMMIT
2021-05-12 17:03:29.306233 (MainThread): Using postgres connection "master".
2021-05-12 17:03:29.306337 (MainThread): On master: COMMIT
2021-05-12 17:03:29.306533 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:03:29.306643 (MainThread): On master: Close
2021-05-12 17:03:29.307121 (MainThread): 13:03:29 | Concurrency: 4 threads (target='dev')
2021-05-12 17:03:29.307292 (MainThread): 13:03:29 | 
2021-05-12 17:03:29.309871 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:03:29.310234 (Thread-1): 13:03:29 | 1 of 1 START tables model fetch_takehome.users_json_extract.......... [RUN]
2021-05-12 17:03:29.310642 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:03:29.310773 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:03:29.311960 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:03:29.312380 (Thread-1): finished collecting timing info
2021-05-12 17:03:29.313289 (Thread-1): finished collecting timing info
2021-05-12 17:03:29.313549 (Thread-1): Compilation Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  No materialization 'tables' was found for adapter postgres! (searched types 'default' and 'postgres')
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 237, in execute
    missing_materialization(model, self.adapter.type())
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 639, in missing_materialization
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  No materialization 'tables' was found for adapter postgres! (searched types 'default' and 'postgres')
2021-05-12 17:03:29.316114 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dc45c165-5048-4e2c-9065-0beedee8814c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10decbca0>]}
2021-05-12 17:03:29.316384 (Thread-1): 13:03:29 | 1 of 1 ERROR creating tables model fetch_takehome.users_json_extract. [ERROR in 0.01s]
2021-05-12 17:03:29.316513 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:03:29.317738 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:03:29.317932 (MainThread): Using postgres connection "master".
2021-05-12 17:03:29.318050 (MainThread): On master: BEGIN
2021-05-12 17:03:29.318167 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:03:29.327964 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:03:29.328192 (MainThread): On master: COMMIT
2021-05-12 17:03:29.328301 (MainThread): Using postgres connection "master".
2021-05-12 17:03:29.328417 (MainThread): On master: COMMIT
2021-05-12 17:03:29.329036 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:03:29.329190 (MainThread): On master: Close
2021-05-12 17:03:29.329817 (MainThread): 13:03:29 | 
2021-05-12 17:03:29.329987 (MainThread): 13:03:29 | Finished running 1 tables model in 0.15s.
2021-05-12 17:03:29.330117 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:03:29.330220 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:03:29.334506 (MainThread): 
2021-05-12 17:03:29.334663 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:03:29.334808 (MainThread): 
2021-05-12 17:03:29.335006 (MainThread): Compilation Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:03:29.335148 (MainThread):   No materialization 'tables' was found for adapter postgres! (searched types 'default' and 'postgres')
2021-05-12 17:03:29.335322 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:03:29.335621 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10deb4f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10deb9a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd80340>]}
2021-05-12 17:03:29.335801 (MainThread): Flushing usage events
2021-05-12 17:03:41.325694 (MainThread): Running with dbt=0.19.1
2021-05-12 17:03:41.481473 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:03:41.482905 (MainThread): Tracking: tracking
2021-05-12 17:03:41.501925 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105852eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10586f670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10586feb0>]}
2021-05-12 17:03:41.519110 (MainThread): Partial parsing not enabled
2021-05-12 17:03:41.521442 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:03:41.526412 (MainThread): Parsing macros/relations.sql
2021-05-12 17:03:41.528804 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:03:41.555243 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:03:41.558982 (MainThread): Parsing macros/core.sql
2021-05-12 17:03:41.564363 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:03:41.576374 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:03:41.578886 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:03:41.604960 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:03:41.645620 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:03:41.669766 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:03:41.672663 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:03:41.680757 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:03:41.699958 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:03:41.709324 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:03:41.718270 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:03:41.725948 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:03:41.727429 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:03:41.729121 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:03:41.731724 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:03:41.745037 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:03:41.748061 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:03:41.750600 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:03:41.806066 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:03:41.808183 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:03:41.809923 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:03:41.811931 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:03:41.819773 (MainThread): Partial parsing not enabled
2021-05-12 17:03:41.876781 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:03:41.935015 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '617d6d78-67fa-40e8-924e-e1212d4cae37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a36760>]}
2021-05-12 17:03:41.938672 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '617d6d78-67fa-40e8-924e-e1212d4cae37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059d4100>]}
2021-05-12 17:03:41.938901 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:03:41.939386 (MainThread): 
2021-05-12 17:03:41.939715 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:03:41.940395 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:03:41.951482 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:03:41.951613 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:03:41.951702 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:03:41.971788 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-12 17:03:41.975488 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:03:41.976978 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:03:41.984904 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:03:41.985049 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:03:41.985155 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:03:41.995131 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:03:41.995406 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:03:41.995545 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:03:42.000583 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:03:42.001718 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:03:42.002093 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:03:42.007384 (MainThread): Using postgres connection "master".
2021-05-12 17:03:42.007529 (MainThread): On master: BEGIN
2021-05-12 17:03:42.007709 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:03:42.017762 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:03:42.017979 (MainThread): Using postgres connection "master".
2021-05-12 17:03:42.018099 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:03:42.027250 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:03:42.027861 (MainThread): On master: ROLLBACK
2021-05-12 17:03:42.028081 (MainThread): Using postgres connection "master".
2021-05-12 17:03:42.028173 (MainThread): On master: BEGIN
2021-05-12 17:03:42.028448 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:03:42.028552 (MainThread): On master: COMMIT
2021-05-12 17:03:42.028634 (MainThread): Using postgres connection "master".
2021-05-12 17:03:42.028712 (MainThread): On master: COMMIT
2021-05-12 17:03:42.028961 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:03:42.029105 (MainThread): On master: Close
2021-05-12 17:03:42.029478 (MainThread): 13:03:42 | Concurrency: 4 threads (target='dev')
2021-05-12 17:03:42.029665 (MainThread): 13:03:42 | 
2021-05-12 17:03:42.032029 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:03:42.032392 (Thread-1): 13:03:42 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:03:42.032784 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:03:42.032934 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:03:42.034066 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:03:42.034519 (Thread-1): finished collecting timing info
2021-05-12 17:03:42.053986 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:03:42.054124 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:03:42.054217 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:03:42.063214 (Thread-1): Postgres error: permission denied for schema fetch_takehome

2021-05-12 17:03:42.063495 (Thread-1): Error running SQL: macro drop_relation
2021-05-12 17:03:42.063624 (Thread-1): Rolling back transaction.
2021-05-12 17:03:42.063849 (Thread-1): finished collecting timing info
2021-05-12 17:03:42.064134 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:03:42.064918 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/compiled/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InsufficientPrivilege: permission denied for schema fetch_takehome


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 44, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/impl.py", line 150, in drop_relation
    self.execute_macro(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 1002, in execute_macro
    result = macro_function(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 30, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/compiled/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:03:42.073365 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '617d6d78-67fa-40e8-924e-e1212d4cae37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105966790>]}
2021-05-12 17:03:42.073876 (Thread-1): 13:03:42 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.04s]
2021-05-12 17:03:42.074022 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:03:42.075296 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:03:42.075433 (MainThread): Using postgres connection "master".
2021-05-12 17:03:42.075513 (MainThread): On master: BEGIN
2021-05-12 17:03:42.075595 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:03:42.083898 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:03:42.084073 (MainThread): On master: COMMIT
2021-05-12 17:03:42.084158 (MainThread): Using postgres connection "master".
2021-05-12 17:03:42.084234 (MainThread): On master: COMMIT
2021-05-12 17:03:42.084432 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:03:42.084586 (MainThread): On master: Close
2021-05-12 17:03:42.084975 (MainThread): 13:03:42 | 
2021-05-12 17:03:42.085137 (MainThread): 13:03:42 | Finished running 1 table model in 0.15s.
2021-05-12 17:03:42.085271 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:03:42.085394 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:03:42.090460 (MainThread): 
2021-05-12 17:03:42.090630 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:03:42.090796 (MainThread): 
2021-05-12 17:03:42.090996 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:03:42.091161 (MainThread):   permission denied for schema fetch_takehome
2021-05-12 17:03:42.091259 (MainThread):   compiled SQL at target/compiled/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:03:42.091356 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:03:42.091602 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105961f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10596e8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105852040>]}
2021-05-12 17:03:42.091844 (MainThread): Flushing usage events
2021-05-12 17:08:46.567584 (MainThread): Running with dbt=0.19.1
2021-05-12 17:08:46.672297 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:08:46.673743 (MainThread): Tracking: tracking
2021-05-12 17:08:46.691331 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f74df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f915e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f91e20>]}
2021-05-12 17:08:46.705660 (MainThread): Partial parsing not enabled
2021-05-12 17:08:46.707120 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:08:46.712078 (MainThread): Parsing macros/relations.sql
2021-05-12 17:08:46.714280 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:08:46.738817 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:08:46.742203 (MainThread): Parsing macros/core.sql
2021-05-12 17:08:46.747008 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:08:46.758248 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:08:46.760739 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:08:46.783585 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:08:46.821487 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:08:46.843435 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:08:46.845728 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:08:46.854236 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:08:46.871858 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:08:46.879404 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:08:46.886492 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:08:46.892492 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:08:46.893730 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:08:46.895075 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:08:46.896969 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:08:46.906327 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:08:46.908550 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:08:46.910527 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:08:46.954798 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:08:46.957032 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:08:46.958798 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:08:46.960833 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:08:46.968470 (MainThread): Partial parsing not enabled
2021-05-12 17:08:47.022236 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:08:47.082384 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '691eb702-f6b5-4fb7-92f9-d8f1d910e1e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107158670>]}
2021-05-12 17:08:47.086069 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '691eb702-f6b5-4fb7-92f9-d8f1d910e1e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070d6580>]}
2021-05-12 17:08:47.086304 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:08:47.086894 (MainThread): 
2021-05-12 17:08:47.087250 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:08:47.088019 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:08:47.099213 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:08:47.099339 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:08:47.099437 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:08:47.311166 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.21 seconds
2021-05-12 17:08:47.313670 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:08:47.314861 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:08:47.320625 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:08:47.320745 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:08:47.320832 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:08:47.328468 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:08:47.328607 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:08:47.328686 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:08:47.331956 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:08:47.332549 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:08:47.332752 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:08:47.337257 (MainThread): Using postgres connection "master".
2021-05-12 17:08:47.337398 (MainThread): On master: BEGIN
2021-05-12 17:08:47.337484 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:08:47.345966 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:08:47.346123 (MainThread): Using postgres connection "master".
2021-05-12 17:08:47.346205 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:08:47.353707 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:08:47.354223 (MainThread): On master: ROLLBACK
2021-05-12 17:08:47.354442 (MainThread): Using postgres connection "master".
2021-05-12 17:08:47.354573 (MainThread): On master: BEGIN
2021-05-12 17:08:47.354875 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:08:47.354992 (MainThread): On master: COMMIT
2021-05-12 17:08:47.355137 (MainThread): Using postgres connection "master".
2021-05-12 17:08:47.355305 (MainThread): On master: COMMIT
2021-05-12 17:08:47.355501 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:08:47.355653 (MainThread): On master: Close
2021-05-12 17:08:47.355989 (MainThread): 13:08:47 | Concurrency: 4 threads (target='dev')
2021-05-12 17:08:47.356154 (MainThread): 13:08:47 | 
2021-05-12 17:08:47.358520 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:08:47.358767 (Thread-1): 13:08:47 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:08:47.359115 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:08:47.359262 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:08:47.360523 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:08:47.360920 (Thread-1): finished collecting timing info
2021-05-12 17:08:47.380552 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:08:47.380732 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:08:47.380925 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:08:47.410581 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2021-05-12 17:08:47.413574 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:08:47.413727 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:08:47.414078 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:08:47.425586 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:08:47.426240 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:08:47.426344 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:08:47.426642 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:08:47.426745 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:08:47.426869 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId
json_extract_path (to_json(json_txt), 'role') as role
json_extract_path (to_json(json_txt), 'state') as state
json_extract_path (to_json(json_txt), 'active') as active
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin
json_extract_path (to_json(json_txt), 'createdDate', '$date') as userId
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users;
  );
2021-05-12 17:08:47.486113 (Thread-1): Postgres error: syntax error at or near "json_extract_path"
LINE 8: json_extract_path (to_json(json_txt), 'role') as role
        ^

2021-05-12 17:08:47.486307 (Thread-1): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-12 17:08:47.486614 (Thread-1): finished collecting timing info
2021-05-12 17:08:47.486777 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:08:47.487216 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  syntax error at or near "json_extract_path"
  LINE 8: json_extract_path (to_json(json_txt), 'role') as role
          ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "json_extract_path"
LINE 8: json_extract_path (to_json(json_txt), 'role') as role
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  syntax error at or near "json_extract_path"
  LINE 8: json_extract_path (to_json(json_txt), 'role') as role
          ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:08:47.494175 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '691eb702-f6b5-4fb7-92f9-d8f1d910e1e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f56400>]}
2021-05-12 17:08:47.494467 (Thread-1): 13:08:47 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.14s]
2021-05-12 17:08:47.494584 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:08:47.495829 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:08:47.495950 (MainThread): Using postgres connection "master".
2021-05-12 17:08:47.496022 (MainThread): On master: BEGIN
2021-05-12 17:08:47.496095 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:08:47.504210 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:08:47.504424 (MainThread): On master: COMMIT
2021-05-12 17:08:47.504512 (MainThread): Using postgres connection "master".
2021-05-12 17:08:47.504582 (MainThread): On master: COMMIT
2021-05-12 17:08:47.504750 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:08:47.504897 (MainThread): On master: Close
2021-05-12 17:08:47.505281 (MainThread): 13:08:47 | 
2021-05-12 17:08:47.505403 (MainThread): 13:08:47 | Finished running 1 table model in 0.42s.
2021-05-12 17:08:47.505506 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:08:47.505591 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:08:47.509271 (MainThread): 
2021-05-12 17:08:47.509402 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:08:47.509522 (MainThread): 
2021-05-12 17:08:47.509658 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:08:47.509780 (MainThread):   syntax error at or near "json_extract_path"
2021-05-12 17:08:47.509893 (MainThread):   LINE 8: json_extract_path (to_json(json_txt), 'role') as role
2021-05-12 17:08:47.510006 (MainThread):           ^
2021-05-12 17:08:47.510114 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:08:47.510234 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:08:47.510428 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103dcd760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d53940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f45e50>]}
2021-05-12 17:08:47.510660 (MainThread): Flushing usage events
2021-05-12 17:09:07.978341 (MainThread): Running with dbt=0.19.1
2021-05-12 17:09:08.062892 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:09:08.063900 (MainThread): Tracking: tracking
2021-05-12 17:09:08.090038 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10859de20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b9640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085b9e80>]}
2021-05-12 17:09:08.109596 (MainThread): Partial parsing not enabled
2021-05-12 17:09:08.111948 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:09:08.117248 (MainThread): Parsing macros/relations.sql
2021-05-12 17:09:08.119918 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:09:08.146623 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:09:08.151046 (MainThread): Parsing macros/core.sql
2021-05-12 17:09:08.155707 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:09:08.166053 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:09:08.168292 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:09:08.189722 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:09:08.226681 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:09:08.249454 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:09:08.251690 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:09:08.258756 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:09:08.274617 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:09:08.282499 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:09:08.290224 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:09:08.296072 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:09:08.297286 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:09:08.298656 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:09:08.300581 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:09:08.310255 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:09:08.312546 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:09:08.314702 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:09:08.368579 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:09:08.371147 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:09:08.373312 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:09:08.375587 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:09:08.385027 (MainThread): Partial parsing not enabled
2021-05-12 17:09:08.445810 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:09:08.515845 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28496dff-7206-49fe-a4b2-661b2d1beca3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087806d0>]}
2021-05-12 17:09:08.520682 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28496dff-7206-49fe-a4b2-661b2d1beca3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086d6610>]}
2021-05-12 17:09:08.520990 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:09:08.521950 (MainThread): 
2021-05-12 17:09:08.522386 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:09:08.523308 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:09:08.536237 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:09:08.536394 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:09:08.536510 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:09:08.597273 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.06 seconds
2021-05-12 17:09:08.600865 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:09:08.601926 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:09:08.609937 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:09:08.610129 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:09:08.610304 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:09:08.621298 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:09:08.621517 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:09:08.621625 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:09:08.627173 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.01 seconds
2021-05-12 17:09:08.628052 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:09:08.628329 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:09:08.634180 (MainThread): Using postgres connection "master".
2021-05-12 17:09:08.634320 (MainThread): On master: BEGIN
2021-05-12 17:09:08.634425 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:09:08.642922 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:09:08.643068 (MainThread): Using postgres connection "master".
2021-05-12 17:09:08.643188 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:09:08.651377 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:09:08.652260 (MainThread): On master: ROLLBACK
2021-05-12 17:09:08.652499 (MainThread): Using postgres connection "master".
2021-05-12 17:09:08.652585 (MainThread): On master: BEGIN
2021-05-12 17:09:08.652842 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:09:08.652982 (MainThread): On master: COMMIT
2021-05-12 17:09:08.653104 (MainThread): Using postgres connection "master".
2021-05-12 17:09:08.653212 (MainThread): On master: COMMIT
2021-05-12 17:09:08.653421 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:09:08.653567 (MainThread): On master: Close
2021-05-12 17:09:08.653940 (MainThread): 13:09:08 | Concurrency: 4 threads (target='dev')
2021-05-12 17:09:08.654086 (MainThread): 13:09:08 | 
2021-05-12 17:09:08.656522 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:09:08.656882 (Thread-1): 13:09:08 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:09:08.657195 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:09:08.657325 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:09:08.658897 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:09:08.659268 (Thread-1): finished collecting timing info
2021-05-12 17:09:08.679939 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:09:08.680091 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:09:08.680191 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:09:08.688608 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-12 17:09:08.692427 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:09:08.692615 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:09:08.692947 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:09:08.708139 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:09:08.708729 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:09:08.708859 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:09:08.709254 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:09:08.709434 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:09:08.709565 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as userId,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users;
  );
2021-05-12 17:09:08.710100 (Thread-1): Postgres error: syntax error at or near ";"
LINE 14: from fetch_takehome.users;
                                  ^

2021-05-12 17:09:08.710249 (Thread-1): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-12 17:09:08.710597 (Thread-1): finished collecting timing info
2021-05-12 17:09:08.710739 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:09:08.711078 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  syntax error at or near ";"
  LINE 14: from fetch_takehome.users;
                                    ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ";"
LINE 14: from fetch_takehome.users;
                                  ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  syntax error at or near ";"
  LINE 14: from fetch_takehome.users;
                                    ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:09:08.718935 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28496dff-7206-49fe-a4b2-661b2d1beca3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108331ca0>]}
2021-05-12 17:09:08.719331 (Thread-1): 13:09:08 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.06s]
2021-05-12 17:09:08.719499 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:09:08.720835 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:09:08.720999 (MainThread): Using postgres connection "master".
2021-05-12 17:09:08.721087 (MainThread): On master: BEGIN
2021-05-12 17:09:08.721174 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:09:08.729356 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:09:08.729562 (MainThread): On master: COMMIT
2021-05-12 17:09:08.729703 (MainThread): Using postgres connection "master".
2021-05-12 17:09:08.729808 (MainThread): On master: COMMIT
2021-05-12 17:09:08.730062 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:09:08.730200 (MainThread): On master: Close
2021-05-12 17:09:08.730542 (MainThread): 13:09:08 | 
2021-05-12 17:09:08.730670 (MainThread): 13:09:08 | Finished running 1 table model in 0.21s.
2021-05-12 17:09:08.730834 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:09:08.730966 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:09:08.735822 (MainThread): 
2021-05-12 17:09:08.736023 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:09:08.736187 (MainThread): 
2021-05-12 17:09:08.736334 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:09:08.736451 (MainThread):   syntax error at or near ";"
2021-05-12 17:09:08.736569 (MainThread):   LINE 14: from fetch_takehome.users;
2021-05-12 17:09:08.736676 (MainThread):                                     ^
2021-05-12 17:09:08.736778 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:09:08.736886 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:09:08.737139 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e72580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086abd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086abd90>]}
2021-05-12 17:09:08.737401 (MainThread): Flushing usage events
2021-05-12 17:10:27.900208 (MainThread): Running with dbt=0.19.1
2021-05-12 17:10:27.967678 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:10:27.968452 (MainThread): Tracking: tracking
2021-05-12 17:10:27.981760 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104571400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10458e610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10458ee50>]}
2021-05-12 17:10:27.997124 (MainThread): Partial parsing not enabled
2021-05-12 17:10:27.998400 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:10:28.003064 (MainThread): Parsing macros/relations.sql
2021-05-12 17:10:28.004972 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:10:28.031450 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:10:28.035110 (MainThread): Parsing macros/core.sql
2021-05-12 17:10:28.039902 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:10:28.051679 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:10:28.053867 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:10:28.078299 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:10:28.121339 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:10:28.144866 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:10:28.146795 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:10:28.153143 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:10:28.167831 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:10:28.175189 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:10:28.181763 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:10:28.186879 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:10:28.187846 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:10:28.188989 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:10:28.190751 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:10:28.199966 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:10:28.202020 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:10:28.203866 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:10:28.248433 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:10:28.250410 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:10:28.252019 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:10:28.253752 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:10:28.261417 (MainThread): Partial parsing not enabled
2021-05-12 17:10:28.315316 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:28.375469 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '034746df-7cfa-4e52-83b4-5791b23e5345', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104755700>]}
2021-05-12 17:10:28.379502 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '034746df-7cfa-4e52-83b4-5791b23e5345', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046d2f70>]}
2021-05-12 17:10:28.379777 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:10:28.380330 (MainThread): 
2021-05-12 17:10:28.380638 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:10:28.381355 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:10:28.392889 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:10:28.393038 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:10:28.393159 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:10:28.422858 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-12 17:10:28.426202 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:10:28.427345 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:10:28.433899 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:10:28.434044 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:10:28.434156 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:10:28.443696 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:10:28.443893 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:10:28.444007 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:10:28.447512 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:10:28.448181 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:10:28.448432 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:10:28.452842 (MainThread): Using postgres connection "master".
2021-05-12 17:10:28.452996 (MainThread): On master: BEGIN
2021-05-12 17:10:28.453102 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:10:28.461678 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:10:28.461844 (MainThread): Using postgres connection "master".
2021-05-12 17:10:28.461941 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:10:28.468200 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:10:28.468783 (MainThread): On master: ROLLBACK
2021-05-12 17:10:28.469046 (MainThread): Using postgres connection "master".
2021-05-12 17:10:28.469242 (MainThread): On master: BEGIN
2021-05-12 17:10:28.469667 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:10:28.469813 (MainThread): On master: COMMIT
2021-05-12 17:10:28.469919 (MainThread): Using postgres connection "master".
2021-05-12 17:10:28.470013 (MainThread): On master: COMMIT
2021-05-12 17:10:28.470239 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:10:28.470372 (MainThread): On master: Close
2021-05-12 17:10:28.470723 (MainThread): 13:10:28 | Concurrency: 4 threads (target='dev')
2021-05-12 17:10:28.470878 (MainThread): 13:10:28 | 
2021-05-12 17:10:28.473243 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:10:28.473551 (Thread-1): 13:10:28 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:10:28.474070 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:28.474225 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:10:28.475633 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:10:28.476075 (Thread-1): finished collecting timing info
2021-05-12 17:10:28.495650 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:28.495787 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:10:28.495877 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:10:28.504036 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-12 17:10:28.506578 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:28.506792 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:10:28.507356 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:10:28.520033 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:10:28.520569 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:28.520684 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:10:28.521045 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:10:28.521173 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:28.521268 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as userId,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-12 17:10:28.536637 (Thread-1): Postgres error: permission denied for schema fetch_takehome

2021-05-12 17:10:28.536838 (Thread-1): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-12 17:10:28.537191 (Thread-1): finished collecting timing info
2021-05-12 17:10:28.537374 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:10:28.537774 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InsufficientPrivilege: permission denied for schema fetch_takehome


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:10:28.540164 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '034746df-7cfa-4e52-83b4-5791b23e5345', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042d6df0>]}
2021-05-12 17:10:28.540516 (Thread-1): 13:10:28 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.07s]
2021-05-12 17:10:28.540702 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:10:28.541936 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:10:28.542093 (MainThread): Using postgres connection "master".
2021-05-12 17:10:28.542189 (MainThread): On master: BEGIN
2021-05-12 17:10:28.542289 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:10:28.550461 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:10:28.550635 (MainThread): On master: COMMIT
2021-05-12 17:10:28.550735 (MainThread): Using postgres connection "master".
2021-05-12 17:10:28.550824 (MainThread): On master: COMMIT
2021-05-12 17:10:28.551047 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:10:28.551283 (MainThread): On master: Close
2021-05-12 17:10:28.551613 (MainThread): 13:10:28 | 
2021-05-12 17:10:28.551743 (MainThread): 13:10:28 | Finished running 1 table model in 0.17s.
2021-05-12 17:10:28.551851 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:10:28.551933 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:10:28.555685 (MainThread): 
2021-05-12 17:10:28.555841 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:10:28.555956 (MainThread): 
2021-05-12 17:10:28.556100 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:10:28.556331 (MainThread):   permission denied for schema fetch_takehome
2021-05-12 17:10:28.556472 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:10:28.556631 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:10:28.556828 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10469e070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10474b5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104716f70>]}
2021-05-12 17:10:28.557031 (MainThread): Flushing usage events
2021-05-12 17:10:47.316297 (MainThread): Running with dbt=0.19.1
2021-05-12 17:10:47.386614 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:10:47.387559 (MainThread): Tracking: tracking
2021-05-12 17:10:47.400750 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e380880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3a5610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3a5e50>]}
2021-05-12 17:10:47.415505 (MainThread): Partial parsing not enabled
2021-05-12 17:10:47.416673 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:10:47.420652 (MainThread): Parsing macros/relations.sql
2021-05-12 17:10:47.422460 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:10:47.448772 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:10:47.452175 (MainThread): Parsing macros/core.sql
2021-05-12 17:10:47.456707 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:10:47.466247 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:10:47.468105 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:10:47.488119 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:10:47.527846 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:10:47.551510 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:10:47.553486 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:10:47.560003 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:10:47.574894 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:10:47.582239 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:10:47.588937 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:10:47.594148 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:10:47.595176 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:10:47.596265 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:10:47.598065 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:10:47.607786 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:10:47.609931 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:10:47.611704 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:10:47.655948 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:10:47.657921 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:10:47.659623 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:10:47.661379 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:10:47.669088 (MainThread): Partial parsing not enabled
2021-05-12 17:10:47.723949 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:47.784637 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f47baf54-9b19-4b9d-bfc3-7432aefe3818', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e572700>]}
2021-05-12 17:10:47.788608 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f47baf54-9b19-4b9d-bfc3-7432aefe3818', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4f0f70>]}
2021-05-12 17:10:47.788894 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:10:47.789454 (MainThread): 
2021-05-12 17:10:47.789776 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:10:47.790540 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:10:47.802387 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:10:47.802542 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:10:47.802650 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:10:47.826677 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-12 17:10:47.829486 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:10:47.830625 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:10:47.837026 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:10:47.837163 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:10:47.837265 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:10:47.846989 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:10:47.847181 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:10:47.847281 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:10:47.850643 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:10:47.851543 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:10:47.851904 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:10:47.857241 (MainThread): Using postgres connection "master".
2021-05-12 17:10:47.857388 (MainThread): On master: BEGIN
2021-05-12 17:10:47.857493 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:10:47.866357 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:10:47.866522 (MainThread): Using postgres connection "master".
2021-05-12 17:10:47.866619 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:10:47.874555 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:10:47.875555 (MainThread): On master: ROLLBACK
2021-05-12 17:10:47.875936 (MainThread): Using postgres connection "master".
2021-05-12 17:10:47.876126 (MainThread): On master: BEGIN
2021-05-12 17:10:47.876532 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:10:47.876719 (MainThread): On master: COMMIT
2021-05-12 17:10:47.876877 (MainThread): Using postgres connection "master".
2021-05-12 17:10:47.877018 (MainThread): On master: COMMIT
2021-05-12 17:10:47.877324 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:10:47.877586 (MainThread): On master: Close
2021-05-12 17:10:47.878069 (MainThread): 13:10:47 | Concurrency: 4 threads (target='dev')
2021-05-12 17:10:47.878264 (MainThread): 13:10:47 | 
2021-05-12 17:10:47.880905 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:10:47.881256 (Thread-1): 13:10:47 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:10:47.881597 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:47.881765 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:10:47.883362 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:10:47.883834 (Thread-1): finished collecting timing info
2021-05-12 17:10:47.907018 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:47.907179 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:10:47.907284 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:10:47.919263 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-12 17:10:47.923016 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:47.923214 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:10:47.923574 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:10:47.943446 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:10:47.944152 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:47.944293 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:10:47.944618 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:10:47.944758 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:10:47.944859 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as userId,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-12 17:10:47.946423 (Thread-1): Postgres error: permission denied for schema fetch_takehome

2021-05-12 17:10:47.946588 (Thread-1): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-12 17:10:47.946921 (Thread-1): finished collecting timing info
2021-05-12 17:10:47.947119 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:10:47.947506 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InsufficientPrivilege: permission denied for schema fetch_takehome


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:10:47.950459 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f47baf54-9b19-4b9d-bfc3-7432aefe3818', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db90220>]}
2021-05-12 17:10:47.950827 (Thread-1): 13:10:47 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.07s]
2021-05-12 17:10:47.950974 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:10:47.952360 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:10:47.952518 (MainThread): Using postgres connection "master".
2021-05-12 17:10:47.952614 (MainThread): On master: BEGIN
2021-05-12 17:10:47.952711 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:10:47.962144 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:10:47.962409 (MainThread): On master: COMMIT
2021-05-12 17:10:47.962571 (MainThread): Using postgres connection "master".
2021-05-12 17:10:47.962718 (MainThread): On master: COMMIT
2021-05-12 17:10:47.963068 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:10:47.963238 (MainThread): On master: Close
2021-05-12 17:10:47.963657 (MainThread): 13:10:47 | 
2021-05-12 17:10:47.963837 (MainThread): 13:10:47 | Finished running 1 table model in 0.17s.
2021-05-12 17:10:47.964014 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:10:47.964141 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:10:47.968560 (MainThread): 
2021-05-12 17:10:47.968731 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:10:47.968852 (MainThread): 
2021-05-12 17:10:47.968965 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:10:47.969067 (MainThread):   permission denied for schema fetch_takehome
2021-05-12 17:10:47.969160 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:10:47.969260 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:10:47.969442 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d31c520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1e7760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5319a0>]}
2021-05-12 17:10:47.969639 (MainThread): Flushing usage events
2021-05-12 17:17:21.592730 (MainThread): Running with dbt=0.19.1
2021-05-12 17:17:21.698772 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:17:21.700581 (MainThread): Tracking: tracking
2021-05-12 17:17:21.717578 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa0be20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa305e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa30e20>]}
2021-05-12 17:17:21.731942 (MainThread): Partial parsing not enabled
2021-05-12 17:17:21.733527 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:17:21.738141 (MainThread): Parsing macros/relations.sql
2021-05-12 17:17:21.740297 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:17:21.764916 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:17:21.768724 (MainThread): Parsing macros/core.sql
2021-05-12 17:17:21.774030 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:17:21.784707 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:17:21.786945 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:17:21.806374 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:17:21.842352 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:17:21.864189 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:17:21.866609 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:17:21.874873 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:17:21.890975 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:17:21.898811 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:17:21.906228 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:17:21.911951 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:17:21.913395 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:17:21.915396 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:17:21.917926 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:17:21.929054 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:17:21.931590 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:17:21.933711 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:17:21.978675 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:17:21.980897 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:17:21.982676 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:17:21.984675 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:17:21.993925 (MainThread): Partial parsing not enabled
2021-05-12 17:17:22.049216 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:17:22.112762 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '462237da-3f68-4c82-bfbc-10d7170a3b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abfd670>]}
2021-05-12 17:17:22.116748 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '462237da-3f68-4c82-bfbc-10d7170a3b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab7a580>]}
2021-05-12 17:17:22.117005 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:17:22.117557 (MainThread): 
2021-05-12 17:17:22.117867 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:17:22.118628 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:17:22.130045 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:17:22.130176 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:17:22.130277 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:17:22.172980 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-12 17:17:22.176895 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:17:22.178343 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:17:22.188054 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:17:22.188357 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:17:22.188574 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:17:22.198025 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:17:22.198201 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:17:22.198302 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:17:22.201871 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:17:22.202584 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:17:22.202835 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:17:22.207556 (MainThread): Using postgres connection "master".
2021-05-12 17:17:22.207699 (MainThread): On master: BEGIN
2021-05-12 17:17:22.207813 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:17:22.216555 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:17:22.216729 (MainThread): Using postgres connection "master".
2021-05-12 17:17:22.216830 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:17:22.223123 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:17:22.223718 (MainThread): On master: ROLLBACK
2021-05-12 17:17:22.224011 (MainThread): Using postgres connection "master".
2021-05-12 17:17:22.224232 (MainThread): On master: BEGIN
2021-05-12 17:17:22.224644 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:17:22.224777 (MainThread): On master: COMMIT
2021-05-12 17:17:22.224882 (MainThread): Using postgres connection "master".
2021-05-12 17:17:22.224970 (MainThread): On master: COMMIT
2021-05-12 17:17:22.225164 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:17:22.225284 (MainThread): On master: Close
2021-05-12 17:17:22.225619 (MainThread): 13:17:22 | Concurrency: 4 threads (target='dev')
2021-05-12 17:17:22.225775 (MainThread): 13:17:22 | 
2021-05-12 17:17:22.228159 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:17:22.228461 (Thread-1): 13:17:22 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:17:22.228774 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:17:22.228909 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:17:22.230237 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:17:22.230677 (Thread-1): finished collecting timing info
2021-05-12 17:17:22.250795 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:17:22.250936 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:17:22.251029 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:17:22.258159 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-12 17:17:22.260707 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:17:22.260960 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:17:22.261502 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:17:22.272608 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:17:22.272981 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:17:22.273067 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:17:22.273328 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:17:22.273428 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:17:22.273506 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as userId,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-12 17:17:22.274773 (Thread-1): Postgres error: permission denied for schema fetch_takehome

2021-05-12 17:17:22.274891 (Thread-1): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-12 17:17:22.275097 (Thread-1): finished collecting timing info
2021-05-12 17:17:22.275217 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:17:22.275485 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InsufficientPrivilege: permission denied for schema fetch_takehome


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:17:22.282181 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '462237da-3f68-4c82-bfbc-10d7170a3b74', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab353d0>]}
2021-05-12 17:17:22.282485 (Thread-1): 13:17:22 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.05s]
2021-05-12 17:17:22.282605 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:17:22.283691 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:17:22.283825 (MainThread): Using postgres connection "master".
2021-05-12 17:17:22.283905 (MainThread): On master: BEGIN
2021-05-12 17:17:22.283989 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:17:22.291979 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:17:22.292193 (MainThread): On master: COMMIT
2021-05-12 17:17:22.292300 (MainThread): Using postgres connection "master".
2021-05-12 17:17:22.292421 (MainThread): On master: COMMIT
2021-05-12 17:17:22.292749 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:17:22.292917 (MainThread): On master: Close
2021-05-12 17:17:22.293326 (MainThread): 13:17:22 | 
2021-05-12 17:17:22.293538 (MainThread): 13:17:22 | Finished running 1 table model in 0.18s.
2021-05-12 17:17:22.293754 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:17:22.293888 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:17:22.297997 (MainThread): 
2021-05-12 17:17:22.298157 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:17:22.298286 (MainThread): 
2021-05-12 17:17:22.298421 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:17:22.298535 (MainThread):   permission denied for schema fetch_takehome
2021-05-12 17:17:22.298654 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:17:22.298777 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:17:22.298996 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9e4100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa47f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab3f790>]}
2021-05-12 17:17:22.299230 (MainThread): Flushing usage events
2021-05-12 17:18:23.033246 (MainThread): Running with dbt=0.19.1
2021-05-12 17:18:23.116449 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:18:23.117251 (MainThread): Tracking: tracking
2021-05-12 17:18:23.135199 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c6d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050ee580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050ee7c0>]}
2021-05-12 17:18:23.150096 (MainThread): Partial parsing not enabled
2021-05-12 17:18:23.151647 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:18:23.156837 (MainThread): Parsing macros/relations.sql
2021-05-12 17:18:23.159215 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:18:23.184632 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:18:23.187857 (MainThread): Parsing macros/core.sql
2021-05-12 17:18:23.192484 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:18:23.202190 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:18:23.204325 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:18:23.224984 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:18:23.268595 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:18:23.296075 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:18:23.298724 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:18:23.307460 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:18:23.326236 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:18:23.335708 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:18:23.345079 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:18:23.352187 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:18:23.353794 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:18:23.355674 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:18:23.358394 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:18:23.371046 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:18:23.374006 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:18:23.376671 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:18:23.446558 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:18:23.449443 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:18:23.451867 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:18:23.454829 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:18:23.465447 (MainThread): Partial parsing not enabled
2021-05-12 17:18:23.530165 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:18:23.597486 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32d5bdbe-bcd8-442d-8da4-90d1cd34066b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052b4610>]}
2021-05-12 17:18:23.601659 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32d5bdbe-bcd8-442d-8da4-90d1cd34066b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052316a0>]}
2021-05-12 17:18:23.601940 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:18:23.602523 (MainThread): 
2021-05-12 17:18:23.602870 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:18:23.603713 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:18:23.617312 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:18:23.617486 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:18:23.617606 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:18:23.651619 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-12 17:18:23.655134 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:18:23.656600 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:18:23.664971 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:18:23.665157 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:18:23.665291 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:18:23.675015 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:18:23.675194 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:18:23.675371 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:18:23.678697 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:18:23.679357 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:18:23.679695 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:18:23.684716 (MainThread): Using postgres connection "master".
2021-05-12 17:18:23.684861 (MainThread): On master: BEGIN
2021-05-12 17:18:23.684974 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:18:23.693914 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:18:23.694147 (MainThread): Using postgres connection "master".
2021-05-12 17:18:23.694289 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:18:23.700907 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:18:23.701507 (MainThread): On master: ROLLBACK
2021-05-12 17:18:23.701782 (MainThread): Using postgres connection "master".
2021-05-12 17:18:23.701904 (MainThread): On master: BEGIN
2021-05-12 17:18:23.702224 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:18:23.702363 (MainThread): On master: COMMIT
2021-05-12 17:18:23.702468 (MainThread): Using postgres connection "master".
2021-05-12 17:18:23.702558 (MainThread): On master: COMMIT
2021-05-12 17:18:23.702763 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:18:23.702883 (MainThread): On master: Close
2021-05-12 17:18:23.703276 (MainThread): 13:18:23 | Concurrency: 4 threads (target='dev')
2021-05-12 17:18:23.703448 (MainThread): 13:18:23 | 
2021-05-12 17:18:23.706282 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:18:23.706599 (Thread-1): 13:18:23 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:18:23.707124 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:18:23.707372 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:18:23.708850 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:18:23.709289 (Thread-1): finished collecting timing info
2021-05-12 17:18:23.730907 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:18:23.731062 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:18:23.731169 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:18:23.740434 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-12 17:18:23.743081 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:18:23.743298 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:18:23.743719 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:18:23.756891 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:18:23.757487 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:18:23.757602 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:18:23.757975 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:18:23.758100 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:18:23.758262 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as userId,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-12 17:18:23.759690 (Thread-1): Postgres error: permission denied for schema fetch_takehome

2021-05-12 17:18:23.759820 (Thread-1): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-12 17:18:23.760100 (Thread-1): finished collecting timing info
2021-05-12 17:18:23.760288 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:18:23.760797 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InsufficientPrivilege: permission denied for schema fetch_takehome


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  permission denied for schema fetch_takehome
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:18:23.768311 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32d5bdbe-bcd8-442d-8da4-90d1cd34066b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e4bbe0>]}
2021-05-12 17:18:23.768664 (Thread-1): 13:18:23 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.06s]
2021-05-12 17:18:23.768873 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:18:23.770268 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:18:23.770426 (MainThread): Using postgres connection "master".
2021-05-12 17:18:23.770521 (MainThread): On master: BEGIN
2021-05-12 17:18:23.770618 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:18:23.778869 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:18:23.779044 (MainThread): On master: COMMIT
2021-05-12 17:18:23.779141 (MainThread): Using postgres connection "master".
2021-05-12 17:18:23.779229 (MainThread): On master: COMMIT
2021-05-12 17:18:23.779491 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:18:23.779642 (MainThread): On master: Close
2021-05-12 17:18:23.779982 (MainThread): 13:18:23 | 
2021-05-12 17:18:23.780121 (MainThread): 13:18:23 | Finished running 1 table model in 0.18s.
2021-05-12 17:18:23.780318 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:18:23.780459 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:18:23.784358 (MainThread): 
2021-05-12 17:18:23.784531 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:18:23.784673 (MainThread): 
2021-05-12 17:18:23.784819 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:18:23.784926 (MainThread):   permission denied for schema fetch_takehome
2021-05-12 17:18:23.785023 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:18:23.785124 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:18:23.785305 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bed160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bed130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051defa0>]}
2021-05-12 17:18:23.785498 (MainThread): Flushing usage events
2021-05-12 17:25:38.801283 (MainThread): Running with dbt=0.19.1
2021-05-12 17:25:38.911027 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:25:38.912298 (MainThread): Tracking: tracking
2021-05-12 17:25:38.930545 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d07edf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d09a610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d09ae50>]}
2021-05-12 17:25:38.945413 (MainThread): Partial parsing not enabled
2021-05-12 17:25:38.947303 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:25:38.952282 (MainThread): Parsing macros/relations.sql
2021-05-12 17:25:38.954478 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:25:38.978729 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:25:38.982616 (MainThread): Parsing macros/core.sql
2021-05-12 17:25:38.987345 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:25:38.997225 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:25:38.999518 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:25:39.019336 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:25:39.057093 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:25:39.081834 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:25:39.083944 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:25:39.090605 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:25:39.105281 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:25:39.112779 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:25:39.119939 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:25:39.125584 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:25:39.126658 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:25:39.127918 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:25:39.129819 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:25:39.139367 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:25:39.141916 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:25:39.144081 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:25:39.189736 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:25:39.192023 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:25:39.193838 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:25:39.195980 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:25:39.204359 (MainThread): Partial parsing not enabled
2021-05-12 17:25:39.258729 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:25:39.320685 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3d825681-7aad-41ec-86d2-8c97cea26f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d262700>]}
2021-05-12 17:25:39.324545 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3d825681-7aad-41ec-86d2-8c97cea26f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1dff70>]}
2021-05-12 17:25:39.324808 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:25:39.325387 (MainThread): 
2021-05-12 17:25:39.325750 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:25:39.326523 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:25:39.338124 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:25:39.338263 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:25:39.338369 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:25:39.416313 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.08 seconds
2021-05-12 17:25:39.419451 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:25:39.420383 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:25:39.426971 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:25:39.427122 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:25:39.427231 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:25:39.435008 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:25:39.435170 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:25:39.435265 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:25:39.438285 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:25:39.438913 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:25:39.439120 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:25:39.443520 (MainThread): Using postgres connection "master".
2021-05-12 17:25:39.443663 (MainThread): On master: BEGIN
2021-05-12 17:25:39.443771 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:25:39.451926 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:25:39.452091 (MainThread): Using postgres connection "master".
2021-05-12 17:25:39.452187 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:25:39.458540 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:25:39.459128 (MainThread): On master: ROLLBACK
2021-05-12 17:25:39.459345 (MainThread): Using postgres connection "master".
2021-05-12 17:25:39.459440 (MainThread): On master: BEGIN
2021-05-12 17:25:39.459775 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:25:39.459899 (MainThread): On master: COMMIT
2021-05-12 17:25:39.459994 (MainThread): Using postgres connection "master".
2021-05-12 17:25:39.460075 (MainThread): On master: COMMIT
2021-05-12 17:25:39.460311 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:25:39.460473 (MainThread): On master: Close
2021-05-12 17:25:39.460835 (MainThread): 13:25:39 | Concurrency: 4 threads (target='dev')
2021-05-12 17:25:39.460978 (MainThread): 13:25:39 | 
2021-05-12 17:25:39.463176 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:25:39.463450 (Thread-1): 13:25:39 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:25:39.463785 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:25:39.463937 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:25:39.465225 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:25:39.465640 (Thread-1): finished collecting timing info
2021-05-12 17:25:39.484197 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:25:39.484331 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:25:39.484418 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:25:39.491402 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-12 17:25:39.493496 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:25:39.493619 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:25:39.493907 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:25:39.504868 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:25:39.505408 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:25:39.505518 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:25:39.505812 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:25:39.505927 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:25:39.506012 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as userId,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-12 17:25:39.514174 (Thread-1): Postgres error: column "userid" specified more than once

2021-05-12 17:25:39.514357 (Thread-1): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-12 17:25:39.514617 (Thread-1): finished collecting timing info
2021-05-12 17:25:39.514754 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:25:39.515095 (Thread-1): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  column "userid" specified more than once
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.DuplicateColumn: column "userid" specified more than once


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  column "userid" specified more than once
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:25:39.522953 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d825681-7aad-41ec-86d2-8c97cea26f79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8babe0>]}
2021-05-12 17:25:39.523306 (Thread-1): 13:25:39 | 1 of 1 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.06s]
2021-05-12 17:25:39.523447 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:25:39.524590 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:25:39.524733 (MainThread): Using postgres connection "master".
2021-05-12 17:25:39.524820 (MainThread): On master: BEGIN
2021-05-12 17:25:39.524910 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:25:39.533010 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:25:39.533190 (MainThread): On master: COMMIT
2021-05-12 17:25:39.533284 (MainThread): Using postgres connection "master".
2021-05-12 17:25:39.533372 (MainThread): On master: COMMIT
2021-05-12 17:25:39.533606 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:25:39.533744 (MainThread): On master: Close
2021-05-12 17:25:39.534075 (MainThread): 13:25:39 | 
2021-05-12 17:25:39.534207 (MainThread): 13:25:39 | Finished running 1 table model in 0.21s.
2021-05-12 17:25:39.534313 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:25:39.534392 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:25:39.538165 (MainThread): 
2021-05-12 17:25:39.538319 (MainThread): Completed with 1 error and 0 warnings:
2021-05-12 17:25:39.538434 (MainThread): 
2021-05-12 17:25:39.538545 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-12 17:25:39.538674 (MainThread):   column "userid" specified more than once
2021-05-12 17:25:39.538765 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-12 17:25:39.538864 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-05-12 17:25:39.539034 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0e0a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d18bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ed7760>]}
2021-05-12 17:25:39.539221 (MainThread): Flushing usage events
2021-05-12 17:26:02.856612 (MainThread): Running with dbt=0.19.1
2021-05-12 17:26:02.938610 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-12 17:26:02.939760 (MainThread): Tracking: tracking
2021-05-12 17:26:02.956396 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afacca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af9f580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af9f7c0>]}
2021-05-12 17:26:02.970950 (MainThread): Partial parsing not enabled
2021-05-12 17:26:02.972448 (MainThread): Parsing macros/catalog.sql
2021-05-12 17:26:02.977054 (MainThread): Parsing macros/relations.sql
2021-05-12 17:26:02.979184 (MainThread): Parsing macros/adapters.sql
2021-05-12 17:26:03.001423 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-12 17:26:03.004696 (MainThread): Parsing macros/core.sql
2021-05-12 17:26:03.009157 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-12 17:26:03.018727 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-12 17:26:03.021075 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-12 17:26:03.040724 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-12 17:26:03.079143 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-12 17:26:03.101500 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-12 17:26:03.103838 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-12 17:26:03.110700 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-12 17:26:03.125585 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-12 17:26:03.133009 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-12 17:26:03.140104 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-12 17:26:03.145683 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-12 17:26:03.146875 (MainThread): Parsing macros/etc/query.sql
2021-05-12 17:26:03.148103 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-12 17:26:03.150001 (MainThread): Parsing macros/etc/datetime.sql
2021-05-12 17:26:03.159243 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-12 17:26:03.161472 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-12 17:26:03.163378 (MainThread): Parsing macros/adapters/common.sql
2021-05-12 17:26:03.208213 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-12 17:26:03.210296 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-12 17:26:03.212044 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-12 17:26:03.214013 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-12 17:26:03.221759 (MainThread): Partial parsing not enabled
2021-05-12 17:26:03.275786 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.330835 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59c4b030-cee3-415c-a82d-5a272c52878c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b16d610>]}
2021-05-12 17:26:03.334532 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59c4b030-cee3-415c-a82d-5a272c52878c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0eb6a0>]}
2021-05-12 17:26:03.334760 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-12 17:26:03.335347 (MainThread): 
2021-05-12 17:26:03.335662 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:26:03.336332 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-12 17:26:03.347076 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-12 17:26:03.347231 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-12 17:26:03.347337 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-12 17:26:03.383622 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-12 17:26:03.386723 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-12 17:26:03.388028 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:26:03.397336 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:26:03.397503 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-12 17:26:03.397623 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-12 17:26:03.406749 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:26:03.406922 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-12 17:26:03.407022 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-12 17:26:03.410147 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-05-12 17:26:03.410911 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-12 17:26:03.411171 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-12 17:26:03.415661 (MainThread): Using postgres connection "master".
2021-05-12 17:26:03.415801 (MainThread): On master: BEGIN
2021-05-12 17:26:03.415913 (MainThread): Opening a new connection, currently in state init
2021-05-12 17:26:03.425402 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:26:03.425582 (MainThread): Using postgres connection "master".
2021-05-12 17:26:03.425683 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-12 17:26:03.432643 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-12 17:26:03.433316 (MainThread): On master: ROLLBACK
2021-05-12 17:26:03.433606 (MainThread): Using postgres connection "master".
2021-05-12 17:26:03.433730 (MainThread): On master: BEGIN
2021-05-12 17:26:03.434083 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:26:03.434232 (MainThread): On master: COMMIT
2021-05-12 17:26:03.434343 (MainThread): Using postgres connection "master".
2021-05-12 17:26:03.434436 (MainThread): On master: COMMIT
2021-05-12 17:26:03.434661 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:26:03.434810 (MainThread): On master: Close
2021-05-12 17:26:03.435209 (MainThread): 13:26:03 | Concurrency: 4 threads (target='dev')
2021-05-12 17:26:03.435365 (MainThread): 13:26:03 | 
2021-05-12 17:26:03.437836 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-12 17:26:03.438156 (Thread-1): 13:26:03 | 1 of 1 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-12 17:26:03.438605 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.438764 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-12 17:26:03.440191 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:26:03.441296 (Thread-1): finished collecting timing info
2021-05-12 17:26:03.473718 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.474034 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-12 17:26:03.474214 (Thread-1): Opening a new connection, currently in state closed
2021-05-12 17:26:03.490061 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-12 17:26:03.493878 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.494085 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:26:03.494505 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:26:03.507716 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-12 17:26:03.508256 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.508375 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-12 17:26:03.508743 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-12 17:26:03.508880 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.508983 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-12 17:26:03.550767 (Thread-1): SQL status: SELECT 495 in 0.04 seconds
2021-05-12 17:26:03.561297 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.561568 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-12 17:26:03.565722 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-12 17:26:03.576293 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-12 17:26:03.576468 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.576572 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-12 17:26:03.577193 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:26:03.580976 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-12 17:26:03.581135 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-12 17:26:03.581537 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-12 17:26:03.583000 (Thread-1): finished collecting timing info
2021-05-12 17:26:03.583182 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-12 17:26:03.583585 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59c4b030-cee3-415c-a82d-5a272c52878c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7df310>]}
2021-05-12 17:26:03.583924 (Thread-1): 13:26:03 | 1 of 1 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.15s]
2021-05-12 17:26:03.584077 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-12 17:26:03.585388 (MainThread): Acquiring new postgres connection "master".
2021-05-12 17:26:03.585558 (MainThread): Using postgres connection "master".
2021-05-12 17:26:03.585659 (MainThread): On master: BEGIN
2021-05-12 17:26:03.585765 (MainThread): Opening a new connection, currently in state closed
2021-05-12 17:26:03.595458 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-12 17:26:03.595758 (MainThread): On master: COMMIT
2021-05-12 17:26:03.595895 (MainThread): Using postgres connection "master".
2021-05-12 17:26:03.596001 (MainThread): On master: COMMIT
2021-05-12 17:26:03.596244 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-12 17:26:03.596435 (MainThread): On master: Close
2021-05-12 17:26:03.596866 (MainThread): 13:26:03 | 
2021-05-12 17:26:03.597028 (MainThread): 13:26:03 | Finished running 1 table model in 0.26s.
2021-05-12 17:26:03.597198 (MainThread): Connection 'master' was properly closed.
2021-05-12 17:26:03.597316 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-12 17:26:03.601709 (MainThread): 
2021-05-12 17:26:03.601887 (MainThread): Completed successfully
2021-05-12 17:26:03.602100 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-05-12 17:26:03.602442 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7a4370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b09c5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b017160>]}
2021-05-12 17:26:03.602723 (MainThread): Flushing usage events
2021-05-13 19:52:07.203163 (MainThread): Running with dbt=0.19.1
2021-05-13 19:52:07.316181 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-13 19:52:07.317794 (MainThread): Tracking: tracking
2021-05-13 19:52:07.344451 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11138d730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113a9670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113a9eb0>]}
2021-05-13 19:52:07.359632 (MainThread): Partial parsing not enabled
2021-05-13 19:52:07.361186 (MainThread): Parsing macros/catalog.sql
2021-05-13 19:52:07.366506 (MainThread): Parsing macros/relations.sql
2021-05-13 19:52:07.368947 (MainThread): Parsing macros/adapters.sql
2021-05-13 19:52:07.395469 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-13 19:52:07.399392 (MainThread): Parsing macros/core.sql
2021-05-13 19:52:07.404849 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-13 19:52:07.416258 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-13 19:52:07.418638 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-13 19:52:07.442247 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-13 19:52:07.477206 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-13 19:52:07.499271 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-13 19:52:07.501525 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-13 19:52:07.508477 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-13 19:52:07.523358 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-13 19:52:07.530629 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-13 19:52:07.537736 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-13 19:52:07.543630 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-13 19:52:07.545286 (MainThread): Parsing macros/etc/query.sql
2021-05-13 19:52:07.546716 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-13 19:52:07.548838 (MainThread): Parsing macros/etc/datetime.sql
2021-05-13 19:52:07.559860 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-13 19:52:07.562162 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-13 19:52:07.564050 (MainThread): Parsing macros/adapters/common.sql
2021-05-13 19:52:07.608241 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-13 19:52:07.610478 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-13 19:52:07.612451 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-13 19:52:07.614580 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-13 19:52:07.623067 (MainThread): Partial parsing not enabled
2021-05-13 19:52:07.679132 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:07.691544 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:07.744531 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '763ea836-f529-49c2-ad86-757bbc6557fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111593b50>]}
2021-05-13 19:52:07.750520 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '763ea836-f529-49c2-ad86-757bbc6557fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116520a0>]}
2021-05-13 19:52:07.750807 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-13 19:52:07.751417 (MainThread): 
2021-05-13 19:52:07.751732 (MainThread): Acquiring new postgres connection "master".
2021-05-13 19:52:07.752561 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-13 19:52:07.763319 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-13 19:52:07.763492 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-13 19:52:07.763613 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-13 19:52:07.852981 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.09 seconds
2021-05-13 19:52:07.856093 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-13 19:52:07.857254 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-13 19:52:07.863369 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-13 19:52:07.863555 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-13 19:52:07.863665 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-13 19:52:07.871309 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-13 19:52:07.871447 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-13 19:52:07.871523 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-13 19:52:07.885079 (ThreadPoolExecutor-1_0): SQL status: SELECT 4 in 0.01 seconds
2021-05-13 19:52:07.885667 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-13 19:52:07.885869 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-13 19:52:07.889863 (MainThread): Using postgres connection "master".
2021-05-13 19:52:07.889992 (MainThread): On master: BEGIN
2021-05-13 19:52:07.890081 (MainThread): Opening a new connection, currently in state init
2021-05-13 19:52:07.897228 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-13 19:52:07.897368 (MainThread): Using postgres connection "master".
2021-05-13 19:52:07.897448 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-13 19:52:07.910258 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-13 19:52:07.910780 (MainThread): On master: ROLLBACK
2021-05-13 19:52:07.910989 (MainThread): Using postgres connection "master".
2021-05-13 19:52:07.911076 (MainThread): On master: BEGIN
2021-05-13 19:52:07.911306 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-13 19:52:07.911400 (MainThread): On master: COMMIT
2021-05-13 19:52:07.911480 (MainThread): Using postgres connection "master".
2021-05-13 19:52:07.911552 (MainThread): On master: COMMIT
2021-05-13 19:52:07.911711 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-13 19:52:07.911824 (MainThread): On master: Close
2021-05-13 19:52:07.912158 (MainThread): 15:52:07 | Concurrency: 4 threads (target='dev')
2021-05-13 19:52:07.912380 (MainThread): 15:52:07 | 
2021-05-13 19:52:07.914782 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-13 19:52:07.915027 (Thread-1): 15:52:07 | 1 of 2 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-13 19:52:07.915305 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:07.915419 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-13 19:52:07.916567 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-13 19:52:07.916775 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-13 19:52:07.917006 (Thread-2): 15:52:07 | 2 of 2 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-13 19:52:07.917306 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:07.917416 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-13 19:52:07.918390 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-13 19:52:07.918678 (Thread-1): finished collecting timing info
2021-05-13 19:52:07.935585 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:07.935724 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-13 19:52:07.935815 (Thread-1): Opening a new connection, currently in state closed
2021-05-13 19:52:07.936015 (Thread-2): finished collecting timing info
2021-05-13 19:52:07.938189 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:07.938325 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-13 19:52:07.938414 (Thread-2): Opening a new connection, currently in state init
2021-05-13 19:52:07.945752 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-13 19:52:07.947962 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:07.948127 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-13 19:52:07.948246 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-13 19:52:07.950015 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:07.950231 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-13 19:52:07.950391 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-13 19:52:07.955800 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-13 19:52:07.965514 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-13 19:52:07.966041 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-13 19:52:07.966415 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:07.966510 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-13 19:52:07.966659 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:07.966755 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-13 19:52:07.966874 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-13 19:52:07.967015 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-13 19:52:07.967101 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:07.967212 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:07.967319 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as brandId,
json_extract_path (to_json(json_txt), 'barcode') as barcode,
json_extract_path (to_json(json_txt), 'category') as category,
json_extract_path (to_json(json_txt), 'categoryCode') as categoryCode,
json_extract_path (to_json(json_txt), 'cpg', '$id', '$oid') as cpgId,
json_extract_path (to_json(json_txt), 'cpg', '$ref') as cpgRef,
json_extract_path (to_json(json_txt), 'name') as brandName,
json_extract_path (to_json(json_txt), 'brandCode') as brandCode,
json_extract_path (to_json(json_txt), 'topBrand') as topBrand
from fetch_takehome.users
  );
2021-05-13 19:52:07.967411 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-13 19:52:08.011692 (Thread-2): SQL status: SELECT 495 in 0.04 seconds
2021-05-13 19:52:08.017771 (Thread-1): SQL status: SELECT 495 in 0.05 seconds
2021-05-13 19:52:08.018174 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:08.019967 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:08.020175 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-13 19:52:08.020084 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-13 19:52:08.024274 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-13 19:52:08.027053 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:08.027165 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-13 19:52:08.027285 (Thread-1): SQL status: ALTER TABLE in 0.01 seconds
2021-05-13 19:52:08.033246 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-13 19:52:08.033370 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:08.033451 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-13 19:52:08.033573 (Thread-2): SQL status: ALTER TABLE in 0.01 seconds
2021-05-13 19:52:08.034500 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-13 19:52:08.034621 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-13 19:52:08.034704 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:08.037651 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:52:08.037806 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-13 19:52:08.037905 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-13 19:52:08.038262 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-13 19:52:08.039188 (Thread-1): finished collecting timing info
2021-05-13 19:52:08.039314 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-13 19:52:08.039445 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-13 19:52:08.040683 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:52:08.041021 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '763ea836-f529-49c2-ad86-757bbc6557fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11175c3a0>]}
2021-05-13 19:52:08.041135 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-13 19:52:08.041468 (Thread-1): 15:52:08 | 1 of 2 OK created table model fetch_takehome.brands_json_extract..... [SELECT 495 in 0.13s]
2021-05-13 19:52:08.041679 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-13 19:52:08.052233 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-13 19:52:08.053273 (Thread-2): finished collecting timing info
2021-05-13 19:52:08.053404 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-13 19:52:08.053735 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '763ea836-f529-49c2-ad86-757bbc6557fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114a06a0>]}
2021-05-13 19:52:08.053996 (Thread-2): 15:52:08 | 2 of 2 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.14s]
2021-05-13 19:52:08.054112 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-13 19:52:08.055340 (MainThread): Acquiring new postgres connection "master".
2021-05-13 19:52:08.055468 (MainThread): Using postgres connection "master".
2021-05-13 19:52:08.055547 (MainThread): On master: BEGIN
2021-05-13 19:52:08.055628 (MainThread): Opening a new connection, currently in state closed
2021-05-13 19:52:08.062648 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-13 19:52:08.062797 (MainThread): On master: COMMIT
2021-05-13 19:52:08.062876 (MainThread): Using postgres connection "master".
2021-05-13 19:52:08.062950 (MainThread): On master: COMMIT
2021-05-13 19:52:08.063109 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-13 19:52:08.063208 (MainThread): On master: Close
2021-05-13 19:52:08.063529 (MainThread): 15:52:08 | 
2021-05-13 19:52:08.063639 (MainThread): 15:52:08 | Finished running 2 table models in 0.31s.
2021-05-13 19:52:08.063726 (MainThread): Connection 'master' was properly closed.
2021-05-13 19:52:08.063793 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-13 19:52:08.063868 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-13 19:52:08.067287 (MainThread): 
2021-05-13 19:52:08.067426 (MainThread): Completed successfully
2021-05-13 19:52:08.067568 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-13 19:52:08.067741 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108de1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108dec70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108de850>]}
2021-05-13 19:52:08.067907 (MainThread): Flushing usage events
2021-05-13 19:58:19.644536 (MainThread): Running with dbt=0.19.1
2021-05-13 19:58:19.749393 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-13 19:58:19.750630 (MainThread): Tracking: tracking
2021-05-13 19:58:19.769618 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ded30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065fc580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065fc7c0>]}
2021-05-13 19:58:19.783989 (MainThread): Partial parsing not enabled
2021-05-13 19:58:19.785450 (MainThread): Parsing macros/catalog.sql
2021-05-13 19:58:19.790007 (MainThread): Parsing macros/relations.sql
2021-05-13 19:58:19.792140 (MainThread): Parsing macros/adapters.sql
2021-05-13 19:58:19.815319 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-13 19:58:19.819168 (MainThread): Parsing macros/core.sql
2021-05-13 19:58:19.824561 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-13 19:58:19.835695 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-13 19:58:19.838043 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-13 19:58:19.859148 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-13 19:58:19.893378 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-13 19:58:19.914847 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-13 19:58:19.917333 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-13 19:58:19.924670 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-13 19:58:19.940271 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-13 19:58:19.947416 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-13 19:58:19.954464 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-13 19:58:19.959891 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-13 19:58:19.960922 (MainThread): Parsing macros/etc/query.sql
2021-05-13 19:58:19.962152 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-13 19:58:19.963986 (MainThread): Parsing macros/etc/datetime.sql
2021-05-13 19:58:19.972965 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-13 19:58:19.975252 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-13 19:58:19.977157 (MainThread): Parsing macros/adapters/common.sql
2021-05-13 19:58:20.020836 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-13 19:58:20.022969 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-13 19:58:20.024653 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-13 19:58:20.026435 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-13 19:58:20.034473 (MainThread): Partial parsing not enabled
2021-05-13 19:58:20.091163 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.103605 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.157094 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cfc4cbc4-5346-4a81-b01e-29a45ce3fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066fba00>]}
2021-05-13 19:58:20.161262 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cfc4cbc4-5346-4a81-b01e-29a45ce3fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d7730>]}
2021-05-13 19:58:20.161483 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-13 19:58:20.161997 (MainThread): 
2021-05-13 19:58:20.162265 (MainThread): Acquiring new postgres connection "master".
2021-05-13 19:58:20.162936 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-13 19:58:20.172219 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-13 19:58:20.172331 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-13 19:58:20.172434 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-13 19:58:20.223848 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.05 seconds
2021-05-13 19:58:20.226883 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-13 19:58:20.227941 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-13 19:58:20.234437 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-13 19:58:20.234580 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-13 19:58:20.234694 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-13 19:58:20.243329 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-13 19:58:20.243509 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-13 19:58:20.243607 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-13 19:58:20.246569 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.00 seconds
2021-05-13 19:58:20.247333 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-13 19:58:20.247614 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-13 19:58:20.252224 (MainThread): Using postgres connection "master".
2021-05-13 19:58:20.252376 (MainThread): On master: BEGIN
2021-05-13 19:58:20.252488 (MainThread): Opening a new connection, currently in state init
2021-05-13 19:58:20.260928 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-13 19:58:20.261093 (MainThread): Using postgres connection "master".
2021-05-13 19:58:20.261194 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-13 19:58:20.269966 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-13 19:58:20.270511 (MainThread): On master: ROLLBACK
2021-05-13 19:58:20.270711 (MainThread): Using postgres connection "master".
2021-05-13 19:58:20.270796 (MainThread): On master: BEGIN
2021-05-13 19:58:20.271025 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-13 19:58:20.271120 (MainThread): On master: COMMIT
2021-05-13 19:58:20.271202 (MainThread): Using postgres connection "master".
2021-05-13 19:58:20.271273 (MainThread): On master: COMMIT
2021-05-13 19:58:20.271426 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-13 19:58:20.271523 (MainThread): On master: Close
2021-05-13 19:58:20.271776 (MainThread): 15:58:20 | Concurrency: 4 threads (target='dev')
2021-05-13 19:58:20.271889 (MainThread): 15:58:20 | 
2021-05-13 19:58:20.273907 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-13 19:58:20.274147 (Thread-1): 15:58:20 | 1 of 2 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-13 19:58:20.274407 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.274631 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-13 19:58:20.274744 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-13 19:58:20.275800 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-13 19:58:20.275980 (Thread-2): 15:58:20 | 2 of 2 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-13 19:58:20.276380 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.276623 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-13 19:58:20.277601 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-13 19:58:20.277793 (Thread-1): finished collecting timing info
2021-05-13 19:58:20.294482 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.294617 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-13 19:58:20.294750 (Thread-2): finished collecting timing info
2021-05-13 19:58:20.294846 (Thread-1): Opening a new connection, currently in state closed
2021-05-13 19:58:20.296811 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.297078 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-13 19:58:20.297174 (Thread-2): Opening a new connection, currently in state init
2021-05-13 19:58:20.306328 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-13 19:58:20.310010 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.310237 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-13 19:58:20.310596 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-13 19:58:20.316077 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-13 19:58:20.323424 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.325082 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-13 19:58:20.325193 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-13 19:58:20.325722 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.325853 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-13 19:58:20.326004 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-13 19:58:20.327168 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-13 19:58:20.327538 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-13 19:58:20.327663 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.327743 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-13 19:58:20.327970 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.328066 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-13 19:58:20.328278 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-13 19:58:20.328376 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.328450 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as brandId,
json_extract_path (to_json(json_txt), 'barcode') as barcode,
json_extract_path (to_json(json_txt), 'category') as category,
json_extract_path (to_json(json_txt), 'categoryCode') as categoryCode,
json_extract_path (to_json(json_txt), 'cpg', '$id', '$oid') as cpgId,
json_extract_path (to_json(json_txt), 'cpg', '$ref') as cpgRef,
json_extract_path (to_json(json_txt), 'name') as brandName,
json_extract_path (to_json(json_txt), 'brandCode') as brandCode,
json_extract_path (to_json(json_txt), 'topBrand') as topBrand
from fetch_takehome.brands
  );
2021-05-13 19:58:20.355618 (Thread-2): SQL status: SELECT 495 in 0.03 seconds
2021-05-13 19:58:20.361219 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.361336 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-13 19:58:20.363628 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-13 19:58:20.365282 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.365371 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-13 19:58:20.365731 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-13 19:58:20.372736 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-13 19:58:20.372863 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.372941 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-13 19:58:20.388932 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-13 19:58:20.390762 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.390854 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-13 19:58:20.391222 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-13 19:58:20.392954 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.393046 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-13 19:58:20.393432 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-13 19:58:20.394301 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-13 19:58:20.394391 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.394465 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-13 19:58:20.402254 (Thread-2): SQL status: COMMIT in 0.03 seconds
2021-05-13 19:58:20.404947 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-13 19:58:20.405052 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-13 19:58:20.405159 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-05-13 19:58:20.406467 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-13 19:58:20.406631 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-13 19:58:20.407584 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-13 19:58:20.408673 (Thread-2): finished collecting timing info
2021-05-13 19:58:20.408853 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-13 19:58:20.408981 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-13 19:58:20.409373 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfc4cbc4-5346-4a81-b01e-29a45ce3fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e3af40>]}
2021-05-13 19:58:20.410355 (Thread-1): finished collecting timing info
2021-05-13 19:58:20.410665 (Thread-2): 15:58:20 | 2 of 2 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.13s]
2021-05-13 19:58:20.410777 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-13 19:58:20.410995 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-13 19:58:20.411300 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfc4cbc4-5346-4a81-b01e-29a45ce3fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ec310>]}
2021-05-13 19:58:20.411656 (Thread-1): 15:58:20 | 1 of 2 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.14s]
2021-05-13 19:58:20.411763 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-13 19:58:20.412751 (MainThread): Acquiring new postgres connection "master".
2021-05-13 19:58:20.412871 (MainThread): Using postgres connection "master".
2021-05-13 19:58:20.412945 (MainThread): On master: BEGIN
2021-05-13 19:58:20.413023 (MainThread): Opening a new connection, currently in state closed
2021-05-13 19:58:20.420101 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-13 19:58:20.420251 (MainThread): On master: COMMIT
2021-05-13 19:58:20.420333 (MainThread): Using postgres connection "master".
2021-05-13 19:58:20.420406 (MainThread): On master: COMMIT
2021-05-13 19:58:20.420573 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-13 19:58:20.420670 (MainThread): On master: Close
2021-05-13 19:58:20.420966 (MainThread): 15:58:20 | 
2021-05-13 19:58:20.421087 (MainThread): 15:58:20 | Finished running 2 table models in 0.26s.
2021-05-13 19:58:20.421197 (MainThread): Connection 'master' was properly closed.
2021-05-13 19:58:20.421281 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-13 19:58:20.421358 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-13 19:58:20.424654 (MainThread): 
2021-05-13 19:58:20.424785 (MainThread): Completed successfully
2021-05-13 19:58:20.424894 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-13 19:58:20.425044 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e35520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e35880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106713a30>]}
2021-05-13 19:58:20.425198 (MainThread): Flushing usage events
2021-05-14 18:50:50.144168 (MainThread): Running with dbt=0.19.1
2021-05-14 18:50:50.258955 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-14 18:50:50.259976 (MainThread): Tracking: tracking
2021-05-14 18:50:50.283604 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10664bd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066675e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106667e20>]}
2021-05-14 18:50:50.298864 (MainThread): Partial parsing not enabled
2021-05-14 18:50:50.300445 (MainThread): Parsing macros/catalog.sql
2021-05-14 18:50:50.305649 (MainThread): Parsing macros/relations.sql
2021-05-14 18:50:50.308213 (MainThread): Parsing macros/adapters.sql
2021-05-14 18:50:50.333903 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-14 18:50:50.338512 (MainThread): Parsing macros/core.sql
2021-05-14 18:50:50.344254 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-14 18:50:50.356351 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-14 18:50:50.358916 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-14 18:50:50.383067 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-14 18:50:50.420975 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-14 18:50:50.443156 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-14 18:50:50.445663 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-14 18:50:50.453159 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-14 18:50:50.468571 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-14 18:50:50.476510 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-14 18:50:50.484428 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-14 18:50:50.490348 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-14 18:50:50.491866 (MainThread): Parsing macros/etc/query.sql
2021-05-14 18:50:50.493316 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-14 18:50:50.495276 (MainThread): Parsing macros/etc/datetime.sql
2021-05-14 18:50:50.504518 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-14 18:50:50.507062 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-14 18:50:50.509042 (MainThread): Parsing macros/adapters/common.sql
2021-05-14 18:50:50.554139 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-14 18:50:50.556439 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-14 18:50:50.558472 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-14 18:50:50.560685 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-14 18:50:50.568993 (MainThread): Partial parsing not enabled
2021-05-14 18:50:50.622363 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:50:50.635218 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.684600 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '047774c0-e7e5-4b2e-a0d1-941cf5ef1c52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a6760>]}
2021-05-14 18:50:50.689001 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '047774c0-e7e5-4b2e-a0d1-941cf5ef1c52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106843550>]}
2021-05-14 18:50:50.689292 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-14 18:50:50.689785 (MainThread): 
2021-05-14 18:50:50.690037 (MainThread): Acquiring new postgres connection "master".
2021-05-14 18:50:50.690741 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-14 18:50:50.699698 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-14 18:50:50.699799 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-14 18:50:50.699883 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-14 18:50:50.795716 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.10 seconds
2021-05-14 18:50:50.798756 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-14 18:50:50.799628 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:50:50.804662 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:50:50.804778 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-14 18:50:50.804868 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-14 18:50:50.812171 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:50:50.812317 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:50:50.812399 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-14 18:50:50.820478 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.01 seconds
2021-05-14 18:50:50.821074 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-14 18:50:50.821617 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-14 18:50:50.825330 (MainThread): Using postgres connection "master".
2021-05-14 18:50:50.825442 (MainThread): On master: BEGIN
2021-05-14 18:50:50.825527 (MainThread): Opening a new connection, currently in state init
2021-05-14 18:50:50.832260 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:50:50.832404 (MainThread): Using postgres connection "master".
2021-05-14 18:50:50.832487 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-14 18:50:50.847867 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-14 18:50:50.848381 (MainThread): On master: ROLLBACK
2021-05-14 18:50:50.848569 (MainThread): Using postgres connection "master".
2021-05-14 18:50:50.848653 (MainThread): On master: BEGIN
2021-05-14 18:50:50.848874 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:50:50.848966 (MainThread): On master: COMMIT
2021-05-14 18:50:50.849041 (MainThread): Using postgres connection "master".
2021-05-14 18:50:50.849109 (MainThread): On master: COMMIT
2021-05-14 18:50:50.849252 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:50:50.849343 (MainThread): On master: Close
2021-05-14 18:50:50.849585 (MainThread): 14:50:50 | Concurrency: 4 threads (target='dev')
2021-05-14 18:50:50.849695 (MainThread): 14:50:50 | 
2021-05-14 18:50:50.851746 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-14 18:50:50.851981 (Thread-1): 14:50:50 | 1 of 2 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-14 18:50:50.852233 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:50:50.852452 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-14 18:50:50.853468 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 18:50:50.853667 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-14 18:50:50.853868 (Thread-2): 14:50:50 | 2 of 2 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-14 18:50:50.854158 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.854270 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-14 18:50:50.855220 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 18:50:50.855481 (Thread-1): finished collecting timing info
2021-05-14 18:50:50.872237 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:50:50.872371 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-14 18:50:50.872461 (Thread-1): Opening a new connection, currently in state closed
2021-05-14 18:50:50.872689 (Thread-2): finished collecting timing info
2021-05-14 18:50:50.875120 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.875260 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-14 18:50:50.875354 (Thread-2): Opening a new connection, currently in state init
2021-05-14 18:50:50.898947 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 18:50:50.900869 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.900973 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 18:50:50.901100 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2021-05-14 18:50:50.901199 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:50:50.902634 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:50:50.912612 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 18:50:50.912710 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 18:50:50.913086 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:50:50.914113 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 18:50:50.914511 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.914605 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-14 18:50:50.914753 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:50:50.914855 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:50:50.914935 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-14 18:50:50.915026 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.915164 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-14 18:50:50.915265 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:50:50.915403 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:50:50.915483 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned') as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason') as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date') as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date') as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date') as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date') as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date') as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned') as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date') as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount') as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList') as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus') as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent') as totalSpent,
json_extract_path (to_json(json_txt), 'userId') as userId,
from fetch_takehome.receipts
  );
2021-05-14 18:50:50.919927 (Thread-1): Postgres error: syntax error at or near "from"
LINE 22: from fetch_takehome.receipts
         ^

2021-05-14 18:50:50.920042 (Thread-1): On model.fetch_takehome.brands_json_extract: ROLLBACK
2021-05-14 18:50:50.920266 (Thread-1): finished collecting timing info
2021-05-14 18:50:50.920401 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-14 18:50:50.920728 (Thread-1): Database Error in model brands_json_extract (models/json_extract/brands_json_extract.sql)
  syntax error at or near "from"
  LINE 22: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/brands_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 22: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model brands_json_extract (models/json_extract/brands_json_extract.sql)
  syntax error at or near "from"
  LINE 22: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/brands_json_extract.sql
2021-05-14 18:50:50.927636 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '047774c0-e7e5-4b2e-a0d1-941cf5ef1c52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105deae20>]}
2021-05-14 18:50:50.927929 (Thread-1): 14:50:50 | 1 of 2 ERROR creating table model fetch_takehome.brands_json_extract. [ERROR in 0.08s]
2021-05-14 18:50:50.928052 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-14 18:50:50.958553 (Thread-2): SQL status: SELECT 495 in 0.04 seconds
2021-05-14 18:50:50.964970 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.965112 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-14 18:50:50.993854 (Thread-2): SQL status: ALTER TABLE in 0.03 seconds
2021-05-14 18:50:50.995681 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:50.995787 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-14 18:50:50.996147 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:50:51.003398 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 18:50:51.003522 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:51.003603 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 18:50:51.004087 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:50:51.006631 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:50:51.006730 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 18:50:51.019482 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 18:50:51.020544 (Thread-2): finished collecting timing info
2021-05-14 18:50:51.020678 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-14 18:50:51.020975 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '047774c0-e7e5-4b2e-a0d1-941cf5ef1c52', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c8e50>]}
2021-05-14 18:50:51.021227 (Thread-2): 14:50:51 | 2 of 2 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.17s]
2021-05-14 18:50:51.021343 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-14 18:50:51.022361 (MainThread): Acquiring new postgres connection "master".
2021-05-14 18:50:51.022527 (MainThread): Using postgres connection "master".
2021-05-14 18:50:51.022616 (MainThread): On master: BEGIN
2021-05-14 18:50:51.022699 (MainThread): Opening a new connection, currently in state closed
2021-05-14 18:50:51.029455 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:50:51.029616 (MainThread): On master: COMMIT
2021-05-14 18:50:51.029704 (MainThread): Using postgres connection "master".
2021-05-14 18:50:51.029780 (MainThread): On master: COMMIT
2021-05-14 18:50:51.029965 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:50:51.030085 (MainThread): On master: Close
2021-05-14 18:50:51.030381 (MainThread): 14:50:51 | 
2021-05-14 18:50:51.030495 (MainThread): 14:50:51 | Finished running 2 table models in 0.34s.
2021-05-14 18:50:51.030587 (MainThread): Connection 'master' was properly closed.
2021-05-14 18:50:51.030656 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-14 18:50:51.030722 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-14 18:50:51.034137 (MainThread): 
2021-05-14 18:50:51.034272 (MainThread): Completed with 1 error and 0 warnings:
2021-05-14 18:50:51.034373 (MainThread): 
2021-05-14 18:50:51.034469 (MainThread): Database Error in model brands_json_extract (models/json_extract/brands_json_extract.sql)
2021-05-14 18:50:51.034553 (MainThread):   syntax error at or near "from"
2021-05-14 18:50:51.034637 (MainThread):   LINE 22: from fetch_takehome.receipts
2021-05-14 18:50:51.034714 (MainThread):            ^
2021-05-14 18:50:51.034814 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/brands_json_extract.sql
2021-05-14 18:50:51.034904 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2021-05-14 18:50:51.035051 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c5370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c5880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c54f0>]}
2021-05-14 18:50:51.035215 (MainThread): Flushing usage events
2021-05-14 18:51:05.296542 (MainThread): Running with dbt=0.19.1
2021-05-14 18:51:05.404439 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-14 18:51:05.405663 (MainThread): Tracking: tracking
2021-05-14 18:51:05.424625 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5e11f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5fe640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5fee80>]}
2021-05-14 18:51:05.438774 (MainThread): Partial parsing not enabled
2021-05-14 18:51:05.440273 (MainThread): Parsing macros/catalog.sql
2021-05-14 18:51:05.444934 (MainThread): Parsing macros/relations.sql
2021-05-14 18:51:05.447145 (MainThread): Parsing macros/adapters.sql
2021-05-14 18:51:05.470759 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-14 18:51:05.474088 (MainThread): Parsing macros/core.sql
2021-05-14 18:51:05.478573 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-14 18:51:05.488277 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-14 18:51:05.490271 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-14 18:51:05.510001 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-14 18:51:05.544660 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-14 18:51:05.566982 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-14 18:51:05.569120 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-14 18:51:05.575956 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-14 18:51:05.591087 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-14 18:51:05.598495 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-14 18:51:05.605498 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-14 18:51:05.611007 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-14 18:51:05.612253 (MainThread): Parsing macros/etc/query.sql
2021-05-14 18:51:05.613507 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-14 18:51:05.615343 (MainThread): Parsing macros/etc/datetime.sql
2021-05-14 18:51:05.624778 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-14 18:51:05.626924 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-14 18:51:05.628811 (MainThread): Parsing macros/adapters/common.sql
2021-05-14 18:51:05.673653 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-14 18:51:05.675884 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-14 18:51:05.677746 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-14 18:51:05.679855 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-14 18:51:05.687918 (MainThread): Partial parsing not enabled
2021-05-14 18:51:05.743272 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:05.755870 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.804300 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f368343e-2a0c-4e11-b475-ede7c4d9585c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c718b20>]}
2021-05-14 18:51:05.808482 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f368343e-2a0c-4e11-b475-ede7c4d9585c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7da8b0>]}
2021-05-14 18:51:05.808696 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-14 18:51:05.809184 (MainThread): 
2021-05-14 18:51:05.809444 (MainThread): Acquiring new postgres connection "master".
2021-05-14 18:51:05.810116 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-14 18:51:05.818960 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-14 18:51:05.819079 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-14 18:51:05.819169 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-14 18:51:05.847085 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-14 18:51:05.850016 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-14 18:51:05.851009 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:51:05.857702 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:51:05.857844 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-14 18:51:05.857948 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-14 18:51:05.865981 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:51:05.866148 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:51:05.866244 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-14 18:51:05.869206 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.00 seconds
2021-05-14 18:51:05.869924 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-14 18:51:05.870131 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-14 18:51:05.874463 (MainThread): Using postgres connection "master".
2021-05-14 18:51:05.874591 (MainThread): On master: BEGIN
2021-05-14 18:51:05.874694 (MainThread): Opening a new connection, currently in state init
2021-05-14 18:51:05.882899 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:51:05.883060 (MainThread): Using postgres connection "master".
2021-05-14 18:51:05.883153 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-14 18:51:05.892060 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-14 18:51:05.892692 (MainThread): On master: ROLLBACK
2021-05-14 18:51:05.892912 (MainThread): Using postgres connection "master".
2021-05-14 18:51:05.893021 (MainThread): On master: BEGIN
2021-05-14 18:51:05.893280 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:51:05.893403 (MainThread): On master: COMMIT
2021-05-14 18:51:05.893500 (MainThread): Using postgres connection "master".
2021-05-14 18:51:05.893581 (MainThread): On master: COMMIT
2021-05-14 18:51:05.893759 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:51:05.893870 (MainThread): On master: Close
2021-05-14 18:51:05.894157 (MainThread): 14:51:05 | Concurrency: 4 threads (target='dev')
2021-05-14 18:51:05.894286 (MainThread): 14:51:05 | 
2021-05-14 18:51:05.896438 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-14 18:51:05.896711 (Thread-1): 14:51:05 | 1 of 2 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-14 18:51:05.896878 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-14 18:51:05.897354 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:05.897549 (Thread-2): 14:51:05 | 2 of 2 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-14 18:51:05.897684 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-14 18:51:05.898937 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 18:51:05.899302 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.899428 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-14 18:51:05.900550 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 18:51:05.900943 (Thread-1): finished collecting timing info
2021-05-14 18:51:05.906188 (Thread-2): finished collecting timing info
2021-05-14 18:51:05.933503 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.933644 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-14 18:51:05.933739 (Thread-2): Opening a new connection, currently in state init
2021-05-14 18:51:05.935932 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:05.936101 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-14 18:51:05.936230 (Thread-1): Opening a new connection, currently in state closed
2021-05-14 18:51:05.941532 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 18:51:05.943433 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.943609 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 18:51:05.943883 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:51:05.944000 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 18:51:05.950855 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:05.950957 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 18:51:05.955795 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 18:51:05.956010 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:51:05.957047 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 18:51:05.957396 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.957489 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-14 18:51:05.957632 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:05.957738 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-14 18:51:05.957854 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:51:05.957958 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.958037 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-14 18:51:05.958148 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:51:05.958246 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:05.958321 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned') as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason') as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date') as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date') as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date') as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date') as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date') as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned') as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date') as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount') as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList') as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus') as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent') as totalSpent,
json_extract_path (to_json(json_txt), 'userId') as userId
from fetch_takehome.receipts
  );
2021-05-14 18:51:05.974696 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-14 18:51:05.980028 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.980151 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-14 18:51:05.980516 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:51:05.983420 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.983531 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-14 18:51:05.983920 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:51:05.990061 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 18:51:05.990185 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.990264 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 18:51:05.990817 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:51:05.993452 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:51:05.993561 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 18:51:05.995157 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:51:05.996148 (Thread-2): finished collecting timing info
2021-05-14 18:51:05.996272 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-14 18:51:05.996565 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f368343e-2a0c-4e11-b475-ede7c4d9585c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c79a3a0>]}
2021-05-14 18:51:05.996816 (Thread-2): 14:51:05 | 2 of 2 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.10s]
2021-05-14 18:51:05.996929 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-14 18:51:06.659910 (Thread-1): SQL status: SELECT 1119 in 0.70 seconds
2021-05-14 18:51:06.662245 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:06.662368 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-14 18:51:06.663360 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:51:06.664995 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:06.665134 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-14 18:51:06.665514 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:51:06.666393 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 18:51:06.666486 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:06.666561 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 18:51:06.667259 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:51:06.668514 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:51:06.668623 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 18:51:06.673291 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:51:06.674213 (Thread-1): finished collecting timing info
2021-05-14 18:51:06.674338 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-14 18:51:06.674649 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f368343e-2a0c-4e11-b475-ede7c4d9585c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c702c70>]}
2021-05-14 18:51:06.674915 (Thread-1): 14:51:06 | 1 of 2 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1119 in 0.78s]
2021-05-14 18:51:06.675030 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-14 18:51:06.676306 (MainThread): Acquiring new postgres connection "master".
2021-05-14 18:51:06.676436 (MainThread): Using postgres connection "master".
2021-05-14 18:51:06.676557 (MainThread): On master: BEGIN
2021-05-14 18:51:06.676725 (MainThread): Opening a new connection, currently in state closed
2021-05-14 18:51:06.684351 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:51:06.684530 (MainThread): On master: COMMIT
2021-05-14 18:51:06.684620 (MainThread): Using postgres connection "master".
2021-05-14 18:51:06.684716 (MainThread): On master: COMMIT
2021-05-14 18:51:06.684949 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:51:06.685091 (MainThread): On master: Close
2021-05-14 18:51:06.685655 (MainThread): 14:51:06 | 
2021-05-14 18:51:06.685819 (MainThread): 14:51:06 | Finished running 2 table models in 0.88s.
2021-05-14 18:51:06.685938 (MainThread): Connection 'master' was properly closed.
2021-05-14 18:51:06.686030 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-14 18:51:06.686108 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-14 18:51:06.690322 (MainThread): 
2021-05-14 18:51:06.690507 (MainThread): Completed successfully
2021-05-14 18:51:06.690635 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-05-14 18:51:06.690871 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be42a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6f8550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beb7580>]}
2021-05-14 18:51:06.691083 (MainThread): Flushing usage events
2021-05-14 18:54:11.423969 (MainThread): Running with dbt=0.19.1
2021-05-14 18:54:11.592148 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-14 18:54:11.593267 (MainThread): Tracking: tracking
2021-05-14 18:54:11.611130 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d3fca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d615b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d61df0>]}
2021-05-14 18:54:11.626298 (MainThread): Partial parsing not enabled
2021-05-14 18:54:11.627805 (MainThread): Parsing macros/catalog.sql
2021-05-14 18:54:11.632563 (MainThread): Parsing macros/relations.sql
2021-05-14 18:54:11.634728 (MainThread): Parsing macros/adapters.sql
2021-05-14 18:54:11.664009 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-14 18:54:11.668416 (MainThread): Parsing macros/core.sql
2021-05-14 18:54:11.673766 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-14 18:54:11.686213 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-14 18:54:11.688702 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-14 18:54:11.713559 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-14 18:54:11.750567 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-14 18:54:11.772889 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-14 18:54:11.775027 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-14 18:54:11.781593 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-14 18:54:11.796223 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-14 18:54:11.804305 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-14 18:54:11.811774 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-14 18:54:11.817334 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-14 18:54:11.818463 (MainThread): Parsing macros/etc/query.sql
2021-05-14 18:54:11.819635 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-14 18:54:11.821477 (MainThread): Parsing macros/etc/datetime.sql
2021-05-14 18:54:11.830704 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-14 18:54:11.832986 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-14 18:54:11.834885 (MainThread): Parsing macros/adapters/common.sql
2021-05-14 18:54:11.880374 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-14 18:54:11.882481 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-14 18:54:11.884191 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-14 18:54:11.886168 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-14 18:54:11.893988 (MainThread): Partial parsing not enabled
2021-05-14 18:54:11.947902 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:11.960865 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:11.964274 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:12.037187 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5eeaeeb-77ac-4504-b4ee-2a03f6532d17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11058b880>]}
2021-05-14 18:54:12.046112 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c5eeaeeb-77ac-4504-b4ee-2a03f6532d17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f23df0>]}
2021-05-14 18:54:12.046642 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-14 18:54:12.047764 (MainThread): 
2021-05-14 18:54:12.048347 (MainThread): Acquiring new postgres connection "master".
2021-05-14 18:54:12.049944 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-14 18:54:12.063733 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-14 18:54:12.063908 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-14 18:54:12.064045 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-14 18:54:12.122795 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.06 seconds
2021-05-14 18:54:12.125824 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-14 18:54:12.126939 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:54:12.133445 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:54:12.133594 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-14 18:54:12.133706 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-14 18:54:12.143331 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:54:12.143517 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 18:54:12.143638 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-14 18:54:12.147385 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.00 seconds
2021-05-14 18:54:12.148118 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-14 18:54:12.148339 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-14 18:54:12.153221 (MainThread): Using postgres connection "master".
2021-05-14 18:54:12.153373 (MainThread): On master: BEGIN
2021-05-14 18:54:12.153480 (MainThread): Opening a new connection, currently in state init
2021-05-14 18:54:12.163697 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:54:12.163874 (MainThread): Using postgres connection "master".
2021-05-14 18:54:12.164026 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-14 18:54:12.175582 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-14 18:54:12.176238 (MainThread): On master: ROLLBACK
2021-05-14 18:54:12.176467 (MainThread): Using postgres connection "master".
2021-05-14 18:54:12.176577 (MainThread): On master: BEGIN
2021-05-14 18:54:12.176903 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:54:12.177075 (MainThread): On master: COMMIT
2021-05-14 18:54:12.177183 (MainThread): Using postgres connection "master".
2021-05-14 18:54:12.177306 (MainThread): On master: COMMIT
2021-05-14 18:54:12.177543 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:54:12.177695 (MainThread): On master: Close
2021-05-14 18:54:12.178084 (MainThread): 14:54:12 | Concurrency: 4 threads (target='dev')
2021-05-14 18:54:12.178236 (MainThread): 14:54:12 | 
2021-05-14 18:54:12.181854 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-14 18:54:12.182156 (Thread-1): 14:54:12 | 1 of 3 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-14 18:54:12.182495 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-14 18:54:12.182778 (Thread-2): 14:54:12 | 2 of 3 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-14 18:54:12.182951 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-14 18:54:12.183277 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.183564 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:12.183791 (Thread-3): 14:54:12 | 3 of 3 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-14 18:54:12.183930 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-14 18:54:12.184043 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-14 18:54:12.184479 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.185949 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 18:54:12.187550 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 18:54:12.187794 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-14 18:54:12.190175 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 18:54:12.190746 (Thread-2): finished collecting timing info
2021-05-14 18:54:12.191041 (Thread-1): finished collecting timing info
2021-05-14 18:54:12.214662 (Thread-3): finished collecting timing info
2021-05-14 18:54:12.231592 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.231748 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-14 18:54:12.231861 (Thread-3): Opening a new connection, currently in state init
2021-05-14 18:54:12.232192 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:12.240275 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.240627 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-14 18:54:12.240768 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-14 18:54:12.240888 (Thread-2): Opening a new connection, currently in state init
2021-05-14 18:54:12.240992 (Thread-1): Opening a new connection, currently in state closed
2021-05-14 18:54:12.251032 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 18:54:12.253403 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.253604 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 18:54:12.253765 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 18:54:12.253919 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 18:54:12.257715 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.259985 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:12.260250 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 18:54:12.260414 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:54:12.260525 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 18:54:12.265868 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 18:54:12.274179 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 18:54:12.275676 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 18:54:12.275832 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:54:12.277448 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 18:54:12.277715 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.277873 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.278004 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-14 18:54:12.278134 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-14 18:54:12.278333 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:12.278580 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-14 18:54:12.278751 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:54:12.278906 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.279018 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as brandId,
json_extract_path (to_json(json_txt), 'barcode') as barcode,
json_extract_path (to_json(json_txt), 'category') as category,
json_extract_path (to_json(json_txt), 'categoryCode') as categoryCode,
json_extract_path (to_json(json_txt), 'cpg', '$id', '$oid') as cpgId,
json_extract_path (to_json(json_txt), 'cpg', '$ref') as cpgRef,
json_extract_path (to_json(json_txt), 'name') as brandName,
json_extract_path (to_json(json_txt), 'brandCode') as brandCode,
json_extract_path (to_json(json_txt), 'topBrand') as topBrand
from fetch_takehome.brands
  );
2021-05-14 18:54:12.279167 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:54:12.279292 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.279388 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role') as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-14 18:54:12.279509 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-14 18:54:12.279683 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:12.279788 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned') as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason') as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date') as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date') as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date') as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date') as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date') as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned') as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date') as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount') as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList') as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus') as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent') as totalSpent,
json_extract_path (to_json(json_txt), 'userId') as userId
from fetch_takehome.receipts
  );
2021-05-14 18:54:12.328547 (Thread-3): SQL status: SELECT 495 in 0.05 seconds
2021-05-14 18:54:12.350070 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.350235 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-14 18:54:12.350707 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:54:12.353142 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.353289 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-14 18:54:12.353908 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:54:12.362426 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 18:54:12.362596 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.362700 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 18:54:12.363584 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:54:12.367119 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 18:54:12.367271 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 18:54:12.370223 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:54:12.371610 (Thread-3): finished collecting timing info
2021-05-14 18:54:12.371864 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-14 18:54:12.372538 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5eeaeeb-77ac-4504-b4ee-2a03f6532d17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11085d190>]}
2021-05-14 18:54:12.372990 (Thread-3): 14:54:12 | 3 of 3 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.19s]
2021-05-14 18:54:12.373223 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-14 18:54:12.377267 (Thread-1): SQL status: SELECT 1167 in 0.10 seconds
2021-05-14 18:54:12.379814 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.379951 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-14 18:54:12.380553 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:54:12.382701 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.382834 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-14 18:54:12.383376 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:54:12.384707 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 18:54:12.384831 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.384928 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 18:54:12.385471 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:54:12.386939 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 18:54:12.387095 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 18:54:12.403788 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 18:54:12.405274 (Thread-1): finished collecting timing info
2021-05-14 18:54:12.405465 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-14 18:54:12.405895 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5eeaeeb-77ac-4504-b4ee-2a03f6532d17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eee970>]}
2021-05-14 18:54:12.406231 (Thread-1): 14:54:12 | 1 of 3 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.22s]
2021-05-14 18:54:12.406385 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-14 18:54:13.097461 (Thread-2): SQL status: SELECT 1119 in 0.82 seconds
2021-05-14 18:54:13.099519 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:13.099639 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-14 18:54:13.100293 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 18:54:13.101207 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 18:54:13.101299 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:13.101377 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 18:54:13.101888 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:54:13.102997 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 18:54:13.103091 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 18:54:13.103471 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 18:54:13.104456 (Thread-2): finished collecting timing info
2021-05-14 18:54:13.104574 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-14 18:54:13.104855 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5eeaeeb-77ac-4504-b4ee-2a03f6532d17', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ad9370>]}
2021-05-14 18:54:13.105101 (Thread-2): 14:54:13 | 2 of 3 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.92s]
2021-05-14 18:54:13.105213 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-14 18:54:13.106272 (MainThread): Acquiring new postgres connection "master".
2021-05-14 18:54:13.106416 (MainThread): Using postgres connection "master".
2021-05-14 18:54:13.106496 (MainThread): On master: BEGIN
2021-05-14 18:54:13.106581 (MainThread): Opening a new connection, currently in state closed
2021-05-14 18:54:13.114396 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 18:54:13.114572 (MainThread): On master: COMMIT
2021-05-14 18:54:13.114683 (MainThread): Using postgres connection "master".
2021-05-14 18:54:13.114769 (MainThread): On master: COMMIT
2021-05-14 18:54:13.114952 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 18:54:13.115067 (MainThread): On master: Close
2021-05-14 18:54:13.115402 (MainThread): 14:54:13 | 
2021-05-14 18:54:13.115533 (MainThread): 14:54:13 | Finished running 3 table models in 1.07s.
2021-05-14 18:54:13.115637 (MainThread): Connection 'master' was properly closed.
2021-05-14 18:54:13.115719 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-14 18:54:13.115796 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-14 18:54:13.115870 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-14 18:54:13.120241 (MainThread): 
2021-05-14 18:54:13.120416 (MainThread): Completed successfully
2021-05-14 18:54:13.120549 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-05-14 18:54:13.120797 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d1a070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eed550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11059b070>]}
2021-05-14 18:54:13.121019 (MainThread): Flushing usage events
2021-05-14 19:03:14.095207 (MainThread): Running with dbt=0.19.1
2021-05-14 19:03:14.196944 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-14 19:03:14.198859 (MainThread): Tracking: tracking
2021-05-14 19:03:14.221207 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c56d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c745e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c74e20>]}
2021-05-14 19:03:14.237751 (MainThread): Partial parsing not enabled
2021-05-14 19:03:14.239726 (MainThread): Parsing macros/catalog.sql
2021-05-14 19:03:14.245093 (MainThread): Parsing macros/relations.sql
2021-05-14 19:03:14.247509 (MainThread): Parsing macros/adapters.sql
2021-05-14 19:03:14.276692 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-14 19:03:14.281423 (MainThread): Parsing macros/core.sql
2021-05-14 19:03:14.286934 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-14 19:03:14.298982 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-14 19:03:14.301764 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-14 19:03:14.326663 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-14 19:03:14.369133 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-14 19:03:14.395786 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-14 19:03:14.398398 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-14 19:03:14.406814 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-14 19:03:14.426068 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-14 19:03:14.436243 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-14 19:03:14.445352 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-14 19:03:14.452194 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-14 19:03:14.453603 (MainThread): Parsing macros/etc/query.sql
2021-05-14 19:03:14.455143 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-14 19:03:14.457328 (MainThread): Parsing macros/etc/datetime.sql
2021-05-14 19:03:14.468968 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-14 19:03:14.471581 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-14 19:03:14.473940 (MainThread): Parsing macros/adapters/common.sql
2021-05-14 19:03:14.532065 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-14 19:03:14.535152 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-14 19:03:14.537734 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-14 19:03:14.540284 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-14 19:03:14.550398 (MainThread): Partial parsing not enabled
2021-05-14 19:03:14.612332 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:14.624915 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.628832 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:14.687454 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1ea95ff-aa06-4e68-b276-17b6035a25e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084ab7c0>]}
2021-05-14 19:03:14.693570 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1ea95ff-aa06-4e68-b276-17b6035a25e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e36e50>]}
2021-05-14 19:03:14.693908 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-14 19:03:14.694735 (MainThread): 
2021-05-14 19:03:14.695101 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:03:14.696159 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-14 19:03:14.709434 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-14 19:03:14.709644 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-14 19:03:14.709806 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-14 19:03:14.763534 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.05 seconds
2021-05-14 19:03:14.766829 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-14 19:03:14.768001 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:03:14.774572 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:03:14.774729 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-14 19:03:14.774847 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-14 19:03:14.783681 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:03:14.783855 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:03:14.783956 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-14 19:03:14.787023 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.00 seconds
2021-05-14 19:03:14.787734 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-14 19:03:14.787951 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-14 19:03:14.792835 (MainThread): Using postgres connection "master".
2021-05-14 19:03:14.793010 (MainThread): On master: BEGIN
2021-05-14 19:03:14.793132 (MainThread): Opening a new connection, currently in state init
2021-05-14 19:03:14.801823 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:03:14.801996 (MainThread): Using postgres connection "master".
2021-05-14 19:03:14.802100 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-14 19:03:14.813728 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-14 19:03:14.814366 (MainThread): On master: ROLLBACK
2021-05-14 19:03:14.814627 (MainThread): Using postgres connection "master".
2021-05-14 19:03:14.814752 (MainThread): On master: BEGIN
2021-05-14 19:03:14.815033 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:03:14.815169 (MainThread): On master: COMMIT
2021-05-14 19:03:14.815275 (MainThread): Using postgres connection "master".
2021-05-14 19:03:14.815368 (MainThread): On master: COMMIT
2021-05-14 19:03:14.815560 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:03:14.815682 (MainThread): On master: Close
2021-05-14 19:03:14.815992 (MainThread): 15:03:14 | Concurrency: 4 threads (target='dev')
2021-05-14 19:03:14.816138 (MainThread): 15:03:14 | 
2021-05-14 19:03:14.818482 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-14 19:03:14.818825 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:03:14.819077 (Thread-1): 15:03:14 | 1 of 3 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-14 19:03:14.819178 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-14 19:03:14.819418 (Thread-2): 15:03:14 | 2 of 3 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-14 19:03:14.819761 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:14.819993 (Thread-3): 15:03:14 | 3 of 3 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-14 19:03:14.820271 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:14.820410 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-14 19:03:14.820666 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.820787 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-14 19:03:14.821968 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:03:14.822110 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-14 19:03:14.823313 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:03:14.824502 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:03:14.825635 (Thread-1): finished collecting timing info
2021-05-14 19:03:14.838111 (Thread-3): finished collecting timing info
2021-05-14 19:03:14.838320 (Thread-2): finished collecting timing info
2021-05-14 19:03:14.853037 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:14.864374 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:14.868837 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.869013 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-14 19:03:14.869130 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-14 19:03:14.869234 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-14 19:03:14.869387 (Thread-1): Opening a new connection, currently in state closed
2021-05-14 19:03:14.869546 (Thread-2): Opening a new connection, currently in state init
2021-05-14 19:03:14.869715 (Thread-3): Opening a new connection, currently in state init
2021-05-14 19:03:14.882353 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:03:14.884948 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:14.885111 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:03:14.885377 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 19:03:14.885520 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:03:14.889055 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.889254 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 19:03:14.900072 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 19:03:14.902454 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:03:14.904677 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:14.905072 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:03:14.905174 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:03:14.906527 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:03:14.906714 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:14.907059 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-14 19:03:14.907205 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:03:14.908636 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:03:14.908800 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:03:14.909268 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.909388 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:14.909525 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:14.909646 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-14 19:03:14.909759 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned') as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason') as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date') as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date') as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date') as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date') as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date') as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned') as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date') as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount') as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList') as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus') as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent') as totalSpent,
json_extract_path (to_json(json_txt), 'userId') as userId
from fetch_takehome.receipts
  );
2021-05-14 19:03:14.909872 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-14 19:03:14.910319 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:03:14.910606 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.910736 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as userId,
json_extract_path (to_json(json_txt), 'role')::varchar as role,
json_extract_path (to_json(json_txt), 'state') as state,
json_extract_path (to_json(json_txt), 'active') as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date') as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date') as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource') as signUpSource
from fetch_takehome.users
  );
2021-05-14 19:03:14.910877 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:03:14.911066 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:14.911175 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as brandId,
json_extract_path (to_json(json_txt), 'barcode') as barcode,
json_extract_path (to_json(json_txt), 'category') as category,
json_extract_path (to_json(json_txt), 'categoryCode') as categoryCode,
json_extract_path (to_json(json_txt), 'cpg', '$id', '$oid') as cpgId,
json_extract_path (to_json(json_txt), 'cpg', '$ref') as cpgRef,
json_extract_path (to_json(json_txt), 'name') as brandName,
json_extract_path (to_json(json_txt), 'brandCode') as brandCode,
json_extract_path (to_json(json_txt), 'topBrand') as topBrand
from fetch_takehome.brands
  );
2021-05-14 19:03:14.933714 (Thread-3): SQL status: SELECT 495 in 0.02 seconds
2021-05-14 19:03:14.940574 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.940733 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-14 19:03:14.941193 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:03:14.943539 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.943698 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-14 19:03:14.944375 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:03:14.955364 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 19:03:14.975047 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:14.975584 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 19:03:14.996350 (Thread-3): SQL status: COMMIT in 0.02 seconds
2021-05-14 19:03:15.002159 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:03:15.002417 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 19:03:15.009034 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:03:15.011437 (Thread-3): finished collecting timing info
2021-05-14 19:03:15.011775 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-14 19:03:15.012396 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1ea95ff-aa06-4e68-b276-17b6035a25e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084b28b0>]}
2021-05-14 19:03:15.012908 (Thread-3): 15:03:15 | 3 of 3 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.19s]
2021-05-14 19:03:15.013127 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-14 19:03:15.060550 (Thread-1): SQL status: SELECT 1167 in 0.15 seconds
2021-05-14 19:03:15.063469 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:15.063644 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-14 19:03:15.064923 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:03:15.068731 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:15.068923 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-14 19:03:15.069695 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:03:15.071538 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:03:15.071765 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:15.071931 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:03:15.076278 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:03:15.079508 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:03:15.079841 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:03:15.105912 (Thread-1): SQL status: DROP TABLE in 0.03 seconds
2021-05-14 19:03:15.108444 (Thread-1): finished collecting timing info
2021-05-14 19:03:15.108802 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-14 19:03:15.109669 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1ea95ff-aa06-4e68-b276-17b6035a25e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d712b0>]}
2021-05-14 19:03:15.110362 (Thread-1): 15:03:15 | 1 of 3 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.29s]
2021-05-14 19:03:15.110660 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-14 19:03:16.270119 (Thread-2): SQL status: SELECT 1119 in 1.36 seconds
2021-05-14 19:03:16.272595 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:16.272736 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-14 19:03:16.273292 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:03:16.275554 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:16.275755 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-14 19:03:16.276574 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:03:16.277888 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:03:16.278036 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:16.278138 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:03:16.278991 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:03:16.280660 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:03:16.280801 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:03:16.286011 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:03:16.287589 (Thread-2): finished collecting timing info
2021-05-14 19:03:16.287790 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-14 19:03:16.288191 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1ea95ff-aa06-4e68-b276-17b6035a25e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e17ac0>]}
2021-05-14 19:03:16.288525 (Thread-2): 15:03:16 | 2 of 3 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.47s]
2021-05-14 19:03:16.288677 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:03:16.289932 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:03:16.290162 (MainThread): Using postgres connection "master".
2021-05-14 19:03:16.290379 (MainThread): On master: BEGIN
2021-05-14 19:03:16.290526 (MainThread): Opening a new connection, currently in state closed
2021-05-14 19:03:16.300595 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:03:16.300805 (MainThread): On master: COMMIT
2021-05-14 19:03:16.300915 (MainThread): Using postgres connection "master".
2021-05-14 19:03:16.301013 (MainThread): On master: COMMIT
2021-05-14 19:03:16.301321 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:03:16.301543 (MainThread): On master: Close
2021-05-14 19:03:16.302090 (MainThread): 15:03:16 | 
2021-05-14 19:03:16.302284 (MainThread): 15:03:16 | Finished running 3 table models in 1.61s.
2021-05-14 19:03:16.302465 (MainThread): Connection 'master' was properly closed.
2021-05-14 19:03:16.302601 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-14 19:03:16.302727 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-14 19:03:16.302845 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-14 19:03:16.308543 (MainThread): 
2021-05-14 19:03:16.308846 (MainThread): Completed successfully
2021-05-14 19:03:16.309148 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-05-14 19:03:16.309522 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089d29a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089d2700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f03070>]}
2021-05-14 19:03:16.309984 (MainThread): Flushing usage events
2021-05-14 19:05:11.200798 (MainThread): Running with dbt=0.19.1
2021-05-14 19:05:11.529930 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-14 19:05:11.548455 (MainThread): Tracking: tracking
2021-05-14 19:05:11.577566 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8e7d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9035e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a903e20>]}
2021-05-14 19:05:11.629530 (MainThread): Partial parsing not enabled
2021-05-14 19:05:11.633601 (MainThread): Parsing macros/catalog.sql
2021-05-14 19:05:11.643945 (MainThread): Parsing macros/relations.sql
2021-05-14 19:05:11.649029 (MainThread): Parsing macros/adapters.sql
2021-05-14 19:05:11.713625 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-14 19:05:11.717859 (MainThread): Parsing macros/core.sql
2021-05-14 19:05:11.725694 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-14 19:05:11.741834 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-14 19:05:11.744851 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-14 19:05:11.772458 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-14 19:05:11.820129 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-14 19:05:11.850524 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-14 19:05:11.853191 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-14 19:05:11.863367 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-14 19:05:11.883760 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-14 19:05:11.894564 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-14 19:05:11.903440 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-14 19:05:11.912128 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-14 19:05:11.913539 (MainThread): Parsing macros/etc/query.sql
2021-05-14 19:05:11.915092 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-14 19:05:11.917525 (MainThread): Parsing macros/etc/datetime.sql
2021-05-14 19:05:11.931191 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-14 19:05:11.934412 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-14 19:05:11.936802 (MainThread): Parsing macros/adapters/common.sql
2021-05-14 19:05:12.025539 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-14 19:05:12.028412 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-14 19:05:12.030672 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-14 19:05:12.033253 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-14 19:05:12.046164 (MainThread): Partial parsing not enabled
2021-05-14 19:05:12.114466 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.127804 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:05:12.131378 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:12.186108 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '590ca43a-d617-42e5-879d-e10d0e9ca156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a13abb0>]}
2021-05-14 19:05:12.192041 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '590ca43a-d617-42e5-879d-e10d0e9ca156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aac3e50>]}
2021-05-14 19:05:12.192324 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-14 19:05:12.192973 (MainThread): 
2021-05-14 19:05:12.193307 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:05:12.194411 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-14 19:05:12.207215 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-14 19:05:12.207391 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-14 19:05:12.207519 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-14 19:05:12.246108 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-14 19:05:12.249132 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-14 19:05:12.250273 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:05:12.257148 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:05:12.257306 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-14 19:05:12.257421 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-14 19:05:12.266379 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:05:12.266575 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:05:12.266796 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-14 19:05:12.286771 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-14 19:05:12.288064 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-14 19:05:12.294367 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-14 19:05:12.302288 (MainThread): Using postgres connection "master".
2021-05-14 19:05:12.302627 (MainThread): On master: BEGIN
2021-05-14 19:05:12.302798 (MainThread): Opening a new connection, currently in state init
2021-05-14 19:05:12.316321 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:05:12.316548 (MainThread): Using postgres connection "master".
2021-05-14 19:05:12.316694 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-14 19:05:12.332068 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-14 19:05:12.332731 (MainThread): On master: ROLLBACK
2021-05-14 19:05:12.332984 (MainThread): Using postgres connection "master".
2021-05-14 19:05:12.333094 (MainThread): On master: BEGIN
2021-05-14 19:05:12.333417 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:05:12.333561 (MainThread): On master: COMMIT
2021-05-14 19:05:12.333674 (MainThread): Using postgres connection "master".
2021-05-14 19:05:12.333773 (MainThread): On master: COMMIT
2021-05-14 19:05:12.333965 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:05:12.334094 (MainThread): On master: Close
2021-05-14 19:05:12.334414 (MainThread): 15:05:12 | Concurrency: 4 threads (target='dev')
2021-05-14 19:05:12.334562 (MainThread): 15:05:12 | 
2021-05-14 19:05:12.337302 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-14 19:05:12.337706 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:05:12.337988 (Thread-1): 15:05:12 | 1 of 3 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-14 19:05:12.338092 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-14 19:05:12.338396 (Thread-2): 15:05:12 | 2 of 3 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-14 19:05:12.338791 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.339022 (Thread-3): 15:05:12 | 3 of 3 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-14 19:05:12.339333 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:12.339529 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-14 19:05:12.339891 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:05:12.340102 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-14 19:05:12.341599 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:05:12.341855 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-14 19:05:12.343599 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:05:12.344963 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:05:12.345352 (Thread-1): finished collecting timing info
2021-05-14 19:05:12.356331 (Thread-2): finished collecting timing info
2021-05-14 19:05:12.356561 (Thread-3): finished collecting timing info
2021-05-14 19:05:12.387095 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.389010 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:12.391949 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:05:12.392138 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-14 19:05:12.392262 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-14 19:05:12.392374 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-14 19:05:12.392491 (Thread-1): Opening a new connection, currently in state closed
2021-05-14 19:05:12.392595 (Thread-2): Opening a new connection, currently in state init
2021-05-14 19:05:12.392732 (Thread-3): Opening a new connection, currently in state init
2021-05-14 19:05:12.403864 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:05:12.407809 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.408011 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 19:05:12.408257 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:05:12.412233 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:12.412535 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 19:05:12.412749 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:05:12.415079 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:05:12.415325 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:05:12.415486 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 19:05:12.415634 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:05:12.430113 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:05:12.450994 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:05:12.451158 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:05:12.452850 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:05:12.453101 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.453293 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:12.453389 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-14 19:05:12.453568 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-14 19:05:12.453734 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:05:12.454025 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-14 19:05:12.454216 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:05:12.454375 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:05:12.454543 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:12.454639 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:05:12.454758 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.454865 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned') as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason') as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date') as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date') as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date') as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date') as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date') as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned') as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date') as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount') as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList') as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus') as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent') as totalSpent,
json_extract_path (to_json(json_txt), 'userId') as userId
from fetch_takehome.receipts
  );
2021-05-14 19:05:12.454976 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:05:12.455074 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as brandId,
json_extract_path (to_json(json_txt), 'barcode') as barcode,
json_extract_path (to_json(json_txt), 'category') as category,
json_extract_path (to_json(json_txt), 'categoryCode') as categoryCode,
json_extract_path (to_json(json_txt), 'cpg', '$id', '$oid') as cpgId,
json_extract_path (to_json(json_txt), 'cpg', '$ref') as cpgRef,
json_extract_path (to_json(json_txt), 'name') as brandName,
json_extract_path (to_json(json_txt), 'brandCode') as brandCode,
json_extract_path (to_json(json_txt), 'topBrand') as topBrand
from fetch_takehome.brands
  );
2021-05-14 19:05:12.455264 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path (to_json(json_txt), 'role')::varchar as role,
json_extract_path (to_json(json_txt), 'state')::varchar as state,
json_extract_path (to_json(json_txt), 'active')::varchar as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date')::timestamp as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date')::timestamp as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-14 19:05:12.458714 (Thread-3): Postgres error: cannot cast type json to timestamp without time zone
LINE 11: ...act_path (to_json(json_txt), 'lastLogin', '$date')::timestam...
                                                              ^

2021-05-14 19:05:12.458880 (Thread-3): On model.fetch_takehome.users_json_extract: ROLLBACK
2021-05-14 19:05:12.459164 (Thread-3): finished collecting timing info
2021-05-14 19:05:12.459333 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-14 19:05:12.459682 (Thread-3): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  cannot cast type json to timestamp without time zone
  LINE 11: ...act_path (to_json(json_txt), 'lastLogin', '$date')::timestam...
                                                                ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.CannotCoerce: cannot cast type json to timestamp without time zone
LINE 11: ...act_path (to_json(json_txt), 'lastLogin', '$date')::timestam...
                                                              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
  cannot cast type json to timestamp without time zone
  LINE 11: ...act_path (to_json(json_txt), 'lastLogin', '$date')::timestam...
                                                                ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-14 19:05:12.473013 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '590ca43a-d617-42e5-879d-e10d0e9ca156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa85b80>]}
2021-05-14 19:05:12.473375 (Thread-3): 15:05:12 | 3 of 3 ERROR creating table model fetch_takehome.users_json_extract.. [ERROR in 0.13s]
2021-05-14 19:05:12.473531 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-14 19:05:12.530201 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-14 19:05:12.537799 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.538002 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-14 19:05:12.538600 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:05:12.541290 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.541450 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-14 19:05:12.542177 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:05:12.550912 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:05:12.551121 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.551236 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:05:12.551899 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:05:12.555557 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:05:12.555725 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:05:12.559537 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:05:12.561076 (Thread-1): finished collecting timing info
2021-05-14 19:05:12.561276 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-14 19:05:12.561720 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '590ca43a-d617-42e5-879d-e10d0e9ca156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8d33a0>]}
2021-05-14 19:05:12.562069 (Thread-1): 15:05:12 | 1 of 3 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.22s]
2021-05-14 19:05:12.562225 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-14 19:05:13.325442 (Thread-2): SQL status: SELECT 1119 in 0.87 seconds
2021-05-14 19:05:13.348312 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:13.367002 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-14 19:05:13.367532 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:05:13.369772 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:13.388641 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-14 19:05:13.389551 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:05:13.390928 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:05:13.414187 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:13.414383 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:05:13.416004 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:05:13.417983 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:05:13.418148 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:05:13.420995 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:05:13.422343 (Thread-2): finished collecting timing info
2021-05-14 19:05:13.422536 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-14 19:05:13.422955 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '590ca43a-d617-42e5-879d-e10d0e9ca156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa3a9d0>]}
2021-05-14 19:05:13.423276 (Thread-2): 15:05:13 | 2 of 3 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.08s]
2021-05-14 19:05:13.423417 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:05:13.424685 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:05:13.424892 (MainThread): Using postgres connection "master".
2021-05-14 19:05:13.424996 (MainThread): On master: BEGIN
2021-05-14 19:05:13.425103 (MainThread): Opening a new connection, currently in state closed
2021-05-14 19:05:13.433652 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:05:13.433835 (MainThread): On master: COMMIT
2021-05-14 19:05:13.433930 (MainThread): Using postgres connection "master".
2021-05-14 19:05:13.434018 (MainThread): On master: COMMIT
2021-05-14 19:05:13.434205 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:05:13.434323 (MainThread): On master: Close
2021-05-14 19:05:13.434793 (MainThread): 15:05:13 | 
2021-05-14 19:05:13.434952 (MainThread): 15:05:13 | Finished running 3 table models in 1.24s.
2021-05-14 19:05:13.435072 (MainThread): Connection 'master' was properly closed.
2021-05-14 19:05:13.435160 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-14 19:05:13.435242 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-14 19:05:13.435323 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-14 19:05:13.439696 (MainThread): 
2021-05-14 19:05:13.439870 (MainThread): Completed with 1 error and 0 warnings:
2021-05-14 19:05:13.439994 (MainThread): 
2021-05-14 19:05:13.440110 (MainThread): Database Error in model users_json_extract (models/json_extract/users_json_extract.sql)
2021-05-14 19:05:13.440215 (MainThread):   cannot cast type json to timestamp without time zone
2021-05-14 19:05:13.440312 (MainThread):   LINE 11: ...act_path (to_json(json_txt), 'lastLogin', '$date')::timestam...
2021-05-14 19:05:13.440408 (MainThread):                                                                 ^
2021-05-14 19:05:13.440502 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/users_json_extract.sql
2021-05-14 19:05:13.440609 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2021-05-14 19:05:13.440789 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a085e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a085be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a085e50>]}
2021-05-14 19:05:13.440980 (MainThread): Flushing usage events
2021-05-14 19:06:32.571735 (MainThread): Running with dbt=0.19.1
2021-05-14 19:06:32.675656 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-14 19:06:32.677016 (MainThread): Tracking: tracking
2021-05-14 19:06:32.701458 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e312d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e334580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3347c0>]}
2021-05-14 19:06:32.717446 (MainThread): Partial parsing not enabled
2021-05-14 19:06:32.719470 (MainThread): Parsing macros/catalog.sql
2021-05-14 19:06:32.724292 (MainThread): Parsing macros/relations.sql
2021-05-14 19:06:32.726538 (MainThread): Parsing macros/adapters.sql
2021-05-14 19:06:32.756776 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-14 19:06:32.760740 (MainThread): Parsing macros/core.sql
2021-05-14 19:06:32.766420 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-14 19:06:32.778570 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-14 19:06:32.781183 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-14 19:06:32.805389 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-14 19:06:32.841042 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-14 19:06:32.863001 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-14 19:06:32.865145 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-14 19:06:32.872502 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-14 19:06:32.889510 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-14 19:06:32.897007 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-14 19:06:32.904090 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-14 19:06:32.909666 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-14 19:06:32.910865 (MainThread): Parsing macros/etc/query.sql
2021-05-14 19:06:32.912118 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-14 19:06:32.913940 (MainThread): Parsing macros/etc/datetime.sql
2021-05-14 19:06:32.923315 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-14 19:06:32.925531 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-14 19:06:32.927434 (MainThread): Parsing macros/adapters/common.sql
2021-05-14 19:06:32.976642 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-14 19:06:32.979780 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-14 19:06:32.982213 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-14 19:06:32.985204 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-14 19:06:32.995456 (MainThread): Partial parsing not enabled
2021-05-14 19:06:33.052268 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.065090 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.068802 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:33.123014 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a754cd2-b2c7-4035-977b-e72bedd922e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e093fd0>]}
2021-05-14 19:06:33.128156 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a754cd2-b2c7-4035-977b-e72bedd922e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4f5df0>]}
2021-05-14 19:06:33.128433 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-14 19:06:33.129221 (MainThread): 
2021-05-14 19:06:33.129554 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:06:33.130468 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-14 19:06:33.141253 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-14 19:06:33.141405 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-14 19:06:33.141516 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-14 19:06:33.184527 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-14 19:06:33.187670 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-14 19:06:33.190221 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:06:33.197818 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:06:33.197984 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-14 19:06:33.198098 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-14 19:06:33.207352 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:06:33.207605 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:06:33.207762 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-14 19:06:33.211449 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.00 seconds
2021-05-14 19:06:33.212208 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-14 19:06:33.212438 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-14 19:06:33.217308 (MainThread): Using postgres connection "master".
2021-05-14 19:06:33.217471 (MainThread): On master: BEGIN
2021-05-14 19:06:33.217587 (MainThread): Opening a new connection, currently in state init
2021-05-14 19:06:33.226807 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:06:33.226985 (MainThread): Using postgres connection "master".
2021-05-14 19:06:33.227092 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-14 19:06:33.239072 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-14 19:06:33.239698 (MainThread): On master: ROLLBACK
2021-05-14 19:06:33.239935 (MainThread): Using postgres connection "master".
2021-05-14 19:06:33.240044 (MainThread): On master: BEGIN
2021-05-14 19:06:33.240433 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:06:33.240575 (MainThread): On master: COMMIT
2021-05-14 19:06:33.240683 (MainThread): Using postgres connection "master".
2021-05-14 19:06:33.240774 (MainThread): On master: COMMIT
2021-05-14 19:06:33.240965 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:06:33.241086 (MainThread): On master: Close
2021-05-14 19:06:33.241398 (MainThread): 15:06:33 | Concurrency: 4 threads (target='dev')
2021-05-14 19:06:33.241548 (MainThread): 15:06:33 | 
2021-05-14 19:06:33.244219 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-14 19:06:33.244599 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:06:33.244963 (Thread-1): 15:06:33 | 1 of 3 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-14 19:06:33.245093 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-14 19:06:33.245363 (Thread-2): 15:06:33 | 2 of 3 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-14 19:06:33.245768 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.245985 (Thread-3): 15:06:33 | 3 of 3 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-14 19:06:33.246356 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:33.246490 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-14 19:06:33.246798 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.246943 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-14 19:06:33.248235 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:06:33.248376 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-14 19:06:33.249612 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:06:33.250827 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:06:33.251291 (Thread-1): finished collecting timing info
2021-05-14 19:06:33.272715 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.272921 (Thread-3): finished collecting timing info
2021-05-14 19:06:33.273037 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-14 19:06:33.273124 (Thread-2): finished collecting timing info
2021-05-14 19:06:33.275789 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.275930 (Thread-1): Opening a new connection, currently in state closed
2021-05-14 19:06:33.278675 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:33.278880 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-14 19:06:33.279206 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-14 19:06:33.279353 (Thread-3): Opening a new connection, currently in state init
2021-05-14 19:06:33.279463 (Thread-2): Opening a new connection, currently in state init
2021-05-14 19:06:33.289200 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:06:33.291692 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.291851 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:06:33.291956 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:06:33.292039 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:06:33.295189 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.297211 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:33.297438 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 19:06:33.297599 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:06:33.297697 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:06:33.304269 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:06:33.310277 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:06:33.311659 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:06:33.311803 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:06:33.313287 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:06:33.313639 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.313758 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-14 19:06:33.314065 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.314200 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:06:33.314330 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:33.314406 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-14 19:06:33.314512 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.314609 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-14 19:06:33.314767 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as brandId,
json_extract_path (to_json(json_txt), 'barcode') as barcode,
json_extract_path (to_json(json_txt), 'category') as category,
json_extract_path (to_json(json_txt), 'categoryCode') as categoryCode,
json_extract_path (to_json(json_txt), 'cpg', '$id', '$oid') as cpgId,
json_extract_path (to_json(json_txt), 'cpg', '$ref') as cpgRef,
json_extract_path (to_json(json_txt), 'name') as brandName,
json_extract_path (to_json(json_txt), 'brandCode') as brandCode,
json_extract_path (to_json(json_txt), 'topBrand') as topBrand
from fetch_takehome.brands
  );
2021-05-14 19:06:33.314895 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:06:33.315165 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:06:33.315265 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.315387 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:33.315503 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path (to_json(json_txt), 'role')::varchar as role,
json_extract_path (to_json(json_txt), 'state')::varchar as state,
json_extract_path (to_json(json_txt), 'active')::varchar as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-14 19:06:33.315613 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid') as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned') as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason') as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date') as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date') as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date') as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date') as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date') as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned') as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date') as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount') as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList') as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus') as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent') as totalSpent,
json_extract_path (to_json(json_txt), 'userId') as userId
from fetch_takehome.receipts
  );
2021-05-14 19:06:33.333814 (Thread-3): SQL status: SELECT 495 in 0.02 seconds
2021-05-14 19:06:33.339978 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.340103 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-14 19:06:33.340530 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:06:33.342328 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.342452 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-14 19:06:33.343081 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:06:33.350858 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 19:06:33.351007 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.351093 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 19:06:33.351874 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:06:33.355179 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:06:33.355325 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 19:06:33.357711 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:06:33.359850 (Thread-3): finished collecting timing info
2021-05-14 19:06:33.360110 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-14 19:06:33.360699 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a754cd2-b2c7-4035-977b-e72bedd922e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2f84c0>]}
2021-05-14 19:06:33.361223 (Thread-3): 15:06:33 | 3 of 3 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.11s]
2021-05-14 19:06:33.361433 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-14 19:06:33.371153 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-14 19:06:33.374242 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.374406 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-14 19:06:33.374889 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:06:33.377170 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.377327 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-14 19:06:33.377828 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:06:33.379065 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:06:33.379199 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.379291 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:06:33.379818 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:06:33.381642 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:06:33.381787 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:06:33.384253 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:06:33.385588 (Thread-1): finished collecting timing info
2021-05-14 19:06:33.385775 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-14 19:06:33.386152 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a754cd2-b2c7-4035-977b-e72bedd922e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4be700>]}
2021-05-14 19:06:33.386469 (Thread-1): 15:06:33 | 1 of 3 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.14s]
2021-05-14 19:06:33.386613 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-14 19:06:34.107499 (Thread-2): SQL status: SELECT 1119 in 0.79 seconds
2021-05-14 19:06:34.109592 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:34.109696 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-14 19:06:34.110034 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:06:34.111697 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:34.111799 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-14 19:06:34.112185 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:06:34.113086 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:06:34.113182 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:34.113261 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:06:34.113801 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:06:34.115011 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:06:34.115110 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:06:34.117209 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:06:34.118168 (Thread-2): finished collecting timing info
2021-05-14 19:06:34.118295 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-14 19:06:34.118594 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a754cd2-b2c7-4035-977b-e72bedd922e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3066d0>]}
2021-05-14 19:06:34.118862 (Thread-2): 15:06:34 | 2 of 3 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.87s]
2021-05-14 19:06:34.118977 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:06:34.119985 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:06:34.120118 (MainThread): Using postgres connection "master".
2021-05-14 19:06:34.120197 (MainThread): On master: BEGIN
2021-05-14 19:06:34.120277 (MainThread): Opening a new connection, currently in state closed
2021-05-14 19:06:34.127448 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:06:34.127620 (MainThread): On master: COMMIT
2021-05-14 19:06:34.127717 (MainThread): Using postgres connection "master".
2021-05-14 19:06:34.127805 (MainThread): On master: COMMIT
2021-05-14 19:06:34.128014 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:06:34.128157 (MainThread): On master: Close
2021-05-14 19:06:34.128501 (MainThread): 15:06:34 | 
2021-05-14 19:06:34.128634 (MainThread): 15:06:34 | Finished running 3 table models in 1.00s.
2021-05-14 19:06:34.128746 (MainThread): Connection 'master' was properly closed.
2021-05-14 19:06:34.128827 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-14 19:06:34.128905 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-14 19:06:34.128978 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-14 19:06:34.133103 (MainThread): 
2021-05-14 19:06:34.133257 (MainThread): Completed successfully
2021-05-14 19:06:34.133380 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-05-14 19:06:34.133573 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db33370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e42b9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5f45b0>]}
2021-05-14 19:06:34.133838 (MainThread): Flushing usage events
2021-05-14 19:31:27.107775 (MainThread): Running with dbt=0.19.1
2021-05-14 19:31:27.217668 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-14 19:31:27.221129 (MainThread): Tracking: tracking
2021-05-14 19:31:27.244085 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105680e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10569d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10569de20>]}
2021-05-14 19:31:27.259610 (MainThread): Partial parsing not enabled
2021-05-14 19:31:27.261505 (MainThread): Parsing macros/catalog.sql
2021-05-14 19:31:27.266590 (MainThread): Parsing macros/relations.sql
2021-05-14 19:31:27.268901 (MainThread): Parsing macros/adapters.sql
2021-05-14 19:31:27.295042 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-14 19:31:27.299260 (MainThread): Parsing macros/core.sql
2021-05-14 19:31:27.304557 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-14 19:31:27.317736 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-14 19:31:27.320479 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-14 19:31:27.345140 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-14 19:31:27.380557 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-14 19:31:27.402528 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-14 19:31:27.404740 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-14 19:31:27.411256 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-14 19:31:27.425816 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-14 19:31:27.433111 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-14 19:31:27.440244 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-14 19:31:27.445785 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-14 19:31:27.447050 (MainThread): Parsing macros/etc/query.sql
2021-05-14 19:31:27.448423 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-14 19:31:27.450387 (MainThread): Parsing macros/etc/datetime.sql
2021-05-14 19:31:27.460136 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-14 19:31:27.462406 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-14 19:31:27.464395 (MainThread): Parsing macros/adapters/common.sql
2021-05-14 19:31:27.508425 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-14 19:31:27.510580 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-14 19:31:27.512361 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-14 19:31:27.516046 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-14 19:31:27.526650 (MainThread): Partial parsing not enabled
2021-05-14 19:31:27.587687 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.600590 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.604122 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:27.658853 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf14f975-ad6f-4361-9dbb-c81942e0037b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105790ca0>]}
2021-05-14 19:31:27.665638 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf14f975-ad6f-4361-9dbb-c81942e0037b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10585de50>]}
2021-05-14 19:31:27.666079 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-14 19:31:27.667359 (MainThread): 
2021-05-14 19:31:27.667878 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:31:27.669288 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-14 19:31:27.680849 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-14 19:31:27.681011 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-14 19:31:27.681127 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-14 19:31:27.730312 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.05 seconds
2021-05-14 19:31:27.733597 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-14 19:31:27.734751 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:31:27.741131 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:31:27.741267 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-14 19:31:27.741382 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-14 19:31:27.749741 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:31:27.749905 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-14 19:31:27.750013 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-14 19:31:27.754574 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.00 seconds
2021-05-14 19:31:27.755331 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-14 19:31:27.755591 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-14 19:31:27.760331 (MainThread): Using postgres connection "master".
2021-05-14 19:31:27.760466 (MainThread): On master: BEGIN
2021-05-14 19:31:27.760567 (MainThread): Opening a new connection, currently in state init
2021-05-14 19:31:27.769309 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:31:27.769479 (MainThread): Using postgres connection "master".
2021-05-14 19:31:27.769579 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-14 19:31:27.782006 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-14 19:31:27.782605 (MainThread): On master: ROLLBACK
2021-05-14 19:31:27.782830 (MainThread): Using postgres connection "master".
2021-05-14 19:31:27.782929 (MainThread): On master: BEGIN
2021-05-14 19:31:27.783260 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:31:27.783385 (MainThread): On master: COMMIT
2021-05-14 19:31:27.783480 (MainThread): Using postgres connection "master".
2021-05-14 19:31:27.783562 (MainThread): On master: COMMIT
2021-05-14 19:31:27.783741 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:31:27.783854 (MainThread): On master: Close
2021-05-14 19:31:27.784148 (MainThread): 15:31:27 | Concurrency: 4 threads (target='dev')
2021-05-14 19:31:27.784283 (MainThread): 15:31:27 | 
2021-05-14 19:31:27.786642 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-14 19:31:27.786952 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:31:27.787119 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-14 19:31:27.787355 (Thread-1): 15:31:27 | 1 of 3 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-14 19:31:27.787558 (Thread-2): 15:31:27 | 2 of 3 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-14 19:31:27.787751 (Thread-3): 15:31:27 | 3 of 3 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-14 19:31:27.788096 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.788348 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:27.788617 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.788755 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-14 19:31:27.788863 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-14 19:31:27.788961 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-14 19:31:27.790213 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:31:27.791430 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:31:27.792498 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:31:27.793972 (Thread-3): finished collecting timing info
2021-05-14 19:31:27.794147 (Thread-2): finished collecting timing info
2021-05-14 19:31:27.805128 (Thread-1): finished collecting timing info
2021-05-14 19:31:27.846278 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.847645 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.847755 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-14 19:31:27.848944 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:27.849084 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-14 19:31:27.849203 (Thread-3): Opening a new connection, currently in state init
2021-05-14 19:31:27.849304 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-14 19:31:27.849408 (Thread-1): Opening a new connection, currently in state closed
2021-05-14 19:31:27.849714 (Thread-2): Opening a new connection, currently in state init
2021-05-14 19:31:27.865821 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 19:31:27.868931 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.869197 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:31:27.869381 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 19:31:27.873336 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.873524 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-14 19:31:27.873640 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 19:31:27.873729 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:31:27.875954 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:27.881458 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-14 19:31:27.888499 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-14 19:31:27.888651 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:31:27.889877 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-14 19:31:27.890384 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:31:27.891627 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-14 19:31:27.891885 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.892006 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-14 19:31:27.892377 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.892510 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-14 19:31:27.892697 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:27.892820 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:31:27.892920 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-14 19:31:27.892996 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:31:27.893105 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.893275 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.893432 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-14 19:31:27.893533 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path (to_json(json_txt), 'category')::varchar as category,
json_extract_path (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-14 19:31:27.893641 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path (to_json(json_txt), 'role')::varchar as role,
json_extract_path (to_json(json_txt), 'state')::varchar as state,
json_extract_path (to_json(json_txt), 'active')::varchar as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-14 19:31:27.893749 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:27.893999 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-14 19:31:27.921657 (Thread-3): SQL status: SELECT 495 in 0.03 seconds
2021-05-14 19:31:27.929237 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.929392 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-14 19:31:27.929884 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:31:27.932057 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.932191 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-14 19:31:27.933064 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:31:27.941425 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 19:31:27.941577 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.941674 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-14 19:31:27.943677 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:31:27.949106 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-14 19:31:27.949269 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-14 19:31:27.953283 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:31:27.954578 (Thread-3): finished collecting timing info
2021-05-14 19:31:27.954748 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-14 19:31:27.955194 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14f975-ad6f-4361-9dbb-c81942e0037b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053e6a90>]}
2021-05-14 19:31:27.955524 (Thread-3): 15:31:27 | 3 of 3 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.17s]
2021-05-14 19:31:27.955676 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-14 19:31:27.962023 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-14 19:31:27.964559 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.964691 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-14 19:31:27.965208 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:31:27.967813 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.967955 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-14 19:31:27.968430 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:31:27.969688 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:31:27.969798 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.969886 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-14 19:31:27.992060 (Thread-1): SQL status: COMMIT in 0.02 seconds
2021-05-14 19:31:27.993373 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-14 19:31:27.993472 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-14 19:31:27.995904 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:31:27.996930 (Thread-1): finished collecting timing info
2021-05-14 19:31:27.997054 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-14 19:31:27.997345 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14f975-ad6f-4361-9dbb-c81942e0037b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10565c910>]}
2021-05-14 19:31:27.997635 (Thread-1): 15:31:27 | 1 of 3 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.21s]
2021-05-14 19:31:27.997750 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-14 19:31:28.712793 (Thread-2): SQL status: SELECT 1119 in 0.82 seconds
2021-05-14 19:31:28.714913 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:28.715023 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-14 19:31:28.715402 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:31:28.717087 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:28.717187 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-14 19:31:28.717573 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-14 19:31:28.718480 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:31:28.718569 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:28.718640 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-14 19:31:28.719098 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:31:28.720353 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-14 19:31:28.720446 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-14 19:31:28.723818 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-14 19:31:28.724773 (Thread-2): finished collecting timing info
2021-05-14 19:31:28.724896 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-14 19:31:28.725189 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14f975-ad6f-4361-9dbb-c81942e0037b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105654160>]}
2021-05-14 19:31:28.725463 (Thread-2): 15:31:28 | 2 of 3 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.94s]
2021-05-14 19:31:28.725574 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-14 19:31:28.726543 (MainThread): Acquiring new postgres connection "master".
2021-05-14 19:31:28.726668 (MainThread): Using postgres connection "master".
2021-05-14 19:31:28.726743 (MainThread): On master: BEGIN
2021-05-14 19:31:28.726818 (MainThread): Opening a new connection, currently in state closed
2021-05-14 19:31:28.734306 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-14 19:31:28.734455 (MainThread): On master: COMMIT
2021-05-14 19:31:28.734535 (MainThread): Using postgres connection "master".
2021-05-14 19:31:28.734606 (MainThread): On master: COMMIT
2021-05-14 19:31:28.734753 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-14 19:31:28.734850 (MainThread): On master: Close
2021-05-14 19:31:28.735144 (MainThread): 15:31:28 | 
2021-05-14 19:31:28.735252 (MainThread): 15:31:28 | Finished running 3 table models in 1.07s.
2021-05-14 19:31:28.735356 (MainThread): Connection 'master' was properly closed.
2021-05-14 19:31:28.735424 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-14 19:31:28.735487 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-14 19:31:28.735548 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-14 19:31:28.739386 (MainThread): 
2021-05-14 19:31:28.739529 (MainThread): Completed successfully
2021-05-14 19:31:28.739639 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-05-14 19:31:28.739796 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e1ffa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10585da90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ed1250>]}
2021-05-14 19:31:28.739966 (MainThread): Flushing usage events
2021-05-17 20:44:14.304322 (MainThread): Running with dbt=0.19.1
2021-05-17 20:44:14.442685 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 20:44:14.444107 (MainThread): Tracking: tracking
2021-05-17 20:44:14.474287 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106edee20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f016a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f01ee0>]}
2021-05-17 20:44:14.491367 (MainThread): Partial parsing not enabled
2021-05-17 20:44:14.493081 (MainThread): Parsing macros/catalog.sql
2021-05-17 20:44:14.498746 (MainThread): Parsing macros/relations.sql
2021-05-17 20:44:14.501292 (MainThread): Parsing macros/adapters.sql
2021-05-17 20:44:14.530453 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 20:44:14.540164 (MainThread): Parsing macros/core.sql
2021-05-17 20:44:14.551093 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 20:44:14.572823 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 20:44:14.576499 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 20:44:14.601409 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 20:44:14.646127 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 20:44:14.673716 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 20:44:14.676301 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 20:44:14.684380 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 20:44:14.702602 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 20:44:14.711631 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 20:44:14.721135 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 20:44:14.728295 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 20:44:14.729877 (MainThread): Parsing macros/etc/query.sql
2021-05-17 20:44:14.731418 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 20:44:14.733733 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 20:44:14.745169 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 20:44:14.747872 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 20:44:14.750271 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 20:44:14.804615 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 20:44:14.807367 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 20:44:14.809465 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 20:44:14.811997 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 20:44:14.821739 (MainThread): Partial parsing not enabled
2021-05-17 20:44:14.882775 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:14.895882 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:14.900189 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:14.957280 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35dee087-acfa-4825-88ee-bb67acb1a188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ec2c40>]}
2021-05-17 20:44:14.963735 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35dee087-acfa-4825-88ee-bb67acb1a188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c8b50>]}
2021-05-17 20:44:14.964051 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 20:44:14.964748 (MainThread): 
2021-05-17 20:44:14.965142 (MainThread): Acquiring new postgres connection "master".
2021-05-17 20:44:14.966193 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 20:44:14.978563 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 20:44:14.978726 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 20:44:14.978844 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 20:44:15.152158 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.17 seconds
2021-05-17 20:44:15.155691 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 20:44:15.156921 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 20:44:15.163997 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 20:44:15.164168 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 20:44:15.164290 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 20:44:15.174770 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 20:44:15.175005 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 20:44:15.175119 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 20:44:15.190548 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-17 20:44:15.191339 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 20:44:15.191739 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 20:44:15.199125 (MainThread): Using postgres connection "master".
2021-05-17 20:44:15.199375 (MainThread): On master: BEGIN
2021-05-17 20:44:15.199593 (MainThread): Opening a new connection, currently in state init
2021-05-17 20:44:15.337864 (MainThread): SQL status: BEGIN in 0.14 seconds
2021-05-17 20:44:15.338182 (MainThread): Using postgres connection "master".
2021-05-17 20:44:15.338359 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 20:44:15.369783 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-17 20:44:15.370457 (MainThread): On master: ROLLBACK
2021-05-17 20:44:15.370749 (MainThread): Using postgres connection "master".
2021-05-17 20:44:15.370885 (MainThread): On master: BEGIN
2021-05-17 20:44:15.371245 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:44:15.371387 (MainThread): On master: COMMIT
2021-05-17 20:44:15.371504 (MainThread): Using postgres connection "master".
2021-05-17 20:44:15.371599 (MainThread): On master: COMMIT
2021-05-17 20:44:15.371805 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:44:15.371944 (MainThread): On master: Close
2021-05-17 20:44:15.372275 (MainThread): 16:44:15 | Concurrency: 4 threads (target='dev')
2021-05-17 20:44:15.372426 (MainThread): 16:44:15 | 
2021-05-17 20:44:15.375647 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 20:44:15.376151 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 20:44:15.376308 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-17 20:44:15.376562 (Thread-1): 16:44:15 | 1 of 3 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 20:44:15.376895 (Thread-2): 16:44:15 | 2 of 3 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 20:44:15.377170 (Thread-3): 16:44:15 | 3 of 3 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 20:44:15.377554 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.377882 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:15.378320 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.378591 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 20:44:15.378772 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 20:44:15.378935 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-17 20:44:15.380496 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 20:44:15.382372 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 20:44:15.384152 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 20:44:15.385012 (Thread-1): finished collecting timing info
2021-05-17 20:44:15.396111 (Thread-2): finished collecting timing info
2021-05-17 20:44:15.422710 (Thread-3): finished collecting timing info
2021-05-17 20:44:15.431787 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.437588 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 20:44:15.439442 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.439602 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 20:44:15.441570 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:15.441790 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 20:44:15.442186 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 20:44:15.442418 (Thread-3): Opening a new connection, currently in state init
2021-05-17 20:44:15.442681 (Thread-2): Opening a new connection, currently in state init
2021-05-17 20:44:15.457538 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 20:44:15.457743 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 20:44:15.460357 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:15.460486 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 20:44:15.463938 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.464126 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 20:44:15.466354 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.466551 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 20:44:15.466790 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 20:44:15.466975 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:44:15.473253 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 20:44:15.478852 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 20:44:15.484783 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 20:44:15.486687 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 20:44:15.488047 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 20:44:15.488886 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:15.489089 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.489199 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 20:44:15.489364 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.489525 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 20:44:15.489776 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 20:44:15.489921 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:44:15.490232 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:15.490361 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-17 20:44:15.490504 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:44:15.490622 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:44:15.490814 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.490958 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.491106 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 20:44:15.491250 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path (to_json(json_txt), 'role')::varchar as role,
json_extract_path (to_json(json_txt), 'state')::varchar as state,
json_extract_path (to_json(json_txt), 'active')::varchar as active,
json_extract_path (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 20:44:15.620695 (Thread-3): SQL status: SELECT 495 in 0.13 seconds
2021-05-17 20:44:15.628065 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.628230 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 20:44:15.631078 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:44:15.633320 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.633458 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 20:44:15.634012 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:44:15.642250 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 20:44:15.642403 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.642500 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 20:44:15.644173 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:44:15.648211 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:44:15.648356 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 20:44:15.665003 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 20:44:15.666298 (Thread-3): finished collecting timing info
2021-05-17 20:44:15.666463 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-17 20:44:15.666832 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35dee087-acfa-4825-88ee-bb67acb1a188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ec5b20>]}
2021-05-17 20:44:15.667143 (Thread-3): 16:44:15 | 3 of 3 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.29s]
2021-05-17 20:44:15.667290 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 20:44:15.677514 (Thread-1): SQL status: SELECT 1167 in 0.19 seconds
2021-05-17 20:44:15.680226 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.680600 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 20:44:15.681207 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:44:15.683666 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.683841 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 20:44:15.684355 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:44:15.685803 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 20:44:15.710552 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.710761 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 20:44:15.717243 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-05-17 20:44:15.719431 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:44:15.719611 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 20:44:15.723929 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:44:15.725652 (Thread-1): finished collecting timing info
2021-05-17 20:44:15.725881 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 20:44:15.726613 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35dee087-acfa-4825-88ee-bb67acb1a188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069fe3a0>]}
2021-05-17 20:44:15.727083 (Thread-1): 16:44:15 | 1 of 3 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.35s]
2021-05-17 20:44:15.727246 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 20:44:16.705522 (Thread-2): SQL status: SELECT 1119 in 1.21 seconds
2021-05-17 20:44:16.707942 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:16.708063 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-17 20:44:16.708491 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:44:16.710388 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:16.710503 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-17 20:44:16.710958 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:44:16.712036 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 20:44:16.712150 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:16.712241 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 20:44:16.713393 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:44:16.715151 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:44:16.715293 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 20:44:16.719803 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:44:16.721015 (Thread-2): finished collecting timing info
2021-05-17 20:44:16.721248 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 20:44:16.721663 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35dee087-acfa-4825-88ee-bb67acb1a188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ffdf70>]}
2021-05-17 20:44:16.721995 (Thread-2): 16:44:16 | 2 of 3 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.34s]
2021-05-17 20:44:16.722144 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 20:44:16.723522 (MainThread): Acquiring new postgres connection "master".
2021-05-17 20:44:16.723696 (MainThread): Using postgres connection "master".
2021-05-17 20:44:16.723799 (MainThread): On master: BEGIN
2021-05-17 20:44:16.723899 (MainThread): Opening a new connection, currently in state closed
2021-05-17 20:44:16.732781 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 20:44:16.732973 (MainThread): On master: COMMIT
2021-05-17 20:44:16.733074 (MainThread): Using postgres connection "master".
2021-05-17 20:44:16.733166 (MainThread): On master: COMMIT
2021-05-17 20:44:16.733356 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:44:16.733483 (MainThread): On master: Close
2021-05-17 20:44:16.733844 (MainThread): 16:44:16 | 
2021-05-17 20:44:16.733981 (MainThread): 16:44:16 | Finished running 3 table models in 1.77s.
2021-05-17 20:44:16.734094 (MainThread): Connection 'master' was properly closed.
2021-05-17 20:44:16.734179 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 20:44:16.734313 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 20:44:16.734470 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 20:44:16.739548 (MainThread): 
2021-05-17 20:44:16.739751 (MainThread): Completed successfully
2021-05-17 20:44:16.739894 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-05-17 20:44:16.740096 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c8f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ec5af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c700d0>]}
2021-05-17 20:44:16.740305 (MainThread): Flushing usage events
2021-05-17 20:46:13.898104 (MainThread): Running with dbt=0.19.1
2021-05-17 20:46:14.006714 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 20:46:14.009221 (MainThread): Tracking: tracking
2021-05-17 20:46:14.082137 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f873ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8976d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f897f10>]}
2021-05-17 20:46:14.097611 (MainThread): Partial parsing not enabled
2021-05-17 20:46:14.099165 (MainThread): Parsing macros/catalog.sql
2021-05-17 20:46:14.104082 (MainThread): Parsing macros/relations.sql
2021-05-17 20:46:14.106479 (MainThread): Parsing macros/adapters.sql
2021-05-17 20:46:14.135584 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 20:46:14.140162 (MainThread): Parsing macros/core.sql
2021-05-17 20:46:14.146507 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 20:46:14.158851 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 20:46:14.161553 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 20:46:14.185365 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 20:46:14.221580 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 20:46:14.243665 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 20:46:14.245795 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 20:46:14.252418 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 20:46:14.267212 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 20:46:14.274508 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 20:46:14.281799 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 20:46:14.287520 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 20:46:14.288946 (MainThread): Parsing macros/etc/query.sql
2021-05-17 20:46:14.290318 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 20:46:14.292236 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 20:46:14.301632 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 20:46:14.303834 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 20:46:14.305969 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 20:46:14.351396 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 20:46:14.353721 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 20:46:14.355651 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 20:46:14.357806 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 20:46:14.366053 (MainThread): Partial parsing not enabled
2021-05-17 20:46:14.424326 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.437120 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.441676 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:14.495798 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5bb14b43-a4eb-41cd-8e5f-634515a9caab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9afc10>]}
2021-05-17 20:46:14.502167 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5bb14b43-a4eb-41cd-8e5f-634515a9caab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa5cee0>]}
2021-05-17 20:46:14.502618 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 20:46:14.503408 (MainThread): 
2021-05-17 20:46:14.503756 (MainThread): Acquiring new postgres connection "master".
2021-05-17 20:46:14.504705 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 20:46:14.515870 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 20:46:14.516017 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 20:46:14.516127 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 20:46:14.624354 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.11 seconds
2021-05-17 20:46:14.627254 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 20:46:14.628332 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 20:46:14.634626 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 20:46:14.634764 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 20:46:14.634871 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 20:46:14.643688 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 20:46:14.643860 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 20:46:14.644021 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 20:46:14.647026 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.00 seconds
2021-05-17 20:46:14.647711 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 20:46:14.647922 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 20:46:14.652469 (MainThread): Using postgres connection "master".
2021-05-17 20:46:14.652606 (MainThread): On master: BEGIN
2021-05-17 20:46:14.652722 (MainThread): Opening a new connection, currently in state init
2021-05-17 20:46:14.661323 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 20:46:14.661487 (MainThread): Using postgres connection "master".
2021-05-17 20:46:14.661586 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 20:46:14.672559 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 20:46:14.673171 (MainThread): On master: ROLLBACK
2021-05-17 20:46:14.673433 (MainThread): Using postgres connection "master".
2021-05-17 20:46:14.673547 (MainThread): On master: BEGIN
2021-05-17 20:46:14.673861 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:46:14.673990 (MainThread): On master: COMMIT
2021-05-17 20:46:14.674091 (MainThread): Using postgres connection "master".
2021-05-17 20:46:14.674176 (MainThread): On master: COMMIT
2021-05-17 20:46:14.674357 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:46:14.674471 (MainThread): On master: Close
2021-05-17 20:46:14.674766 (MainThread): 16:46:14 | Concurrency: 4 threads (target='dev')
2021-05-17 20:46:14.674904 (MainThread): 16:46:14 | 
2021-05-17 20:46:14.677284 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 20:46:14.677557 (Thread-1): 16:46:14 | 1 of 3 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 20:46:14.678007 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.678139 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 20:46:14.679316 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 20:46:14.679543 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 20:46:14.679783 (Thread-2): 16:46:14 | 2 of 3 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 20:46:14.679945 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-17 20:46:14.680183 (Thread-3): 16:46:14 | 3 of 3 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 20:46:14.680471 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:14.680736 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 20:46:14.681943 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 20:46:14.682078 (Thread-1): finished collecting timing info
2021-05-17 20:46:14.687904 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.688047 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-17 20:46:14.689213 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 20:46:14.704381 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.704533 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 20:46:14.704639 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 20:46:14.704945 (Thread-3): finished collecting timing info
2021-05-17 20:46:14.705159 (Thread-2): finished collecting timing info
2021-05-17 20:46:14.707971 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.711417 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:14.711704 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 20:46:14.711879 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 20:46:14.712048 (Thread-3): Opening a new connection, currently in state init
2021-05-17 20:46:14.712186 (Thread-2): Opening a new connection, currently in state init
2021-05-17 20:46:14.714353 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 20:46:14.717168 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.717318 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 20:46:14.718301 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:46:14.734092 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 20:46:14.734313 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 20:46:14.734431 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 20:46:14.736617 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.738769 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:14.738910 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 20:46:14.739020 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 20:46:14.739276 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.739466 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:46:14.739593 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 20:46:14.740836 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 20:46:14.740924 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:46:14.741278 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:46:14.742576 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 20:46:14.742819 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.743115 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.743247 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 20:46:14.743439 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 20:46:14.743635 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:14.743895 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 20:46:14.744026 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:46:14.744182 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.744276 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 20:46:14.744384 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 20:46:14.744492 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:14.744669 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-17 20:46:14.794042 (Thread-3): SQL status: SELECT 495 in 0.05 seconds
2021-05-17 20:46:14.802176 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.802325 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 20:46:14.802926 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:46:14.805044 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.805165 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 20:46:14.805676 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:46:14.813233 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 20:46:14.813375 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.813463 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 20:46:14.814795 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:46:14.818232 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 20:46:14.818364 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 20:46:14.820454 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:46:14.821654 (Thread-3): finished collecting timing info
2021-05-17 20:46:14.821818 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-17 20:46:14.822196 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bb14b43-a4eb-41cd-8e5f-634515a9caab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa1ed30>]}
2021-05-17 20:46:14.822517 (Thread-3): 16:46:14 | 3 of 3 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.13s]
2021-05-17 20:46:14.822658 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 20:46:14.831142 (Thread-1): SQL status: SELECT 1167 in 0.09 seconds
2021-05-17 20:46:14.834216 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.834374 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 20:46:14.835390 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:46:14.838358 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.838589 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 20:46:14.839353 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:46:14.840851 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 20:46:14.841044 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.841156 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 20:46:14.842272 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:46:14.845041 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 20:46:14.845249 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 20:46:14.848116 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:46:14.849630 (Thread-1): finished collecting timing info
2021-05-17 20:46:14.849837 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 20:46:14.850280 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bb14b43-a4eb-41cd-8e5f-634515a9caab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa2fca0>]}
2021-05-17 20:46:14.850748 (Thread-1): 16:46:14 | 1 of 3 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.17s]
2021-05-17 20:46:14.850969 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 20:46:15.591532 (Thread-2): SQL status: SELECT 1119 in 0.85 seconds
2021-05-17 20:46:15.595802 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:15.596062 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-17 20:46:15.596983 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:46:15.600742 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:15.600963 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-17 20:46:15.601811 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 20:46:15.603924 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 20:46:15.604149 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:15.604296 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 20:46:15.605112 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:46:15.607819 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 20:46:15.608042 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 20:46:15.612266 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 20:46:15.614293 (Thread-2): finished collecting timing info
2021-05-17 20:46:15.614562 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 20:46:15.615139 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bb14b43-a4eb-41cd-8e5f-634515a9caab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8529a0>]}
2021-05-17 20:46:15.615632 (Thread-2): 16:46:15 | 2 of 3 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.93s]
2021-05-17 20:46:15.615853 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 20:46:15.617557 (MainThread): Acquiring new postgres connection "master".
2021-05-17 20:46:15.617817 (MainThread): Using postgres connection "master".
2021-05-17 20:46:15.617965 (MainThread): On master: BEGIN
2021-05-17 20:46:15.618111 (MainThread): Opening a new connection, currently in state closed
2021-05-17 20:46:15.630262 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 20:46:15.630459 (MainThread): On master: COMMIT
2021-05-17 20:46:15.630565 (MainThread): Using postgres connection "master".
2021-05-17 20:46:15.630654 (MainThread): On master: COMMIT
2021-05-17 20:46:15.630896 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 20:46:15.631045 (MainThread): On master: Close
2021-05-17 20:46:15.631428 (MainThread): 16:46:15 | 
2021-05-17 20:46:15.631572 (MainThread): 16:46:15 | Finished running 3 table models in 1.13s.
2021-05-17 20:46:15.631698 (MainThread): Connection 'master' was properly closed.
2021-05-17 20:46:15.631815 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 20:46:15.631898 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 20:46:15.631977 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 20:46:15.636536 (MainThread): 
2021-05-17 20:46:15.636773 (MainThread): Completed successfully
2021-05-17 20:46:15.636978 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-05-17 20:46:15.637213 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9d22b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f604a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9922e0>]}
2021-05-17 20:46:15.637431 (MainThread): Flushing usage events
2021-05-17 21:27:08.187315 (MainThread): Running with dbt=0.19.1
2021-05-17 21:27:08.302318 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:27:08.305236 (MainThread): Tracking: tracking
2021-05-17 21:27:08.337005 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ffc280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112017640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112017e80>]}
2021-05-17 21:27:08.351261 (MainThread): Partial parsing not enabled
2021-05-17 21:27:08.352776 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:27:08.358105 (MainThread): Parsing macros/relations.sql
2021-05-17 21:27:08.360461 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:27:08.383797 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:27:08.387311 (MainThread): Parsing macros/core.sql
2021-05-17 21:27:08.392204 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:27:08.403155 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:27:08.405697 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:27:08.430194 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:27:08.466596 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:27:08.490371 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:27:08.494802 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:27:08.504218 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:27:08.520708 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:27:08.547724 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:27:08.580450 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:27:08.600241 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:27:08.602027 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:27:08.603769 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:27:08.607087 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:27:08.620304 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:27:08.623413 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:27:08.625907 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:27:08.675200 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:27:08.680075 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:27:08.682945 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:27:08.686243 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:27:08.695825 (MainThread): Partial parsing not enabled
2021-05-17 21:27:08.751152 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:08.763840 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:08.768574 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:08.772127 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:08.842646 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40e82d40-3e3b-4dce-a789-6fe3d590ffc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121ab5b0>]}
2021-05-17 21:27:08.847689 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40e82d40-3e3b-4dce-a789-6fe3d590ffc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d13d0>]}
2021-05-17 21:27:08.847992 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:27:08.848694 (MainThread): 
2021-05-17 21:27:08.849015 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:27:08.850018 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:27:08.862415 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:27:08.862617 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:27:08.862733 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:27:08.900411 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-17 21:27:08.904327 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:27:08.906349 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:27:08.914337 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:27:08.914503 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:27:08.914624 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:27:08.923249 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:27:08.923428 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:27:08.923534 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:27:08.927738 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.00 seconds
2021-05-17 21:27:08.928517 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:27:08.928781 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:27:08.933705 (MainThread): Using postgres connection "master".
2021-05-17 21:27:08.933863 (MainThread): On master: BEGIN
2021-05-17 21:27:08.933975 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:27:08.942512 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:27:08.942684 (MainThread): Using postgres connection "master".
2021-05-17 21:27:08.942787 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:27:08.955367 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 21:27:08.955995 (MainThread): On master: ROLLBACK
2021-05-17 21:27:08.956235 (MainThread): Using postgres connection "master".
2021-05-17 21:27:08.956343 (MainThread): On master: BEGIN
2021-05-17 21:27:08.956602 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:08.956719 (MainThread): On master: COMMIT
2021-05-17 21:27:08.956821 (MainThread): Using postgres connection "master".
2021-05-17 21:27:08.956909 (MainThread): On master: COMMIT
2021-05-17 21:27:08.957105 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:08.957252 (MainThread): On master: Close
2021-05-17 21:27:08.957572 (MainThread): 17:27:08 | Concurrency: 4 threads (target='dev')
2021-05-17 21:27:08.957714 (MainThread): 17:27:08 | 
2021-05-17 21:27:08.960344 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:27:08.960703 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:27:08.960967 (Thread-1): 17:27:08 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:27:08.961067 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:27:08.961326 (Thread-2): 17:27:08 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:27:08.961432 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:27:08.961774 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:08.961984 (Thread-3): 17:27:08 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:27:08.962266 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:08.962473 (Thread-4): 17:27:08 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:27:08.962616 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:27:08.962931 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:08.963074 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:27:08.963344 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:08.964704 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:27:08.964845 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:27:08.965909 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:27:08.966034 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:27:08.967302 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:27:08.968544 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:27:08.968646 (Thread-1): finished collecting timing info
2021-05-17 21:27:08.975167 (Thread-3): finished collecting timing info
2021-05-17 21:27:08.975327 (Thread-2): finished collecting timing info
2021-05-17 21:27:09.002149 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.007284 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.007405 (Thread-4): finished collecting timing info
2021-05-17 21:27:09.010523 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:09.010678 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:27:09.010881 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:27:09.013348 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.013522 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:27:09.013661 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:27:09.013805 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:27:09.013957 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:27:09.014077 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:27:09.014532 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:27:09.024829 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:27:09.025021 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:27:09.027233 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.027332 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:27:09.029283 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:09.029425 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:27:09.029523 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:27:09.031425 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.031547 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:27:09.033414 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.033627 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:27:09.033826 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:09.033921 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:27:09.034006 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:09.040557 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:27:09.045693 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:27:09.047217 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:27:09.047399 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:09.048636 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:27:09.050110 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:27:09.050533 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.050784 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:27:09.051007 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.051137 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:09.051302 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:27:09.051394 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:09.051780 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.051914 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:27:09.052117 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.052228 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:09.052347 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:27:09.052520 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:27:09.052615 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:09.052741 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.052978 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:09.053064 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:09.053164 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:27:09.053276 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.053369 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    select
receiptId,
json_array_elements_text(rewardsreceiptitemlist::json) as items
from fetch_takehome.receipts_json_extract;
  );
2021-05-17 21:27:09.053513 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-17 21:27:09.056906 (Thread-2): Postgres error: syntax error at or near ";"
LINE 9: from fetch_takehome.receipts_json_extract;
                                                 ^

2021-05-17 21:27:09.057048 (Thread-2): On model.fetch_takehome.items_json_extract: ROLLBACK
2021-05-17 21:27:09.057306 (Thread-2): finished collecting timing info
2021-05-17 21:27:09.057491 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:27:09.057878 (Thread-2): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  syntax error at or near ";"
  LINE 9: from fetch_takehome.receipts_json_extract;
                                                   ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ";"
LINE 9: from fetch_takehome.receipts_json_extract;
                                                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  syntax error at or near ";"
  LINE 9: from fetch_takehome.receipts_json_extract;
                                                   ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:27:09.065255 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40e82d40-3e3b-4dce-a789-6fe3d590ffc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118507f0>]}
2021-05-17 21:27:09.065603 (Thread-2): 17:27:09 | 2 of 4 ERROR creating table model fetch_takehome.items_json_extract.. [ERROR in 0.10s]
2021-05-17 21:27:09.065745 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:27:09.095363 (Thread-4): SQL status: SELECT 495 in 0.04 seconds
2021-05-17 21:27:09.105540 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.105711 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:27:09.106171 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:09.108642 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.108792 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:27:09.109388 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:09.118073 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:27:09.118251 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.118352 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:27:09.120571 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:09.124976 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:09.125142 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:27:09.129584 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:09.130921 (Thread-4): finished collecting timing info
2021-05-17 21:27:09.131113 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:27:09.131519 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40e82d40-3e3b-4dce-a789-6fe3d590ffc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fdc790>]}
2021-05-17 21:27:09.131864 (Thread-4): 17:27:09 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.17s]
2021-05-17 21:27:09.132034 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:27:09.140152 (Thread-1): SQL status: SELECT 1167 in 0.09 seconds
2021-05-17 21:27:09.142620 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.142782 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:27:09.143474 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:09.147237 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.147543 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:27:09.148334 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:09.150335 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:27:09.150567 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.150684 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:27:09.151232 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:09.152912 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:09.153057 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:27:09.156932 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:09.158496 (Thread-1): finished collecting timing info
2021-05-17 21:27:09.158731 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:27:09.159139 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40e82d40-3e3b-4dce-a789-6fe3d590ffc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d77910>]}
2021-05-17 21:27:09.159478 (Thread-1): 17:27:09 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.20s]
2021-05-17 21:27:09.159686 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:27:09.846115 (Thread-3): SQL status: SELECT 1119 in 0.79 seconds
2021-05-17 21:27:09.848354 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.868485 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-17 21:27:09.868977 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:09.871100 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.894041 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-17 21:27:09.894855 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:09.895955 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 21:27:09.918289 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.918618 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 21:27:09.919879 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:09.921483 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:09.940852 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:27:09.945272 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:09.948629 (Thread-3): finished collecting timing info
2021-05-17 21:27:09.948805 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:27:09.949340 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40e82d40-3e3b-4dce-a789-6fe3d590ffc8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112132670>]}
2021-05-17 21:27:09.949669 (Thread-3): 17:27:09 | 3 of 4 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.99s]
2021-05-17 21:27:09.949803 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:27:09.951172 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:27:09.951350 (MainThread): Using postgres connection "master".
2021-05-17 21:27:09.951457 (MainThread): On master: BEGIN
2021-05-17 21:27:09.951575 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:27:09.960509 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:27:09.981113 (MainThread): On master: COMMIT
2021-05-17 21:27:09.981537 (MainThread): Using postgres connection "master".
2021-05-17 21:27:09.981675 (MainThread): On master: COMMIT
2021-05-17 21:27:09.981978 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:09.982141 (MainThread): On master: Close
2021-05-17 21:27:09.982537 (MainThread): 17:27:09 | 
2021-05-17 21:27:09.982702 (MainThread): 17:27:09 | Finished running 4 table models in 1.13s.
2021-05-17 21:27:09.982884 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:27:10.004407 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:27:10.004612 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:27:10.004741 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:27:10.004845 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:27:10.009772 (MainThread): 
2021-05-17 21:27:10.009965 (MainThread): Completed with 1 error and 0 warnings:
2021-05-17 21:27:10.010100 (MainThread): 
2021-05-17 21:27:10.010222 (MainThread): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
2021-05-17 21:27:10.010333 (MainThread):   syntax error at or near ";"
2021-05-17 21:27:10.010437 (MainThread):   LINE 9: from fetch_takehome.receipts_json_extract;
2021-05-17 21:27:10.010538 (MainThread):                                                    ^
2021-05-17 21:27:10.010636 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:27:10.010754 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-05-17 21:27:10.010950 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11184b520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11184b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11184b2b0>]}
2021-05-17 21:27:10.011164 (MainThread): Flushing usage events
2021-05-17 21:27:30.618759 (MainThread): Running with dbt=0.19.1
2021-05-17 21:27:30.707814 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:27:30.708614 (MainThread): Tracking: tracking
2021-05-17 21:27:30.722884 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107046d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10706a580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10706a7c0>]}
2021-05-17 21:27:30.737821 (MainThread): Partial parsing not enabled
2021-05-17 21:27:30.739005 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:27:30.743106 (MainThread): Parsing macros/relations.sql
2021-05-17 21:27:30.745031 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:27:30.771426 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:27:30.774930 (MainThread): Parsing macros/core.sql
2021-05-17 21:27:30.779684 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:27:30.826177 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:27:30.828428 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:27:30.851015 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:27:30.886753 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:27:30.908954 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:27:30.910937 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:27:30.917518 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:27:30.933443 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:27:30.940697 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:27:30.947368 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:27:30.952986 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:27:30.953998 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:27:30.955137 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:27:30.956793 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:27:30.966123 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:27:30.968352 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:27:30.970097 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:27:31.014733 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:27:31.016697 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:27:31.018308 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:27:31.020108 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:27:31.027779 (MainThread): Partial parsing not enabled
2021-05-17 21:27:31.081983 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.093696 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.097152 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:31.100449 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.151621 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0db755d1-76f3-4917-b888-7d7b44d0ea08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107202070>]}
2021-05-17 21:27:31.155539 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0db755d1-76f3-4917-b888-7d7b44d0ea08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107229310>]}
2021-05-17 21:27:31.155861 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:27:31.156543 (MainThread): 
2021-05-17 21:27:31.156862 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:27:31.157830 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:27:31.168308 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:27:31.168443 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:27:31.168570 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:27:31.192465 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-17 21:27:31.195312 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:27:31.196776 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:27:31.203494 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:27:31.203684 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:27:31.203797 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:27:31.212470 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:27:31.212662 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:27:31.212754 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:27:31.215939 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.00 seconds
2021-05-17 21:27:31.216627 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:27:31.216876 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:27:31.221878 (MainThread): Using postgres connection "master".
2021-05-17 21:27:31.222020 (MainThread): On master: BEGIN
2021-05-17 21:27:31.222125 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:27:31.230480 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:27:31.230633 (MainThread): Using postgres connection "master".
2021-05-17 21:27:31.230721 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:27:31.241616 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 21:27:31.242340 (MainThread): On master: ROLLBACK
2021-05-17 21:27:31.242573 (MainThread): Using postgres connection "master".
2021-05-17 21:27:31.242670 (MainThread): On master: BEGIN
2021-05-17 21:27:31.242943 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:31.243067 (MainThread): On master: COMMIT
2021-05-17 21:27:31.243163 (MainThread): Using postgres connection "master".
2021-05-17 21:27:31.243243 (MainThread): On master: COMMIT
2021-05-17 21:27:31.243428 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:31.243561 (MainThread): On master: Close
2021-05-17 21:27:31.243864 (MainThread): 17:27:31 | Concurrency: 4 threads (target='dev')
2021-05-17 21:27:31.243997 (MainThread): 17:27:31 | 
2021-05-17 21:27:31.245994 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:27:31.246396 (Thread-1): 17:27:31 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:27:31.246557 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:27:31.246735 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:27:31.247027 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.247126 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:27:31.247315 (Thread-2): 17:27:31 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:27:31.247499 (Thread-3): 17:27:31 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:27:31.247626 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:27:31.247804 (Thread-4): 17:27:31 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:27:31.248068 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.248398 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:31.249614 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:27:31.250034 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.250156 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:27:31.250255 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:27:31.250485 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:27:31.251630 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:27:31.252802 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:27:31.252904 (Thread-1): finished collecting timing info
2021-05-17 21:27:31.253960 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:27:31.254390 (Thread-2): finished collecting timing info
2021-05-17 21:27:31.259619 (Thread-3): finished collecting timing info
2021-05-17 21:27:31.276032 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.277313 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.281104 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:31.281275 (Thread-4): finished collecting timing info
2021-05-17 21:27:31.281416 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:27:31.281507 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:27:31.281586 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:27:31.283831 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.283963 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:27:31.284052 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:27:31.284156 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:27:31.284236 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:27:31.284733 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:27:31.341872 (Thread-2): SQL status: DROP TABLE in 0.06 seconds
2021-05-17 21:27:31.342029 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2021-05-17 21:27:31.343826 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.343901 (Thread-3): SQL status: DROP TABLE in 0.06 seconds
2021-05-17 21:27:31.345589 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.345689 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:27:31.345755 (Thread-4): SQL status: DROP TABLE in 0.06 seconds
2021-05-17 21:27:31.347299 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:31.347392 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:27:31.348987 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.349087 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:27:31.349152 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:31.349306 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:27:31.349428 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:31.359319 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:27:31.359429 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:27:31.360529 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:27:31.360719 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:31.361685 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:27:31.361928 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.362851 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:27:31.363147 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:27:31.363382 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:31.363470 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.363727 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:27:31.363823 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:27:31.363888 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:31.364040 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.364132 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:31.364312 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.364417 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:31.364494 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:27:31.364580 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:31.364656 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    select
receiptId,
json_array_elements_text(rewardsreceiptitemlist::json) as items
from fetch_takehome.receipts_json_extract
  );
2021-05-17 21:27:31.364732 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.364859 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-17 21:27:31.364978 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:27:31.365131 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:27:31.365295 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.365447 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:27:31.384746 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-17 21:27:31.390651 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.390777 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:27:31.391226 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:31.393117 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.393218 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:27:31.393723 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:31.399818 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:27:31.399941 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.400016 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:27:31.402465 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:31.405360 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:27:31.405469 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:27:31.407692 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:31.408899 (Thread-4): finished collecting timing info
2021-05-17 21:27:31.409046 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:27:31.409467 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0db755d1-76f3-4917-b888-7d7b44d0ea08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107161f70>]}
2021-05-17 21:27:31.409846 (Thread-4): 17:27:31 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.16s]
2021-05-17 21:27:31.410017 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:27:31.412707 (Thread-2): SQL status: SELECT 6941 in 0.05 seconds
2021-05-17 21:27:31.414472 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.414570 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 21:27:31.415151 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:31.416069 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:27:31.416165 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.416237 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:27:31.416349 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-17 21:27:31.418268 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.418374 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:27:31.418525 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:31.420494 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:27:31.420793 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:31.420896 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:27:31.422731 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.422939 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:27:31.423129 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:31.424182 (Thread-2): finished collecting timing info
2021-05-17 21:27:31.424366 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:27:31.424466 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:31.424919 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0db755d1-76f3-4917-b888-7d7b44d0ea08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107162e20>]}
2021-05-17 21:27:31.425954 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:27:31.426389 (Thread-2): 17:27:31 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.18s]
2021-05-17 21:27:31.426489 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.426711 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:27:31.426833 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:27:31.432608 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-05-17 21:27:31.434222 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:27:31.434342 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:27:31.436151 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:31.437274 (Thread-1): finished collecting timing info
2021-05-17 21:27:31.437417 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:27:31.437752 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0db755d1-76f3-4917-b888-7d7b44d0ea08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069284c0>]}
2021-05-17 21:27:31.438043 (Thread-1): 17:27:31 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.19s]
2021-05-17 21:27:31.438176 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:27:32.084775 (Thread-3): SQL status: SELECT 1119 in 0.72 seconds
2021-05-17 21:27:32.087085 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:32.087207 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-17 21:27:32.087639 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:32.092977 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:32.093138 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-17 21:27:32.093658 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:27:32.094974 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 21:27:32.095134 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:32.095234 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 21:27:32.096116 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:32.098007 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:27:32.098197 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:27:32.101905 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:27:32.103779 (Thread-3): finished collecting timing info
2021-05-17 21:27:32.104000 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:27:32.104460 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0db755d1-76f3-4917-b888-7d7b44d0ea08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073579a0>]}
2021-05-17 21:27:32.104807 (Thread-3): 17:27:32 | 3 of 4 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.86s]
2021-05-17 21:27:32.104959 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:27:32.106397 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:27:32.106638 (MainThread): Using postgres connection "master".
2021-05-17 21:27:32.106778 (MainThread): On master: BEGIN
2021-05-17 21:27:32.106886 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:27:32.115730 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:27:32.115916 (MainThread): On master: COMMIT
2021-05-17 21:27:32.116030 (MainThread): Using postgres connection "master".
2021-05-17 21:27:32.116114 (MainThread): On master: COMMIT
2021-05-17 21:27:32.116309 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:27:32.116433 (MainThread): On master: Close
2021-05-17 21:27:32.116793 (MainThread): 17:27:32 | 
2021-05-17 21:27:32.116924 (MainThread): 17:27:32 | Finished running 4 table models in 0.96s.
2021-05-17 21:27:32.117040 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:27:32.117121 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:27:32.117199 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:27:32.117286 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:27:32.117361 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:27:32.121847 (MainThread): 
2021-05-17 21:27:32.122032 (MainThread): Completed successfully
2021-05-17 21:27:32.122164 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-05-17 21:27:32.122357 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd91f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd9130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd9d30>]}
2021-05-17 21:27:32.122559 (MainThread): Flushing usage events
2021-05-17 21:47:05.726246 (MainThread): Running with dbt=0.19.1
2021-05-17 21:47:05.847561 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:47:05.849327 (MainThread): Tracking: tracking
2021-05-17 21:47:05.869668 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ff7cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11201c520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11201c760>]}
2021-05-17 21:47:05.884227 (MainThread): Partial parsing not enabled
2021-05-17 21:47:05.886084 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:47:05.890790 (MainThread): Parsing macros/relations.sql
2021-05-17 21:47:05.893037 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:47:05.918527 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:47:05.922986 (MainThread): Parsing macros/core.sql
2021-05-17 21:47:05.928288 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:47:05.939241 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:47:05.941561 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:47:05.969217 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:47:06.020239 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:47:06.048699 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:47:06.051414 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:47:06.059449 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:47:06.074274 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:47:06.081708 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:47:06.088686 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:47:06.094076 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:47:06.095300 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:47:06.096556 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:47:06.098428 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:47:06.107612 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:47:06.109808 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:47:06.111690 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:47:06.155530 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:47:06.157632 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:47:06.159350 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:47:06.161234 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:47:06.168820 (MainThread): Partial parsing not enabled
2021-05-17 21:47:06.220542 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.231395 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.235370 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:47:06.238932 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:47:06.288525 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '64538541-4077-4434-91d8-409f7397ef89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121b4250>]}
2021-05-17 21:47:06.295817 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64538541-4077-4434-91d8-409f7397ef89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121e2c40>]}
2021-05-17 21:47:06.296187 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:47:06.297113 (MainThread): 
2021-05-17 21:47:06.297566 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:47:06.306957 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:47:06.341457 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:47:06.347421 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:47:06.347772 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:47:06.402728 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.06 seconds
2021-05-17 21:47:06.406003 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:47:06.407233 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:47:06.413471 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:47:06.413601 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:47:06.413706 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:47:06.421926 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:47:06.422094 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:47:06.422196 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:47:06.425289 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 21:47:06.426004 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:47:06.426203 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:47:06.430716 (MainThread): Using postgres connection "master".
2021-05-17 21:47:06.430842 (MainThread): On master: BEGIN
2021-05-17 21:47:06.430944 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:47:06.439396 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:47:06.439559 (MainThread): Using postgres connection "master".
2021-05-17 21:47:06.439656 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:47:06.452333 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 21:47:06.452863 (MainThread): On master: ROLLBACK
2021-05-17 21:47:06.453058 (MainThread): Using postgres connection "master".
2021-05-17 21:47:06.453146 (MainThread): On master: BEGIN
2021-05-17 21:47:06.453408 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:47:06.453513 (MainThread): On master: COMMIT
2021-05-17 21:47:06.453594 (MainThread): Using postgres connection "master".
2021-05-17 21:47:06.453663 (MainThread): On master: COMMIT
2021-05-17 21:47:06.453814 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:47:06.453908 (MainThread): On master: Close
2021-05-17 21:47:06.454158 (MainThread): 17:47:06 | Concurrency: 4 threads (target='dev')
2021-05-17 21:47:06.454276 (MainThread): 17:47:06 | 
2021-05-17 21:47:06.456372 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:47:06.456747 (Thread-1): 17:47:06 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:47:06.456893 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:47:06.457098 (Thread-2): 17:47:06 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:47:06.457396 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.457528 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:47:06.458604 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:47:06.458813 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:47:06.459038 (Thread-3): 17:47:06 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:47:06.459171 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:47:06.459444 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:47:06.459699 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:47:06.459971 (Thread-4): 17:47:06 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:47:06.460112 (Thread-1): finished collecting timing info
2021-05-17 21:47:06.460246 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:47:06.460479 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:47:06.460754 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.474554 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:47:06.478614 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.479557 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:47:06.479670 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:47:06.479849 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:47:06.480908 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:47:06.481018 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:47:06.481312 (Thread-2): finished collecting timing info
2021-05-17 21:47:06.481401 (Thread-3): finished collecting timing info
2021-05-17 21:47:06.483636 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:47:06.486588 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:47:06.486739 (Thread-4): finished collecting timing info
2021-05-17 21:47:06.486832 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:47:06.486924 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:47:06.489172 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.489594 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:47:06.489732 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:47:06.489834 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:47:06.490297 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:47:06.490400 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:47:06.493199 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.493516 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:47:06.493851 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:47:06.506115 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:47:06.506934 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.507107 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:47:06.507212 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:47:06.507290 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:47:06.507416 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:47:06.509584 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:47:06.511812 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:47:06.512165 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:47:06.514173 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.514321 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:47:06.514438 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:47:06.514549 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.514647 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:47:06.514917 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:47:06.515056 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:47:06.515217 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:47:06.515350 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:47:06.516725 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:47:06.518387 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:47:06.519914 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:47:06.520647 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:47:06.520791 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:47:06.521047 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:47:06.521174 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:47:06.521321 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:47:06.521522 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.521659 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:47:06.521741 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:47:06.521854 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:47:06.521956 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 21:47:06.522064 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:47:06.522373 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from (
select receiptId, json_array_elements_text(rewardsreceiptitemlist::json) as items
from fetch_takehome.receipts_json_extract
) as c;
  );
2021-05-17 21:47:06.522602 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:47:06.522760 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 21:47:06.522871 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.523000 (Thread-2): Postgres error: syntax error at or near "json_extract_path_text"
LINE 21: json_extract_path_text (to_json(items::json), 'originalFinal...
         ^

2021-05-17 21:47:06.523093 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 21:47:06.523198 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:47:06.523312 (Thread-2): On model.fetch_takehome.items_json_extract: ROLLBACK
2021-05-17 21:47:06.523679 (Thread-3): finished collecting timing info
2021-05-17 21:47:06.523880 (Thread-2): finished collecting timing info
2021-05-17 21:47:06.524015 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:47:06.524181 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:47:06.525087 (Thread-2): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  syntax error at or near "json_extract_path_text"
  LINE 21: json_extract_path_text (to_json(items::json), 'originalFinal...
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "json_extract_path_text"
LINE 21: json_extract_path_text (to_json(items::json), 'originalFinal...
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  syntax error at or near "json_extract_path_text"
  LINE 21: json_extract_path_text (to_json(items::json), 'originalFinal...
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:47:06.524609 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:47:06.534509 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64538541-4077-4434-91d8-409f7397ef89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118547f0>]}
2021-05-17 21:47:06.534804 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64538541-4077-4434-91d8-409f7397ef89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118592e0>]}
2021-05-17 21:47:06.535225 (Thread-3): 17:47:06 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.08s]
2021-05-17 21:47:06.535379 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:47:06.535684 (Thread-2): 17:47:06 | 2 of 4 ERROR creating table model fetch_takehome.items_json_extract.. [ERROR in 0.08s]
2021-05-17 21:47:06.536016 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:47:06.553393 (Thread-4): SQL status: SELECT 495 in 0.03 seconds
2021-05-17 21:47:06.559872 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.560014 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:47:06.560470 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:47:06.563299 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.563448 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:47:06.563965 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:47:06.573317 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:47:06.573486 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.573611 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:47:06.574896 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:47:06.580096 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:47:06.580309 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:47:06.583619 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:47:06.585089 (Thread-4): finished collecting timing info
2021-05-17 21:47:06.585344 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:47:06.585847 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64538541-4077-4434-91d8-409f7397ef89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112129520>]}
2021-05-17 21:47:06.586445 (Thread-4): 17:47:06 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.13s]
2021-05-17 21:47:06.586634 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:47:06.589541 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-17 21:47:06.592994 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.593204 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:47:06.594101 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:47:06.599416 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.599652 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:47:06.600383 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:47:06.602331 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:47:06.602553 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.602704 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:47:06.604068 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:47:06.606559 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:47:06.606718 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:47:06.609687 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:47:06.611081 (Thread-1): finished collecting timing info
2021-05-17 21:47:06.611275 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:47:06.611899 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64538541-4077-4434-91d8-409f7397ef89', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118546a0>]}
2021-05-17 21:47:06.612372 (Thread-1): 17:47:06 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.15s]
2021-05-17 21:47:06.612628 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:47:06.614376 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:47:06.614574 (MainThread): Using postgres connection "master".
2021-05-17 21:47:06.614697 (MainThread): On master: BEGIN
2021-05-17 21:47:06.614819 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:47:06.627712 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:47:06.627960 (MainThread): On master: COMMIT
2021-05-17 21:47:06.628068 (MainThread): Using postgres connection "master".
2021-05-17 21:47:06.628159 (MainThread): On master: COMMIT
2021-05-17 21:47:06.628391 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:47:06.628614 (MainThread): On master: Close
2021-05-17 21:47:06.629214 (MainThread): 17:47:06 | 
2021-05-17 21:47:06.629455 (MainThread): 17:47:06 | Finished running 4 table models in 0.33s.
2021-05-17 21:47:06.629620 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:47:06.629777 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:47:06.629896 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:47:06.630008 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:47:06.630115 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:47:06.636401 (MainThread): 
2021-05-17 21:47:06.636589 (MainThread): Completed with 2 errors and 0 warnings:
2021-05-17 21:47:06.636719 (MainThread): 
2021-05-17 21:47:06.636842 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 21:47:06.637016 (MainThread):   syntax error at or near "from"
2021-05-17 21:47:06.637188 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 21:47:06.637357 (MainThread):            ^
2021-05-17 21:47:06.637564 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:47:06.637763 (MainThread): 
2021-05-17 21:47:06.637959 (MainThread): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
2021-05-17 21:47:06.638081 (MainThread):   syntax error at or near "json_extract_path_text"
2021-05-17 21:47:06.638185 (MainThread):   LINE 21: json_extract_path_text (to_json(items::json), 'originalFinal...
2021-05-17 21:47:06.638286 (MainThread):            ^
2021-05-17 21:47:06.638414 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:47:06.638649 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-05-17 21:47:06.638965 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112175d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111307280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11207c9a0>]}
2021-05-17 21:47:06.639297 (MainThread): Flushing usage events
2021-05-17 21:48:38.192894 (MainThread): Running with dbt=0.19.1
2021-05-17 21:48:38.302700 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:48:38.308948 (MainThread): Tracking: tracking
2021-05-17 21:48:38.328043 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b01e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b26610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b26e50>]}
2021-05-17 21:48:38.343598 (MainThread): Partial parsing not enabled
2021-05-17 21:48:38.345414 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:48:38.350019 (MainThread): Parsing macros/relations.sql
2021-05-17 21:48:38.352162 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:48:38.377647 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:48:38.381026 (MainThread): Parsing macros/core.sql
2021-05-17 21:48:38.385457 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:48:38.395293 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:48:38.397604 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:48:38.419569 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:48:38.458043 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:48:38.482248 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:48:38.484410 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:48:38.490942 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:48:38.505579 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:48:38.514029 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:48:38.521854 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:48:38.527611 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:48:38.528931 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:48:38.530270 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:48:38.532259 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:48:38.541894 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:48:38.544137 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:48:38.546094 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:48:38.590548 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:48:38.592725 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:48:38.594563 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:48:38.596557 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:48:38.604211 (MainThread): Partial parsing not enabled
2021-05-17 21:48:38.658966 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:38.670939 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:38.675241 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:48:38.679624 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:48:38.733510 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7484142d-c15c-43b4-8e75-ed48c3349722', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cbe460>]}
2021-05-17 21:48:38.738263 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7484142d-c15c-43b4-8e75-ed48c3349722', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cc9af0>]}
2021-05-17 21:48:38.738541 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:48:38.739201 (MainThread): 
2021-05-17 21:48:38.739519 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:48:38.740512 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:48:38.753275 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:48:38.753438 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:48:38.753553 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:48:38.954517 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.20 seconds
2021-05-17 21:48:38.958651 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:48:38.960227 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:48:38.967011 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:48:38.967364 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:48:38.967529 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:48:38.976408 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:48:38.976576 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:48:38.976676 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:48:38.980154 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 21:48:38.981022 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:48:38.981274 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:48:38.986220 (MainThread): Using postgres connection "master".
2021-05-17 21:48:38.986365 (MainThread): On master: BEGIN
2021-05-17 21:48:38.986476 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:48:38.994885 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:48:38.995058 (MainThread): Using postgres connection "master".
2021-05-17 21:48:38.995160 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:48:39.008980 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 21:48:39.009584 (MainThread): On master: ROLLBACK
2021-05-17 21:48:39.009815 (MainThread): Using postgres connection "master".
2021-05-17 21:48:39.009918 (MainThread): On master: BEGIN
2021-05-17 21:48:39.010207 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:48:39.010345 (MainThread): On master: COMMIT
2021-05-17 21:48:39.010446 (MainThread): Using postgres connection "master".
2021-05-17 21:48:39.010532 (MainThread): On master: COMMIT
2021-05-17 21:48:39.010729 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:48:39.010869 (MainThread): On master: Close
2021-05-17 21:48:39.011178 (MainThread): 17:48:39 | Concurrency: 4 threads (target='dev')
2021-05-17 21:48:39.011321 (MainThread): 17:48:39 | 
2021-05-17 21:48:39.013616 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:48:39.014028 (Thread-1): 17:48:39 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:48:39.014330 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.014460 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:48:39.015640 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:48:39.015876 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:48:39.016030 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:48:39.016257 (Thread-2): 17:48:39 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:48:39.016541 (Thread-3): 17:48:39 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:48:39.016692 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:48:39.016909 (Thread-1): finished collecting timing info
2021-05-17 21:48:39.017276 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:48:39.017537 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:48:39.017838 (Thread-4): 17:48:39 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:48:39.029010 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:48:39.039894 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.040030 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:48:39.040333 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.041767 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:48:39.041906 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:48:39.043055 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:48:39.043218 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:48:39.043471 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:48:39.044788 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:48:39.044982 (Thread-2): finished collecting timing info
2021-05-17 21:48:39.045263 (Thread-3): finished collecting timing info
2021-05-17 21:48:39.049687 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:48:39.053770 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:48:39.054047 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:48:39.054231 (Thread-4): finished collecting timing info
2021-05-17 21:48:39.054365 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:48:39.054512 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:48:39.058094 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.058409 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:48:39.058850 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:48:39.059295 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:48:39.059500 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:48:39.089771 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.089991 (Thread-2): SQL status: DROP TABLE in 0.04 seconds
2021-05-17 21:48:39.090104 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:48:39.090229 (Thread-3): SQL status: DROP TABLE in 0.03 seconds
2021-05-17 21:48:39.092976 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:48:39.095262 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:48:39.095421 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:48:39.095590 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:48:39.095745 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:48:39.109411 (Thread-4): SQL status: DROP TABLE in 0.05 seconds
2021-05-17 21:48:39.109774 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:48:39.112941 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.113086 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:48:39.113215 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:48:39.113536 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:48:39.115422 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:48:39.116846 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:48:39.117181 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.117454 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:48:39.117936 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:48:39.118033 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:48:39.119368 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:48:39.119498 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:48:39.119658 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:48:39.119968 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:48:39.120109 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:48:39.120391 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.120483 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.120558 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:48:39.120736 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:48:39.120872 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:48:39.120973 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:48:39.121093 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:48:39.121303 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:48:39.121534 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:48:39.121672 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from (
select receiptId, json_array_elements_text(rewardsreceiptitemlist::json) as items
from fetch_takehome.receipts_json_extract
) as c
  );
2021-05-17 21:48:39.121791 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 21:48:39.121899 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.122136 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:48:39.122393 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 21:48:39.122524 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 21:48:39.122823 (Thread-3): finished collecting timing info
2021-05-17 21:48:39.122987 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:48:39.123321 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:48:39.129991 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7484142d-c15c-43b4-8e75-ed48c3349722', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10405df10>]}
2021-05-17 21:48:39.130388 (Thread-3): 17:48:39 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.11s]
2021-05-17 21:48:39.130549 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:48:39.181672 (Thread-2): Postgres error: column "partneritemid" specified more than once

2021-05-17 21:48:39.181842 (Thread-2): On model.fetch_takehome.items_json_extract: ROLLBACK
2021-05-17 21:48:39.182085 (Thread-2): finished collecting timing info
2021-05-17 21:48:39.182224 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:48:39.182525 (Thread-2): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  column "partneritemid" specified more than once
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.DuplicateColumn: column "partneritemid" specified more than once


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  column "partneritemid" specified more than once
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:48:39.183010 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7484142d-c15c-43b4-8e75-ed48c3349722', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cf0160>]}
2021-05-17 21:48:39.183293 (Thread-2): 17:48:39 | 2 of 4 ERROR creating table model fetch_takehome.items_json_extract.. [ERROR in 0.17s]
2021-05-17 21:48:39.183416 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:48:39.191525 (Thread-4): SQL status: SELECT 495 in 0.07 seconds
2021-05-17 21:48:39.196986 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.197202 (Thread-1): SQL status: SELECT 1167 in 0.08 seconds
2021-05-17 21:48:39.197304 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:48:39.199651 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.199852 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:48:39.200085 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:48:39.201802 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.201907 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:48:39.202023 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:48:39.203587 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.203690 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:48:39.203811 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:48:39.209800 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:48:39.209912 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.209991 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:48:39.210104 (Thread-1): SQL status: ALTER TABLE in 0.01 seconds
2021-05-17 21:48:39.211013 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:48:39.211108 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.211185 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:48:39.211294 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:48:39.213941 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:48:39.214049 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:48:39.214169 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:48:39.215379 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:48:39.215479 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:48:39.215816 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:48:39.216758 (Thread-4): finished collecting timing info
2021-05-17 21:48:39.216884 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:48:39.217207 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7484142d-c15c-43b4-8e75-ed48c3349722', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104caf130>]}
2021-05-17 21:48:39.217482 (Thread-4): 17:48:39 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.18s]
2021-05-17 21:48:39.217579 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:48:39.217803 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:48:39.219410 (Thread-1): finished collecting timing info
2021-05-17 21:48:39.219847 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:48:39.220231 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7484142d-c15c-43b4-8e75-ed48c3349722', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c9ba90>]}
2021-05-17 21:48:39.220620 (Thread-1): 17:48:39 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.21s]
2021-05-17 21:48:39.220787 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:48:39.222153 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:48:39.222302 (MainThread): Using postgres connection "master".
2021-05-17 21:48:39.222380 (MainThread): On master: BEGIN
2021-05-17 21:48:39.222460 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:48:39.231213 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:48:39.231547 (MainThread): On master: COMMIT
2021-05-17 21:48:39.231705 (MainThread): Using postgres connection "master".
2021-05-17 21:48:39.231793 (MainThread): On master: COMMIT
2021-05-17 21:48:39.232012 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:48:39.232216 (MainThread): On master: Close
2021-05-17 21:48:39.232780 (MainThread): 17:48:39 | 
2021-05-17 21:48:39.232933 (MainThread): 17:48:39 | Finished running 4 table models in 0.49s.
2021-05-17 21:48:39.233073 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:48:39.233250 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:48:39.233377 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:48:39.233482 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:48:39.233576 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:48:39.239400 (MainThread): 
2021-05-17 21:48:39.239684 (MainThread): Completed with 2 errors and 0 warnings:
2021-05-17 21:48:39.240030 (MainThread): 
2021-05-17 21:48:39.240322 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 21:48:39.240470 (MainThread):   syntax error at or near "from"
2021-05-17 21:48:39.240618 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 21:48:39.240784 (MainThread):            ^
2021-05-17 21:48:39.240923 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:48:39.241073 (MainThread): 
2021-05-17 21:48:39.241232 (MainThread): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
2021-05-17 21:48:39.241373 (MainThread):   column "partneritemid" specified more than once
2021-05-17 21:48:39.241505 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:48:39.241660 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-05-17 21:48:39.241914 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043606a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b71a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104af3dc0>]}
2021-05-17 21:48:39.242204 (MainThread): Flushing usage events
2021-05-17 21:49:23.269530 (MainThread): Running with dbt=0.19.1
2021-05-17 21:49:23.362139 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:49:23.363192 (MainThread): Tracking: tracking
2021-05-17 21:49:23.379575 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9c4eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9eb6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9ebf10>]}
2021-05-17 21:49:23.391662 (MainThread): Partial parsing not enabled
2021-05-17 21:49:23.392955 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:49:23.396955 (MainThread): Parsing macros/relations.sql
2021-05-17 21:49:23.398841 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:49:23.420568 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:49:23.423783 (MainThread): Parsing macros/core.sql
2021-05-17 21:49:23.428208 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:49:23.437856 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:49:23.439875 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:49:23.459509 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:49:23.495123 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:49:23.518097 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:49:23.520250 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:49:23.527076 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:49:23.542121 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:49:23.549694 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:49:23.556751 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:49:23.562527 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:49:23.563859 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:49:23.565213 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:49:23.567093 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:49:23.577326 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:49:23.579691 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:49:23.581790 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:49:23.627775 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:49:23.629999 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:49:23.631757 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:49:23.633701 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:49:23.641600 (MainThread): Partial parsing not enabled
2021-05-17 21:49:23.689165 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:23.698198 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:23.701270 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:49:23.703934 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:23.747387 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b135780-2b6f-4c5b-b806-148768bba72b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb837c0>]}
2021-05-17 21:49:23.750734 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b135780-2b6f-4c5b-b806-148768bba72b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fba9460>]}
2021-05-17 21:49:23.750944 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:49:23.751542 (MainThread): 
2021-05-17 21:49:23.751813 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:49:23.752628 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:49:23.761293 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:49:23.761404 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:49:23.761491 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:49:23.839925 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.08 seconds
2021-05-17 21:49:23.842904 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:49:23.844218 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:49:23.851674 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:49:23.851838 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:49:23.851966 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:49:23.861229 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:49:23.861409 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:49:23.861514 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:49:23.865623 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 21:49:23.866860 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:49:23.867239 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:49:23.873738 (MainThread): Using postgres connection "master".
2021-05-17 21:49:23.873896 (MainThread): On master: BEGIN
2021-05-17 21:49:23.874013 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:49:23.884107 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:49:23.884317 (MainThread): Using postgres connection "master".
2021-05-17 21:49:23.884418 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:49:23.900338 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-17 21:49:23.900937 (MainThread): On master: ROLLBACK
2021-05-17 21:49:23.901156 (MainThread): Using postgres connection "master".
2021-05-17 21:49:23.901253 (MainThread): On master: BEGIN
2021-05-17 21:49:23.901548 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:49:23.901673 (MainThread): On master: COMMIT
2021-05-17 21:49:23.901770 (MainThread): Using postgres connection "master".
2021-05-17 21:49:23.901851 (MainThread): On master: COMMIT
2021-05-17 21:49:23.902054 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:49:23.902192 (MainThread): On master: Close
2021-05-17 21:49:23.902501 (MainThread): 17:49:23 | Concurrency: 4 threads (target='dev')
2021-05-17 21:49:23.902640 (MainThread): 17:49:23 | 
2021-05-17 21:49:23.905135 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:49:23.905561 (Thread-1): 17:49:23 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:49:23.905734 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:49:23.906076 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:23.906179 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:49:23.906378 (Thread-2): 17:49:23 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:49:23.906470 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:49:23.906633 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:49:23.906815 (Thread-3): 17:49:23 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:49:23.907085 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:23.907381 (Thread-4): 17:49:23 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:49:23.908632 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:49:23.908944 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:49:23.909084 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:49:23.909471 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:23.909738 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:49:23.911060 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:49:23.911191 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:49:23.911310 (Thread-1): finished collecting timing info
2021-05-17 21:49:23.912523 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:49:23.913682 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:49:23.924677 (Thread-2): finished collecting timing info
2021-05-17 21:49:23.933549 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:23.933660 (Thread-3): finished collecting timing info
2021-05-17 21:49:23.935882 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:23.935997 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:49:23.939745 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:49:23.939942 (Thread-4): finished collecting timing info
2021-05-17 21:49:23.940103 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:49:23.940204 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:49:23.940282 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:49:23.942473 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:23.942596 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:49:23.942858 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:49:23.942981 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:49:23.943417 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:49:23.951941 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:49:23.954455 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:23.954636 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:49:23.954846 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:49:23.956968 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:49:23.957126 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:49:23.957307 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:49:23.957415 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:49:23.959392 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:23.961202 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:23.961290 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:49:23.961481 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:49:23.961642 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:49:23.961729 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:49:23.971883 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:49:23.973146 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:49:23.973268 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:49:23.973446 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:49:23.974655 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:49:23.975744 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:49:23.975893 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:49:23.975987 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:23.976258 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:49:23.976523 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:49:23.976660 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:23.976759 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:23.976955 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:49:23.977060 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:49:23.977168 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:49:23.977232 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:49:23.977370 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:23.977474 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:49:23.977611 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:49:23.977696 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:49:23.977781 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:23.977840 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:49:23.977917 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 21:49:23.978060 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from (
select receiptId, json_array_elements_text(rewardsreceiptitemlist::json) as items
from fetch_takehome.receipts_json_extract
) as c
  );
2021-05-17 21:49:23.978163 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:23.978351 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:49:23.978565 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 21:49:23.978666 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 21:49:23.978929 (Thread-3): finished collecting timing info
2021-05-17 21:49:23.979050 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:49:23.979327 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:49:23.986673 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b135780-2b6f-4c5b-b806-148768bba72b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9a8e20>]}
2021-05-17 21:49:23.987044 (Thread-3): 17:49:23 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.08s]
2021-05-17 21:49:23.987170 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:49:24.003741 (Thread-4): SQL status: SELECT 495 in 0.03 seconds
2021-05-17 21:49:24.010843 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:24.010978 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:49:24.011342 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:49:24.013097 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:24.013245 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:49:24.013807 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:49:24.026100 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:49:24.026341 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:24.026477 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:49:24.027210 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:49:24.032518 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:49:24.032748 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:49:24.035612 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:49:24.037240 (Thread-4): finished collecting timing info
2021-05-17 21:49:24.037505 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:49:24.038088 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b135780-2b6f-4c5b-b806-148768bba72b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9a8190>]}
2021-05-17 21:49:24.038545 (Thread-4): 17:49:24 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.13s]
2021-05-17 21:49:24.038752 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:49:24.053857 (Thread-1): SQL status: SELECT 1167 in 0.08 seconds
2021-05-17 21:49:24.058549 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:24.058735 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:49:24.059463 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:49:24.062692 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:24.062896 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:49:24.063540 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:49:24.065805 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:49:24.090439 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:24.090703 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:49:24.091426 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:49:24.094956 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:49:24.095152 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:49:24.098320 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:49:24.099803 (Thread-1): finished collecting timing info
2021-05-17 21:49:24.099976 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:49:24.100542 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b135780-2b6f-4c5b-b806-148768bba72b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef23160>]}
2021-05-17 21:49:24.100910 (Thread-1): 17:49:24 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.19s]
2021-05-17 21:49:24.101159 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:49:25.099148 (Thread-2): SQL status: SELECT 6941 in 1.12 seconds
2021-05-17 21:49:25.101191 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:25.101291 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 21:49:25.101632 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:49:25.103269 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:25.103362 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 21:49:25.103839 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:49:25.104731 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:49:25.104820 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:25.104890 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:49:25.105440 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:49:25.106659 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:49:25.106751 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:49:25.110670 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:49:25.111711 (Thread-2): finished collecting timing info
2021-05-17 21:49:25.111839 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:49:25.112142 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b135780-2b6f-4c5b-b806-148768bba72b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10faea670>]}
2021-05-17 21:49:25.112398 (Thread-2): 17:49:25 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.21s]
2021-05-17 21:49:25.112530 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:49:25.113572 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:49:25.113713 (MainThread): Using postgres connection "master".
2021-05-17 21:49:25.113793 (MainThread): On master: BEGIN
2021-05-17 21:49:25.113880 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:49:25.122122 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:49:25.122296 (MainThread): On master: COMMIT
2021-05-17 21:49:25.122389 (MainThread): Using postgres connection "master".
2021-05-17 21:49:25.122471 (MainThread): On master: COMMIT
2021-05-17 21:49:25.122651 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:49:25.122767 (MainThread): On master: Close
2021-05-17 21:49:25.123116 (MainThread): 17:49:25 | 
2021-05-17 21:49:25.123244 (MainThread): 17:49:25 | Finished running 4 table models in 1.37s.
2021-05-17 21:49:25.123346 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:49:25.123423 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:49:25.123497 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:49:25.123569 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:49:25.123640 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:49:25.129282 (MainThread): 
2021-05-17 21:49:25.129453 (MainThread): Completed with 1 error and 0 warnings:
2021-05-17 21:49:25.129569 (MainThread): 
2021-05-17 21:49:25.129678 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 21:49:25.129783 (MainThread):   syntax error at or near "from"
2021-05-17 21:49:25.129874 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 21:49:25.129963 (MainThread):            ^
2021-05-17 21:49:25.130051 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:49:25.130154 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-05-17 21:49:25.130334 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9c43d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f9c4820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7581f0>]}
2021-05-17 21:49:25.130524 (MainThread): Flushing usage events
2021-05-17 21:56:24.883653 (MainThread): Running with dbt=0.19.1
2021-05-17 21:56:24.968325 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:56:24.969446 (MainThread): Tracking: tracking
2021-05-17 21:56:24.989978 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b60dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b7c670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b7ceb0>]}
2021-05-17 21:56:25.004642 (MainThread): Partial parsing not enabled
2021-05-17 21:56:25.006479 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:56:25.011051 (MainThread): Parsing macros/relations.sql
2021-05-17 21:56:25.013244 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:56:25.039199 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:56:25.043618 (MainThread): Parsing macros/core.sql
2021-05-17 21:56:25.048980 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:56:25.060660 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:56:25.063386 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:56:25.087351 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:56:25.129242 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:56:25.151159 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:56:25.153403 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:56:25.160595 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:56:25.175382 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:56:25.182737 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:56:25.190207 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:56:25.196159 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:56:25.197714 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:56:25.199247 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:56:25.201886 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:56:25.213137 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:56:25.215998 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:56:25.218330 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:56:25.266292 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:56:25.282116 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:56:25.284655 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:56:25.287225 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:56:25.297542 (MainThread): Partial parsing not enabled
2021-05-17 21:56:25.372071 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.383564 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.387657 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:56:25.391985 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:56:25.447057 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de7085db-ecd3-4711-9645-0a7e7f4b6e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d0f760>]}
2021-05-17 21:56:25.451275 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de7085db-ecd3-4711-9645-0a7e7f4b6e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d35460>]}
2021-05-17 21:56:25.451560 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:56:25.452333 (MainThread): 
2021-05-17 21:56:25.452675 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:56:25.453674 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:56:25.465561 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:56:25.465716 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:56:25.465832 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:56:25.633491 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.17 seconds
2021-05-17 21:56:25.637926 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:56:25.639831 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:56:25.647633 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:56:25.647793 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:56:25.647907 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:56:25.657636 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:56:25.657903 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:56:25.658030 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:56:25.661890 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 21:56:25.662695 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:56:25.662960 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:56:25.668040 (MainThread): Using postgres connection "master".
2021-05-17 21:56:25.668195 (MainThread): On master: BEGIN
2021-05-17 21:56:25.668310 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:56:25.677801 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:56:25.678025 (MainThread): Using postgres connection "master".
2021-05-17 21:56:25.678159 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:56:25.694235 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-17 21:56:25.697041 (MainThread): On master: ROLLBACK
2021-05-17 21:56:25.697327 (MainThread): Using postgres connection "master".
2021-05-17 21:56:25.697478 (MainThread): On master: BEGIN
2021-05-17 21:56:25.697811 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:56:25.697951 (MainThread): On master: COMMIT
2021-05-17 21:56:25.698059 (MainThread): Using postgres connection "master".
2021-05-17 21:56:25.698148 (MainThread): On master: COMMIT
2021-05-17 21:56:25.698339 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:56:25.698461 (MainThread): On master: Close
2021-05-17 21:56:25.698768 (MainThread): 17:56:25 | Concurrency: 4 threads (target='dev')
2021-05-17 21:56:25.698907 (MainThread): 17:56:25 | 
2021-05-17 21:56:25.701584 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:56:25.701969 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:56:25.702215 (Thread-1): 17:56:25 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:56:25.702322 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:56:25.702483 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:56:25.702735 (Thread-2): 17:56:25 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:56:25.703137 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.703377 (Thread-3): 17:56:25 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:56:25.703602 (Thread-4): 17:56:25 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:56:25.703968 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:56:25.704125 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:56:25.704506 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:56:25.704758 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.704917 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:56:25.706322 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:56:25.706496 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:56:25.706628 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:56:25.707913 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:56:25.709412 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:56:25.710740 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:56:25.710928 (Thread-1): finished collecting timing info
2021-05-17 21:56:25.711512 (Thread-2): finished collecting timing info
2021-05-17 21:56:25.716814 (Thread-3): finished collecting timing info
2021-05-17 21:56:25.756470 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.757771 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:56:25.759369 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:56:25.759468 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:56:25.759560 (Thread-4): finished collecting timing info
2021-05-17 21:56:25.759693 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:56:25.759796 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:56:25.759905 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:56:25.762789 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.762992 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:56:25.763143 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:56:25.763477 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:56:25.763944 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:56:25.774977 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:56:25.775174 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:56:25.777426 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.779609 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:56:25.779757 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:56:25.779858 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:56:25.779936 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:56:25.780047 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:56:25.782028 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:56:25.784143 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.784336 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:56:25.784473 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:56:25.784560 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:56:25.784667 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:56:25.797226 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:56:25.797584 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:56:25.798060 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:56:25.798340 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:56:25.798569 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:56:25.799786 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:56:25.799902 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.801215 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:56:25.801329 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:56:25.801563 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:56:25.801928 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:56:25.802329 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.802463 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:56:25.802552 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:56:25.802656 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:56:25.802732 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:56:25.802900 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:56:25.803074 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:56:25.803255 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.803370 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from (
select receiptId,
json_array_elements_text(rewardsreceiptitemlist::json) as items
from fetch_takehome.receipts_json_extract
) as c;
  );
2021-05-17 21:56:25.803454 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:56:25.803552 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:56:25.803642 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:56:25.803829 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.803941 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 21:56:25.804164 (Thread-2): Postgres error: syntax error at or near ";"
LINE 40: ) as c;
               ^

2021-05-17 21:56:25.804254 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:56:25.804436 (Thread-2): On model.fetch_takehome.items_json_extract: ROLLBACK
2021-05-17 21:56:25.804747 (Thread-2): finished collecting timing info
2021-05-17 21:56:25.804879 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 21:56:25.804984 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:56:25.805091 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 21:56:25.805816 (Thread-3): finished collecting timing info
2021-05-17 21:56:25.805960 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:56:25.805454 (Thread-2): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  syntax error at or near ";"
  LINE 40: ) as c;
                 ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ";"
LINE 40: ) as c;
               ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  syntax error at or near ";"
  LINE 40: ) as c;
                 ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:56:25.806328 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:56:25.814563 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de7085db-ecd3-4711-9645-0a7e7f4b6e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098db7f0>]}
2021-05-17 21:56:25.814910 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de7085db-ecd3-4711-9645-0a7e7f4b6e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b40610>]}
2021-05-17 21:56:25.815281 (Thread-2): 17:56:25 | 2 of 4 ERROR creating table model fetch_takehome.items_json_extract.. [ERROR in 0.11s]
2021-05-17 21:56:25.815552 (Thread-3): 17:56:25 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.11s]
2021-05-17 21:56:25.815785 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:56:25.816080 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:56:25.905076 (Thread-4): SQL status: SELECT 495 in 0.10 seconds
2021-05-17 21:56:25.912523 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.912671 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:56:25.913167 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:56:25.915504 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.915614 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:56:25.916084 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:56:25.923949 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:56:25.924098 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.924187 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:56:25.924868 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:56:25.928716 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:56:25.928861 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:56:25.930874 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:56:25.932547 (Thread-4): finished collecting timing info
2021-05-17 21:56:25.932718 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:56:25.933241 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de7085db-ecd3-4711-9645-0a7e7f4b6e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ceab80>]}
2021-05-17 21:56:25.933662 (Thread-4): 17:56:25 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.23s]
2021-05-17 21:56:25.933804 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:56:25.940881 (Thread-1): SQL status: SELECT 1167 in 0.14 seconds
2021-05-17 21:56:25.943580 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.943733 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:56:25.944186 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:56:25.946664 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.946778 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:56:25.947200 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:56:25.948238 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:56:25.948341 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.948424 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:56:25.949027 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:56:25.950689 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:56:25.950795 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:56:25.953643 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:56:25.954935 (Thread-1): finished collecting timing info
2021-05-17 21:56:25.955178 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:56:25.955585 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de7085db-ecd3-4711-9645-0a7e7f4b6e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b40e80>]}
2021-05-17 21:56:25.955886 (Thread-1): 17:56:25 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.25s]
2021-05-17 21:56:25.956017 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:56:25.957225 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:56:25.957374 (MainThread): Using postgres connection "master".
2021-05-17 21:56:25.957464 (MainThread): On master: BEGIN
2021-05-17 21:56:25.957556 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:56:25.966572 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:56:25.967487 (MainThread): On master: COMMIT
2021-05-17 21:56:25.967606 (MainThread): Using postgres connection "master".
2021-05-17 21:56:25.967703 (MainThread): On master: COMMIT
2021-05-17 21:56:25.967995 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:56:25.968342 (MainThread): On master: Close
2021-05-17 21:56:25.969327 (MainThread): 17:56:25 | 
2021-05-17 21:56:25.969658 (MainThread): 17:56:25 | Finished running 4 table models in 0.52s.
2021-05-17 21:56:25.969849 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:56:25.969968 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:56:25.970076 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:56:25.970180 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:56:25.970283 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:56:25.978994 (MainThread): 
2021-05-17 21:56:25.979280 (MainThread): Completed with 2 errors and 0 warnings:
2021-05-17 21:56:25.979463 (MainThread): 
2021-05-17 21:56:25.979647 (MainThread): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
2021-05-17 21:56:25.979812 (MainThread):   syntax error at or near ";"
2021-05-17 21:56:25.980055 (MainThread):   LINE 40: ) as c;
2021-05-17 21:56:25.980176 (MainThread):                  ^
2021-05-17 21:56:25.980295 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-17 21:56:25.980420 (MainThread): 
2021-05-17 21:56:25.980658 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 21:56:25.980848 (MainThread):   syntax error at or near "from"
2021-05-17 21:56:25.981002 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 21:56:25.981152 (MainThread):            ^
2021-05-17 21:56:25.981297 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:56:25.981464 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
2021-05-17 21:56:25.981733 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b8db20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109302ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ec2d30>]}
2021-05-17 21:56:25.982038 (MainThread): Flushing usage events
2021-05-17 21:57:57.744650 (MainThread): Running with dbt=0.19.1
2021-05-17 21:57:57.834644 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:57:57.836459 (MainThread): Tracking: tracking
2021-05-17 21:57:57.870584 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107541e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107567640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107567e80>]}
2021-05-17 21:57:57.885061 (MainThread): Partial parsing not enabled
2021-05-17 21:57:57.886650 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:57:57.891349 (MainThread): Parsing macros/relations.sql
2021-05-17 21:57:57.893557 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:57:57.916466 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:57:57.919673 (MainThread): Parsing macros/core.sql
2021-05-17 21:57:57.924175 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:57:57.933946 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:57:57.936047 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:57:57.957676 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:57:57.999499 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:57:58.026045 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:57:58.028749 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:57:58.036912 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:57:58.054180 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:57:58.063131 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:57:58.071645 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:57:58.078394 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:57:58.079790 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:57:58.081324 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:57:58.083548 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:57:58.095394 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:57:58.098269 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:57:58.100583 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:57:58.158543 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:57:58.161326 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:57:58.163701 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:57:58.166220 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:57:58.176112 (MainThread): Partial parsing not enabled
2021-05-17 21:57:58.233539 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.245181 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.249640 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:57:58.253264 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:58.308082 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed5afa14-c9b8-4595-ae99-eb462baf0598', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076fd190>]}
2021-05-17 21:57:58.312408 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed5afa14-c9b8-4595-ae99-eb462baf0598', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077253d0>]}
2021-05-17 21:57:58.312699 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:57:58.313386 (MainThread): 
2021-05-17 21:57:58.313715 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:57:58.315294 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:57:58.334950 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:57:58.335186 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:57:58.335362 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:57:58.404996 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.07 seconds
2021-05-17 21:57:58.444271 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:57:58.462443 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:57:58.523328 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:57:58.539563 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:57:58.560277 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:57:58.587644 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2021-05-17 21:57:58.587812 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:57:58.587925 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:57:58.591139 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 21:57:58.591822 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:57:58.592045 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:57:58.596271 (MainThread): Using postgres connection "master".
2021-05-17 21:57:58.596402 (MainThread): On master: BEGIN
2021-05-17 21:57:58.596496 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:57:58.604128 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:57:58.604287 (MainThread): Using postgres connection "master".
2021-05-17 21:57:58.604379 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:57:58.617536 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 21:57:58.618169 (MainThread): On master: ROLLBACK
2021-05-17 21:57:58.618449 (MainThread): Using postgres connection "master".
2021-05-17 21:57:58.618571 (MainThread): On master: BEGIN
2021-05-17 21:57:58.618905 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:57:58.619030 (MainThread): On master: COMMIT
2021-05-17 21:57:58.619129 (MainThread): Using postgres connection "master".
2021-05-17 21:57:58.619213 (MainThread): On master: COMMIT
2021-05-17 21:57:58.619396 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:57:58.619511 (MainThread): On master: Close
2021-05-17 21:57:58.619800 (MainThread): 17:57:58 | Concurrency: 4 threads (target='dev')
2021-05-17 21:57:58.619934 (MainThread): 17:57:58 | 
2021-05-17 21:57:58.622411 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:57:58.622877 (Thread-1): 17:57:58 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:57:58.623248 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.623405 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:57:58.623547 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:57:58.623687 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:57:58.625063 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:57:58.625186 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:57:58.625432 (Thread-2): 17:57:58 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:57:58.625624 (Thread-3): 17:57:58 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:57:58.625957 (Thread-4): 17:57:58 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:57:58.626380 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:58.647725 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:57:58.647886 (Thread-1): finished collecting timing info
2021-05-17 21:57:58.648305 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.648449 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:57:58.648622 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:57:58.654005 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:57:58.669544 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.671131 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:57:58.672498 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:57:58.673706 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:57:58.673856 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:57:58.674529 (Thread-3): finished collecting timing info
2021-05-17 21:57:58.674684 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:57:58.674801 (Thread-2): finished collecting timing info
2021-05-17 21:57:58.678147 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:57:58.678349 (Thread-4): finished collecting timing info
2021-05-17 21:57:58.682596 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:58.682778 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:57:58.685529 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.685733 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:57:58.685924 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:57:58.686099 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:57:58.686300 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:57:58.686657 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:57:58.688080 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:57:58.691143 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.691308 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:57:58.691808 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:57:58.705124 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:57:58.705417 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:57:58.705577 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:57:58.707529 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:57:58.709730 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.709964 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.710061 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:57:58.710148 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:57:58.710261 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:57:58.710369 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:57:58.712230 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:58.712555 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:57:58.712689 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:57:58.712855 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:57:58.712951 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:57:58.714375 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:57:58.714523 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:57:58.715761 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:57:58.715896 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.717248 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:57:58.717604 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:57:58.718093 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:57:58.718373 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.718479 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:57:58.718621 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:58.718753 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:57:58.718953 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:57:58.719096 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:57:58.719346 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:57:58.719462 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:57:58.719555 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:57:58.719632 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 21:57:58.719740 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.719833 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:58.720010 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:57:58.720134 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId,
    json_array_elements_text(rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from a
  );
2021-05-17 21:57:58.720272 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 21:57:58.720554 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 21:57:58.720822 (Thread-3): finished collecting timing info
2021-05-17 21:57:58.720981 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:57:58.721311 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:57:58.728695 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed5afa14-c9b8-4595-ae99-eb462baf0598', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d1bb0>]}
2021-05-17 21:57:58.729039 (Thread-3): 17:57:58 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.08s]
2021-05-17 21:57:58.729181 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:57:58.748820 (Thread-4): SQL status: SELECT 495 in 0.03 seconds
2021-05-17 21:57:58.756506 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.756667 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:57:58.757123 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:57:58.759248 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.759380 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:57:58.759891 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:57:58.768679 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:57:58.768844 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.768941 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:57:58.771265 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:57:58.775445 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:57:58.775596 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:57:58.777755 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:57:58.778945 (Thread-4): finished collecting timing info
2021-05-17 21:57:58.779100 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:57:58.779489 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed5afa14-c9b8-4595-ae99-eb462baf0598', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072ca0d0>]}
2021-05-17 21:57:58.779802 (Thread-4): 17:57:58 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.13s]
2021-05-17 21:57:58.779941 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:57:58.785285 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-17 21:57:58.788130 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.788310 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:57:58.788883 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:57:58.792346 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.792567 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:57:58.793667 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:57:58.795421 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:57:58.795580 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.795679 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:57:58.796265 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:57:58.797912 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:57:58.798042 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:57:58.801098 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:57:58.802415 (Thread-1): finished collecting timing info
2021-05-17 21:57:58.802602 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:57:58.803007 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed5afa14-c9b8-4595-ae99-eb462baf0598', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c6df0>]}
2021-05-17 21:57:58.803333 (Thread-1): 17:57:58 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.18s]
2021-05-17 21:57:58.803477 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:57:59.801090 (Thread-2): SQL status: SELECT 6941 in 1.08 seconds
2021-05-17 21:57:59.803733 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:59.803880 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 21:57:59.804346 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:57:59.806383 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:59.806523 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 21:57:59.807118 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:57:59.808269 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:57:59.808427 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:59.808572 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:57:59.809296 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:57:59.810881 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:57:59.811009 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:57:59.814459 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:57:59.815746 (Thread-2): finished collecting timing info
2021-05-17 21:57:59.815934 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:57:59.816438 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed5afa14-c9b8-4595-ae99-eb462baf0598', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077efe50>]}
2021-05-17 21:57:59.816796 (Thread-2): 17:57:59 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.19s]
2021-05-17 21:57:59.816947 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:57:59.818497 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:57:59.818788 (MainThread): Using postgres connection "master".
2021-05-17 21:57:59.818960 (MainThread): On master: BEGIN
2021-05-17 21:57:59.819212 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:57:59.871811 (MainThread): SQL status: BEGIN in 0.05 seconds
2021-05-17 21:57:59.872139 (MainThread): On master: COMMIT
2021-05-17 21:57:59.872346 (MainThread): Using postgres connection "master".
2021-05-17 21:57:59.872557 (MainThread): On master: COMMIT
2021-05-17 21:57:59.872968 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:57:59.873242 (MainThread): On master: Close
2021-05-17 21:57:59.873967 (MainThread): 17:57:59 | 
2021-05-17 21:57:59.874259 (MainThread): 17:57:59 | Finished running 4 table models in 1.56s.
2021-05-17 21:57:59.874459 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:57:59.874601 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:57:59.874723 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:57:59.874840 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:57:59.874958 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:57:59.883306 (MainThread): 
2021-05-17 21:57:59.883522 (MainThread): Completed with 1 error and 0 warnings:
2021-05-17 21:57:59.883752 (MainThread): 
2021-05-17 21:57:59.883928 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 21:57:59.884054 (MainThread):   syntax error at or near "from"
2021-05-17 21:57:59.884164 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 21:57:59.884268 (MainThread):            ^
2021-05-17 21:57:59.884369 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:57:59.884488 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-05-17 21:57:59.884700 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106619ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10766ceb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10766c4c0>]}
2021-05-17 21:57:59.884916 (MainThread): Flushing usage events
2021-05-17 21:58:34.584313 (MainThread): Running with dbt=0.19.1
2021-05-17 21:58:34.653273 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:58:34.654277 (MainThread): Tracking: tracking
2021-05-17 21:58:34.668588 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a12e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a14a730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a14af70>]}
2021-05-17 21:58:34.683182 (MainThread): Partial parsing not enabled
2021-05-17 21:58:34.684312 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:58:34.688468 (MainThread): Parsing macros/relations.sql
2021-05-17 21:58:34.690338 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:58:34.716320 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:58:34.719818 (MainThread): Parsing macros/core.sql
2021-05-17 21:58:34.724982 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:58:34.739143 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:58:34.742092 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:58:34.767558 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:58:34.809788 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:58:34.835800 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:58:34.838610 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:58:34.847978 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:58:34.865218 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:58:34.872308 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:58:34.878795 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:58:34.883970 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:58:34.884915 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:58:34.885958 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:58:34.887588 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:58:34.896692 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:58:34.898709 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:58:34.900414 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:58:34.944514 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:58:34.946482 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:58:34.948043 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:58:34.949844 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:58:34.957410 (MainThread): Partial parsing not enabled
2021-05-17 21:58:35.011196 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.022739 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.026450 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:58:35.030160 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:35.085024 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6adcec20-150c-4b98-8187-fe00c9c8f373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2de5b0>]}
2021-05-17 21:58:35.089799 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6adcec20-150c-4b98-8187-fe00c9c8f373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3054c0>]}
2021-05-17 21:58:35.090094 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:58:35.091253 (MainThread): 
2021-05-17 21:58:35.091889 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:58:35.093774 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:58:35.109870 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:58:35.110112 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:58:35.110247 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:58:35.145602 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-17 21:58:35.148584 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:58:35.149992 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:58:35.157014 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:58:35.157162 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:58:35.157272 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:58:35.166419 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:58:35.166592 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:58:35.166691 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:58:35.170584 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 21:58:35.171460 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:58:35.171751 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:58:35.176680 (MainThread): Using postgres connection "master".
2021-05-17 21:58:35.176817 (MainThread): On master: BEGIN
2021-05-17 21:58:35.176922 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:58:35.185342 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:58:35.185515 (MainThread): Using postgres connection "master".
2021-05-17 21:58:35.185614 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:58:35.200271 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 21:58:35.200889 (MainThread): On master: ROLLBACK
2021-05-17 21:58:35.201123 (MainThread): Using postgres connection "master".
2021-05-17 21:58:35.201225 (MainThread): On master: BEGIN
2021-05-17 21:58:35.201506 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:58:35.201639 (MainThread): On master: COMMIT
2021-05-17 21:58:35.201741 (MainThread): Using postgres connection "master".
2021-05-17 21:58:35.201826 (MainThread): On master: COMMIT
2021-05-17 21:58:35.202014 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:58:35.202131 (MainThread): On master: Close
2021-05-17 21:58:35.202434 (MainThread): 17:58:35 | Concurrency: 4 threads (target='dev')
2021-05-17 21:58:35.202572 (MainThread): 17:58:35 | 
2021-05-17 21:58:35.204945 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:58:35.205346 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:58:35.205611 (Thread-1): 17:58:35 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:58:35.205717 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:58:35.205892 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:58:35.206124 (Thread-2): 17:58:35 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:58:35.206470 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.206702 (Thread-3): 17:58:35 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:58:35.206892 (Thread-4): 17:58:35 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:58:35.207177 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:35.207319 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:58:35.207579 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:58:35.207891 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.208028 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:58:35.209347 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:58:35.209480 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:58:35.209621 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:58:35.210857 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:58:35.212171 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:58:35.213226 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:58:35.213594 (Thread-1): finished collecting timing info
2021-05-17 21:58:35.231561 (Thread-2): finished collecting timing info
2021-05-17 21:58:35.241591 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.241991 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:35.242104 (Thread-3): finished collecting timing info
2021-05-17 21:58:35.242200 (Thread-4): finished collecting timing info
2021-05-17 21:58:35.242285 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:58:35.242387 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:58:35.245985 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:58:35.248518 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.248708 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:58:35.248832 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:58:35.248981 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:58:35.249098 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:58:35.249559 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:58:35.249674 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:58:35.259498 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:58:35.262567 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:35.262845 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:58:35.263388 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:58:35.263567 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:58:35.269150 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 21:58:35.279266 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:58:35.279402 (Thread-4): SQL status: DROP TABLE in 0.03 seconds
2021-05-17 21:58:35.281747 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:58:35.283862 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.286332 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.286512 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:58:35.286744 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:58:35.286954 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:58:35.287151 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:35.287568 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:58:35.287712 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:58:35.287863 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:58:35.288051 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:58:35.289657 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:58:35.289795 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:58:35.291424 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:58:35.292796 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:58:35.293162 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:35.293729 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select
    json_array_elements_text(rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select

json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from a
  );
2021-05-17 21:58:35.293961 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.294430 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.294583 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:58:35.294688 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:58:35.294818 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:58:35.294929 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:58:35.295352 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:58:35.295599 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.295795 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:58:35.295936 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:58:35.296077 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:58:35.296299 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:58:35.296565 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.296752 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 21:58:35.296946 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:58:35.297666 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 21:58:35.297888 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 21:58:35.298256 (Thread-3): finished collecting timing info
2021-05-17 21:58:35.298462 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:58:35.298827 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:58:35.301149 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6adcec20-150c-4b98-8187-fe00c9c8f373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a246f70>]}
2021-05-17 21:58:35.301512 (Thread-3): 17:58:35 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.09s]
2021-05-17 21:58:35.301664 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:58:35.318852 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-17 21:58:35.330096 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.330311 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:58:35.369805 (Thread-4): SQL status: ALTER TABLE in 0.04 seconds
2021-05-17 21:58:35.372992 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.397187 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:58:35.399745 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:58:35.409372 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:58:35.409521 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.409610 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:58:35.410314 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:58:35.413521 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:58:35.413635 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:58:35.415899 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:58:35.417154 (Thread-4): finished collecting timing info
2021-05-17 21:58:35.417291 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:58:35.417645 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6adcec20-150c-4b98-8187-fe00c9c8f373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1022e0>]}
2021-05-17 21:58:35.417921 (Thread-4): 17:58:35 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.21s]
2021-05-17 21:58:35.418050 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:58:35.426490 (Thread-1): SQL status: SELECT 1167 in 0.13 seconds
2021-05-17 21:58:35.428818 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.428951 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:58:35.429355 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:58:35.431275 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.431416 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:58:35.431881 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:58:35.432950 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:58:35.433069 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.433145 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:58:35.433653 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:58:35.435020 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:58:35.435145 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:58:35.437720 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:58:35.439157 (Thread-1): finished collecting timing info
2021-05-17 21:58:35.439316 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:58:35.439679 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6adcec20-150c-4b98-8187-fe00c9c8f373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a28af70>]}
2021-05-17 21:58:35.439994 (Thread-1): 17:58:35 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.23s]
2021-05-17 21:58:35.440134 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:58:36.291415 (Thread-2): SQL status: SELECT 6941 in 1.00 seconds
2021-05-17 21:58:36.293524 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:36.311998 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 21:58:36.312769 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:58:36.316017 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:36.316258 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 21:58:36.317015 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:58:36.318464 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:58:36.318658 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:36.318772 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:58:36.319509 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:58:36.321597 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:58:36.321793 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:58:36.381712 (Thread-2): SQL status: DROP TABLE in 0.06 seconds
2021-05-17 21:58:36.385937 (Thread-2): finished collecting timing info
2021-05-17 21:58:36.407107 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:58:36.407587 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6adcec20-150c-4b98-8187-fe00c9c8f373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a063a0>]}
2021-05-17 21:58:36.408048 (Thread-2): 17:58:36 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.20s]
2021-05-17 21:58:36.428877 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:58:36.430581 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:58:36.451297 (MainThread): Using postgres connection "master".
2021-05-17 21:58:36.451511 (MainThread): On master: BEGIN
2021-05-17 21:58:36.451660 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:58:36.462984 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:58:36.463182 (MainThread): On master: COMMIT
2021-05-17 21:58:36.463290 (MainThread): Using postgres connection "master".
2021-05-17 21:58:36.463398 (MainThread): On master: COMMIT
2021-05-17 21:58:36.463752 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:58:36.464014 (MainThread): On master: Close
2021-05-17 21:58:36.464607 (MainThread): 17:58:36 | 
2021-05-17 21:58:36.464876 (MainThread): 17:58:36 | Finished running 4 table models in 1.37s.
2021-05-17 21:58:36.465066 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:58:36.465193 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:58:36.465312 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:58:36.465425 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:58:36.465531 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:58:36.470916 (MainThread): 
2021-05-17 21:58:36.471105 (MainThread): Completed with 1 error and 0 warnings:
2021-05-17 21:58:36.471229 (MainThread): 
2021-05-17 21:58:36.471350 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 21:58:36.471455 (MainThread):   syntax error at or near "from"
2021-05-17 21:58:36.471551 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 21:58:36.471643 (MainThread):            ^
2021-05-17 21:58:36.471757 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:58:36.471945 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-05-17 21:58:36.472254 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a108d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a108bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099321f0>]}
2021-05-17 21:58:36.472691 (MainThread): Flushing usage events
2021-05-17 21:59:43.700102 (MainThread): Running with dbt=0.19.1
2021-05-17 21:59:43.779042 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 21:59:43.780094 (MainThread): Tracking: tracking
2021-05-17 21:59:43.795001 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112045dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11206a5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11206ae20>]}
2021-05-17 21:59:43.809642 (MainThread): Partial parsing not enabled
2021-05-17 21:59:43.810813 (MainThread): Parsing macros/catalog.sql
2021-05-17 21:59:43.814775 (MainThread): Parsing macros/relations.sql
2021-05-17 21:59:43.816585 (MainThread): Parsing macros/adapters.sql
2021-05-17 21:59:43.855770 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 21:59:43.862331 (MainThread): Parsing macros/core.sql
2021-05-17 21:59:43.868601 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 21:59:43.880273 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 21:59:43.882636 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 21:59:43.907150 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 21:59:43.945641 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 21:59:43.968134 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 21:59:43.970092 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 21:59:43.976782 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 21:59:43.991584 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 21:59:43.999339 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 21:59:44.006401 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 21:59:44.011550 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 21:59:44.012526 (MainThread): Parsing macros/etc/query.sql
2021-05-17 21:59:44.013597 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 21:59:44.015284 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 21:59:44.024803 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 21:59:44.026939 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 21:59:44.028708 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 21:59:44.073901 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 21:59:44.076010 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 21:59:44.077605 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 21:59:44.079360 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 21:59:44.087160 (MainThread): Partial parsing not enabled
2021-05-17 21:59:44.144777 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.156805 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.160426 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:59:44.163945 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:44.221576 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53d27cde-c55c-420f-beea-e62260bc9c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112202c70>]}
2021-05-17 21:59:44.226078 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53d27cde-c55c-420f-beea-e62260bc9c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112230d00>]}
2021-05-17 21:59:44.226442 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 21:59:44.227193 (MainThread): 
2021-05-17 21:59:44.227650 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:59:44.229208 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 21:59:44.243004 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 21:59:44.243178 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 21:59:44.243311 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 21:59:44.274168 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-17 21:59:44.277018 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 21:59:44.278310 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:59:44.285344 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:59:44.285524 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 21:59:44.285643 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 21:59:44.295347 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:59:44.295566 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 21:59:44.295702 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 21:59:44.299077 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 21:59:44.299871 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 21:59:44.300098 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 21:59:44.305064 (MainThread): Using postgres connection "master".
2021-05-17 21:59:44.305214 (MainThread): On master: BEGIN
2021-05-17 21:59:44.305325 (MainThread): Opening a new connection, currently in state init
2021-05-17 21:59:44.314312 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:59:44.314488 (MainThread): Using postgres connection "master".
2021-05-17 21:59:44.314592 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 21:59:44.369523 (MainThread): SQL status: SELECT 1 in 0.05 seconds
2021-05-17 21:59:44.370130 (MainThread): On master: ROLLBACK
2021-05-17 21:59:44.370363 (MainThread): Using postgres connection "master".
2021-05-17 21:59:44.370465 (MainThread): On master: BEGIN
2021-05-17 21:59:44.370768 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:59:44.370900 (MainThread): On master: COMMIT
2021-05-17 21:59:44.371000 (MainThread): Using postgres connection "master".
2021-05-17 21:59:44.371086 (MainThread): On master: COMMIT
2021-05-17 21:59:44.371272 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:59:44.371389 (MainThread): On master: Close
2021-05-17 21:59:44.371677 (MainThread): 17:59:44 | Concurrency: 4 threads (target='dev')
2021-05-17 21:59:44.371813 (MainThread): 17:59:44 | 
2021-05-17 21:59:44.373761 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 21:59:44.374107 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 21:59:44.374353 (Thread-1): 17:59:44 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 21:59:44.374452 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:59:44.374616 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 21:59:44.374824 (Thread-2): 17:59:44 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 21:59:44.375130 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.375335 (Thread-3): 17:59:44 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 21:59:44.375521 (Thread-4): 17:59:44 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 21:59:44.375882 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:44.376008 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 21:59:44.376326 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:59:44.376610 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.376740 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 21:59:44.378074 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:59:44.378205 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 21:59:44.378320 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 21:59:44.379420 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:59:44.380709 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:59:44.381745 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:59:44.382024 (Thread-1): finished collecting timing info
2021-05-17 21:59:44.387715 (Thread-2): finished collecting timing info
2021-05-17 21:59:44.394043 (Thread-4): finished collecting timing info
2021-05-17 21:59:44.443240 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:44.444468 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.444581 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 21:59:44.444676 (Thread-3): finished collecting timing info
2021-05-17 21:59:44.446495 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.472435 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 21:59:44.472661 (Thread-2): Opening a new connection, currently in state init
2021-05-17 21:59:44.475738 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:59:44.475907 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 21:59:44.476026 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 21:59:44.476331 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 21:59:44.476466 (Thread-4): Opening a new connection, currently in state init
2021-05-17 21:59:44.476736 (Thread-3): Opening a new connection, currently in state init
2021-05-17 21:59:44.485864 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:59:44.488197 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:44.488456 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:59:44.488581 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:59:44.488707 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:59:44.490960 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:59:44.491114 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:59:44.493149 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.493289 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:59:44.493388 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 21:59:44.495234 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.495358 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:59:44.507515 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 21:59:44.507676 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:59:44.507779 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:59:44.509301 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 21:59:44.509398 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:59:44.509820 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:44.511033 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 21:59:44.511172 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:59:44.511420 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 21:59:44.511552 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:59:44.512855 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 21:59:44.513168 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.513280 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 21:59:44.513363 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:59:44.513578 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 21:59:44.513900 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.513990 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:44.514085 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:59:44.514288 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 21:59:44.514429 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId,
    json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from a
  );
2021-05-17 21:59:44.514526 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:59:44.514633 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 21:59:44.514884 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.515014 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 21:59:44.515108 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 21:59:44.515234 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 21:59:44.515337 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.515625 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 21:59:44.515929 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 21:59:44.516053 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 21:59:44.516294 (Thread-3): finished collecting timing info
2021-05-17 21:59:44.516460 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 21:59:44.516868 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:59:44.520346 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53d27cde-c55c-420f-beea-e62260bc9c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112026e80>]}
2021-05-17 21:59:44.520911 (Thread-3): 17:59:44 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.14s]
2021-05-17 21:59:44.521150 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 21:59:44.538993 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-17 21:59:44.546062 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.546208 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 21:59:44.546697 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:59:44.548696 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.548803 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 21:59:44.550135 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:59:44.559335 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:59:44.559537 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.559633 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 21:59:44.560398 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:59:44.564015 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 21:59:44.564146 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 21:59:44.566403 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:59:44.567613 (Thread-4): finished collecting timing info
2021-05-17 21:59:44.567774 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 21:59:44.568266 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53d27cde-c55c-420f-beea-e62260bc9c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11227b3d0>]}
2021-05-17 21:59:44.568721 (Thread-4): 17:59:44 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.19s]
2021-05-17 21:59:44.568895 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 21:59:44.571247 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-17 21:59:44.573740 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.573883 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 21:59:44.574561 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:59:44.577502 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.577673 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 21:59:44.578301 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:59:44.580355 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:59:44.580498 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.580589 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 21:59:44.581104 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:59:44.582651 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 21:59:44.582783 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 21:59:44.593831 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 21:59:44.595153 (Thread-1): finished collecting timing info
2021-05-17 21:59:44.595324 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 21:59:44.595728 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53d27cde-c55c-420f-beea-e62260bc9c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112025670>]}
2021-05-17 21:59:44.596054 (Thread-1): 17:59:44 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.22s]
2021-05-17 21:59:44.596201 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 21:59:45.429247 (Thread-2): SQL status: SELECT 6941 in 0.91 seconds
2021-05-17 21:59:45.448631 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:45.468074 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 21:59:45.468641 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:59:45.471103 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:45.490865 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 21:59:45.491692 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 21:59:45.493548 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:59:45.513069 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:45.513323 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 21:59:45.514093 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:59:45.519136 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 21:59:45.519357 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 21:59:45.523263 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 21:59:45.525050 (Thread-2): finished collecting timing info
2021-05-17 21:59:45.525233 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 21:59:45.525678 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53d27cde-c55c-420f-beea-e62260bc9c6e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123ba6d0>]}
2021-05-17 21:59:45.526000 (Thread-2): 17:59:45 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.15s]
2021-05-17 21:59:45.526266 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 21:59:45.527961 (MainThread): Acquiring new postgres connection "master".
2021-05-17 21:59:45.528233 (MainThread): Using postgres connection "master".
2021-05-17 21:59:45.528376 (MainThread): On master: BEGIN
2021-05-17 21:59:45.528510 (MainThread): Opening a new connection, currently in state closed
2021-05-17 21:59:45.540825 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 21:59:45.562330 (MainThread): On master: COMMIT
2021-05-17 21:59:45.562804 (MainThread): Using postgres connection "master".
2021-05-17 21:59:45.563062 (MainThread): On master: COMMIT
2021-05-17 21:59:45.563527 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 21:59:45.563797 (MainThread): On master: Close
2021-05-17 21:59:45.585951 (MainThread): 17:59:45 | 
2021-05-17 21:59:45.586274 (MainThread): 17:59:45 | Finished running 4 table models in 1.36s.
2021-05-17 21:59:45.586482 (MainThread): Connection 'master' was properly closed.
2021-05-17 21:59:45.607443 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 21:59:45.607655 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 21:59:45.607770 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 21:59:45.607893 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 21:59:45.613332 (MainThread): 
2021-05-17 21:59:45.613600 (MainThread): Completed with 1 error and 0 warnings:
2021-05-17 21:59:45.613769 (MainThread): 
2021-05-17 21:59:45.613954 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 21:59:45.614107 (MainThread):   syntax error at or near "from"
2021-05-17 21:59:45.614216 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 21:59:45.614341 (MainThread):            ^
2021-05-17 21:59:45.614497 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 21:59:45.614657 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-05-17 21:59:45.614900 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b6a1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11188f970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11188f1c0>]}
2021-05-17 21:59:45.615131 (MainThread): Flushing usage events
2021-05-17 22:00:15.171662 (MainThread): Running with dbt=0.19.1
2021-05-17 22:00:15.262740 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 22:00:15.263688 (MainThread): Tracking: tracking
2021-05-17 22:00:15.279426 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111267e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111287700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111287f40>]}
2021-05-17 22:00:15.294709 (MainThread): Partial parsing not enabled
2021-05-17 22:00:15.296193 (MainThread): Parsing macros/catalog.sql
2021-05-17 22:00:15.300874 (MainThread): Parsing macros/relations.sql
2021-05-17 22:00:15.303176 (MainThread): Parsing macros/adapters.sql
2021-05-17 22:00:15.342096 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 22:00:15.349173 (MainThread): Parsing macros/core.sql
2021-05-17 22:00:15.359375 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 22:00:15.382528 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 22:00:15.385770 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 22:00:15.416253 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 22:00:15.464598 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 22:00:15.494198 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 22:00:15.496808 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 22:00:15.505769 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 22:00:15.526049 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 22:00:15.536351 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 22:00:15.545343 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 22:00:15.551972 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 22:00:15.553328 (MainThread): Parsing macros/etc/query.sql
2021-05-17 22:00:15.554683 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 22:00:15.556806 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 22:00:15.568030 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 22:00:15.570485 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 22:00:15.572625 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 22:00:15.617945 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 22:00:15.620261 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 22:00:15.621838 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 22:00:15.623552 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 22:00:15.631009 (MainThread): Partial parsing not enabled
2021-05-17 22:00:15.685427 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:15.696921 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:15.700553 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:15.704056 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:15.757711 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86aa7b88-442e-4e83-821e-27c30ff11baa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111417af0>]}
2021-05-17 22:00:15.761600 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86aa7b88-442e-4e83-821e-27c30ff11baa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11143f4f0>]}
2021-05-17 22:00:15.761839 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 22:00:15.762475 (MainThread): 
2021-05-17 22:00:15.762773 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:00:15.763706 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 22:00:15.774020 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 22:00:15.774156 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 22:00:15.774258 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 22:00:15.802461 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-17 22:00:15.805418 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 22:00:15.806670 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:00:15.813419 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:00:15.813565 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 22:00:15.813676 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 22:00:15.822498 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:00:15.822679 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:00:15.822779 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 22:00:15.882616 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.06 seconds
2021-05-17 22:00:15.883559 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 22:00:15.883836 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 22:00:15.888939 (MainThread): Using postgres connection "master".
2021-05-17 22:00:15.889106 (MainThread): On master: BEGIN
2021-05-17 22:00:15.889229 (MainThread): Opening a new connection, currently in state init
2021-05-17 22:00:15.899535 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:00:15.899777 (MainThread): Using postgres connection "master".
2021-05-17 22:00:15.899937 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 22:00:15.916483 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-17 22:00:15.917188 (MainThread): On master: ROLLBACK
2021-05-17 22:00:15.917532 (MainThread): Using postgres connection "master".
2021-05-17 22:00:15.917678 (MainThread): On master: BEGIN
2021-05-17 22:00:15.918029 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:15.918201 (MainThread): On master: COMMIT
2021-05-17 22:00:15.918349 (MainThread): Using postgres connection "master".
2021-05-17 22:00:15.918447 (MainThread): On master: COMMIT
2021-05-17 22:00:15.918713 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:15.918919 (MainThread): On master: Close
2021-05-17 22:00:15.919435 (MainThread): 18:00:15 | Concurrency: 4 threads (target='dev')
2021-05-17 22:00:15.919683 (MainThread): 18:00:15 | 
2021-05-17 22:00:15.922537 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 22:00:15.923026 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 22:00:15.923240 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:00:15.923528 (Thread-1): 18:00:15 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 22:00:15.923675 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 22:00:15.924005 (Thread-2): 18:00:15 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 22:00:15.924332 (Thread-3): 18:00:15 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 22:00:15.924665 (Thread-4): 18:00:15 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 22:00:15.924995 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:15.925318 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:15.925620 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:15.925967 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:15.926144 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 22:00:15.926273 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 22:00:15.926490 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 22:00:15.926634 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 22:00:15.928221 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:00:15.929772 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:00:15.931628 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:00:15.932946 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:00:15.933666 (Thread-2): finished collecting timing info
2021-05-17 22:00:15.933975 (Thread-1): finished collecting timing info
2021-05-17 22:00:15.940114 (Thread-3): finished collecting timing info
2021-05-17 22:00:15.969776 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:15.969977 (Thread-4): finished collecting timing info
2021-05-17 22:00:15.980750 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:15.982298 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:15.982456 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 22:00:15.985367 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:15.985569 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 22:00:15.985716 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 22:00:15.985845 (Thread-2): Opening a new connection, currently in state init
2021-05-17 22:00:15.985987 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 22:00:15.986144 (Thread-3): Opening a new connection, currently in state init
2021-05-17 22:00:15.986264 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 22:00:15.986638 (Thread-4): Opening a new connection, currently in state init
2021-05-17 22:00:15.996598 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:00:15.999112 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:15.999281 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:00:15.999374 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:00:16.001658 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:16.001825 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:00:16.002000 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:00:16.002105 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 22:00:16.002186 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:16.004216 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:16.006158 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:16.018419 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:00:16.018544 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:00:16.018636 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:00:16.018769 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:00:16.020519 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:00:16.020695 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:16.020941 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:16.021113 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:16.022410 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:00:16.022596 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 22:00:16.022798 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:16.024293 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:00:16.024715 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 22:00:16.024916 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:16.025122 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:16.025356 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 22:00:16.025537 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:16.025628 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:16.025713 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:16.025901 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 22:00:16.026053 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:16.026167 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:16.026343 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from a
  );
2021-05-17 22:00:16.026604 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason,
from fetch_takehome.receipts
  );
2021-05-17 22:00:16.026753 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:16.026919 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:16.027248 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:16.027372 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 22:00:16.027522 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 22:00:16.027804 (Thread-3): Postgres error: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^

2021-05-17 22:00:16.028061 (Thread-3): On model.fetch_takehome.receipts_json_extract: ROLLBACK
2021-05-17 22:00:16.028355 (Thread-3): finished collecting timing info
2021-05-17 22:00:16.028525 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 22:00:16.028875 (Thread-3): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "from"
LINE 24: from fetch_takehome.receipts
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
  syntax error at or near "from"
  LINE 24: from fetch_takehome.receipts
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 22:00:16.031482 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86aa7b88-442e-4e83-821e-27c30ff11baa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ac0d90>]}
2021-05-17 22:00:16.031899 (Thread-3): 18:00:16 | 3 of 4 ERROR creating table model fetch_takehome.receipts_json_extract [ERROR in 0.11s]
2021-05-17 22:00:16.032073 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:00:16.046586 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-17 22:00:16.053504 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:16.053692 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 22:00:16.054161 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:16.056585 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:16.056719 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 22:00:16.057220 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:16.064756 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:00:16.064908 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:16.065006 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:00:16.065739 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:16.070170 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:16.070322 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:00:16.072389 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:16.073589 (Thread-4): finished collecting timing info
2021-05-17 22:00:16.073797 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 22:00:16.074200 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86aa7b88-442e-4e83-821e-27c30ff11baa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110aa9f10>]}
2021-05-17 22:00:16.074512 (Thread-4): 18:00:16 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.15s]
2021-05-17 22:00:16.074656 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 22:00:16.079156 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-17 22:00:16.081372 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:16.081494 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 22:00:16.082003 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:16.084197 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:16.084331 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 22:00:16.084887 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:16.086180 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:00:16.086323 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:16.086415 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:00:16.086941 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:16.088540 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:16.088660 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:00:16.090861 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:16.092171 (Thread-1): finished collecting timing info
2021-05-17 22:00:16.092374 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 22:00:16.092795 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86aa7b88-442e-4e83-821e-27c30ff11baa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11137cfa0>]}
2021-05-17 22:00:16.093163 (Thread-1): 18:00:16 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.17s]
2021-05-17 22:00:16.093335 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 22:00:17.025444 (Thread-2): SQL status: SELECT 6941 in 1.00 seconds
2021-05-17 22:00:17.028351 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:17.028530 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 22:00:17.029018 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:17.031598 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:17.032244 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 22:00:17.032995 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:17.034419 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:00:17.034581 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:17.034687 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:00:17.035472 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:17.037694 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:17.037861 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:00:17.040920 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:17.043807 (Thread-2): finished collecting timing info
2021-05-17 22:00:17.043990 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 22:00:17.044373 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86aa7b88-442e-4e83-821e-27c30ff11baa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115ced00>]}
2021-05-17 22:00:17.044696 (Thread-2): 18:00:17 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.12s]
2021-05-17 22:00:17.044843 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 22:00:17.046453 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:00:17.046696 (MainThread): Using postgres connection "master".
2021-05-17 22:00:17.046806 (MainThread): On master: BEGIN
2021-05-17 22:00:17.046910 (MainThread): Opening a new connection, currently in state closed
2021-05-17 22:00:17.056723 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:00:17.057277 (MainThread): On master: COMMIT
2021-05-17 22:00:17.057402 (MainThread): Using postgres connection "master".
2021-05-17 22:00:17.057500 (MainThread): On master: COMMIT
2021-05-17 22:00:17.057748 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:17.057899 (MainThread): On master: Close
2021-05-17 22:00:17.058305 (MainThread): 18:00:17 | 
2021-05-17 22:00:17.058497 (MainThread): 18:00:17 | Finished running 4 table models in 1.30s.
2021-05-17 22:00:17.058646 (MainThread): Connection 'master' was properly closed.
2021-05-17 22:00:17.058776 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 22:00:17.058943 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 22:00:17.059042 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 22:00:17.059128 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 22:00:17.065341 (MainThread): 
2021-05-17 22:00:17.065635 (MainThread): Completed with 1 error and 0 warnings:
2021-05-17 22:00:17.065842 (MainThread): 
2021-05-17 22:00:17.066029 (MainThread): Database Error in model receipts_json_extract (models/json_extract/receipts_json_extract.sql)
2021-05-17 22:00:17.066191 (MainThread):   syntax error at or near "from"
2021-05-17 22:00:17.066342 (MainThread):   LINE 24: from fetch_takehome.receipts
2021-05-17 22:00:17.066488 (MainThread):            ^
2021-05-17 22:00:17.066645 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/receipts_json_extract.sql
2021-05-17 22:00:17.066845 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-05-17 22:00:17.067127 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115ced00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11123fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11123fb80>]}
2021-05-17 22:00:17.067365 (MainThread): Flushing usage events
2021-05-17 22:00:52.707933 (MainThread): Running with dbt=0.19.1
2021-05-17 22:00:52.783486 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 22:00:52.784221 (MainThread): Tracking: tracking
2021-05-17 22:00:52.798540 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b1fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b3d640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b3de80>]}
2021-05-17 22:00:52.812864 (MainThread): Partial parsing not enabled
2021-05-17 22:00:52.813982 (MainThread): Parsing macros/catalog.sql
2021-05-17 22:00:52.817961 (MainThread): Parsing macros/relations.sql
2021-05-17 22:00:52.819731 (MainThread): Parsing macros/adapters.sql
2021-05-17 22:00:52.858919 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 22:00:52.864108 (MainThread): Parsing macros/core.sql
2021-05-17 22:00:52.869237 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 22:00:52.879745 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 22:00:52.881596 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 22:00:52.903454 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 22:00:52.942503 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 22:00:52.964600 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 22:00:52.966570 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 22:00:52.973312 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 22:00:52.988197 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 22:00:52.995474 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 22:00:53.002078 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 22:00:53.007400 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 22:00:53.008401 (MainThread): Parsing macros/etc/query.sql
2021-05-17 22:00:53.009461 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 22:00:53.011108 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 22:00:53.020886 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 22:00:53.022983 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 22:00:53.024819 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 22:00:53.069700 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 22:00:53.071706 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 22:00:53.073283 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 22:00:53.075037 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 22:00:53.082667 (MainThread): Partial parsing not enabled
2021-05-17 22:00:53.137194 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.148858 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.152342 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:53.156162 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:53.208098 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2bae8300-d38e-482f-a434-61c7f4af1a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cd0430>]}
2021-05-17 22:00:53.211364 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2bae8300-d38e-482f-a434-61c7f4af1a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cf63d0>]}
2021-05-17 22:00:53.211583 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 22:00:53.212137 (MainThread): 
2021-05-17 22:00:53.212403 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:00:53.213188 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 22:00:53.223332 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 22:00:53.223478 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 22:00:53.223586 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 22:00:53.245581 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-17 22:00:53.248645 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 22:00:53.250070 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:00:53.257053 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:00:53.257215 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 22:00:53.257333 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 22:00:53.266454 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:00:53.266629 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:00:53.266730 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 22:00:53.270549 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 22:00:53.271412 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 22:00:53.271747 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 22:00:53.277103 (MainThread): Using postgres connection "master".
2021-05-17 22:00:53.277295 (MainThread): On master: BEGIN
2021-05-17 22:00:53.277427 (MainThread): Opening a new connection, currently in state init
2021-05-17 22:00:53.286616 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:00:53.286831 (MainThread): Using postgres connection "master".
2021-05-17 22:00:53.286942 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 22:00:53.300964 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 22:00:53.301600 (MainThread): On master: ROLLBACK
2021-05-17 22:00:53.301842 (MainThread): Using postgres connection "master".
2021-05-17 22:00:53.301944 (MainThread): On master: BEGIN
2021-05-17 22:00:53.302252 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:53.302384 (MainThread): On master: COMMIT
2021-05-17 22:00:53.302485 (MainThread): Using postgres connection "master".
2021-05-17 22:00:53.302570 (MainThread): On master: COMMIT
2021-05-17 22:00:53.302781 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:53.302930 (MainThread): On master: Close
2021-05-17 22:00:53.303251 (MainThread): 18:00:53 | Concurrency: 4 threads (target='dev')
2021-05-17 22:00:53.303393 (MainThread): 18:00:53 | 
2021-05-17 22:00:53.305477 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 22:00:53.305908 (Thread-1): 18:00:53 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 22:00:53.306121 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 22:00:53.306542 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.306759 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:00:53.306892 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 22:00:53.307117 (Thread-2): 18:00:53 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 22:00:53.307261 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 22:00:53.307505 (Thread-3): 18:00:53 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 22:00:53.307721 (Thread-4): 18:00:53 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 22:00:53.308032 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:53.309324 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:00:53.309688 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:53.310081 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.310211 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 22:00:53.310448 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 22:00:53.310573 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 22:00:53.311817 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:00:53.311965 (Thread-1): finished collecting timing info
2021-05-17 22:00:53.313164 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:00:53.314206 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:00:53.345358 (Thread-4): finished collecting timing info
2021-05-17 22:00:53.337682 (Thread-2): finished collecting timing info
2021-05-17 22:00:53.365506 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.372792 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 22:00:53.373024 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 22:00:53.367971 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.371724 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:53.374318 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 22:00:53.365744 (Thread-3): finished collecting timing info
2021-05-17 22:00:53.375081 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 22:00:53.375275 (Thread-4): Opening a new connection, currently in state init
2021-05-17 22:00:53.378300 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:53.378476 (Thread-2): Opening a new connection, currently in state init
2021-05-17 22:00:53.378799 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 22:00:53.379116 (Thread-3): Opening a new connection, currently in state init
2021-05-17 22:00:53.383762 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:00:53.386562 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.386706 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:00:53.387020 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:53.399754 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:00:53.400024 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:00:53.400126 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:00:53.402293 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:53.402557 (Thread-4): SQL status: DROP TABLE in 0.03 seconds
2021-05-17 22:00:53.405066 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:53.405212 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.405338 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:00:53.407390 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.407512 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 22:00:53.407616 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 22:00:53.407803 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:00:53.407970 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:53.408231 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:53.408394 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:53.409650 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:00:53.410925 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:00:53.411024 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:53.411141 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.412797 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:00:53.412927 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:53.413095 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:53.413188 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 22:00:53.413437 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 22:00:53.413649 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 22:00:53.413802 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.414175 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:53.414277 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 22:00:53.414354 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:53.414464 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:53.414648 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:53.414764 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup
from a
  );
2021-05-17 22:00:53.414854 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:00:53.414953 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from fetch_takehome.receipts
  );
2021-05-17 22:00:53.415134 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.415331 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 22:00:53.431836 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-17 22:00:53.437724 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.437842 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 22:00:53.438243 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:53.439914 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.440007 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 22:00:53.440435 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:53.446626 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:00:53.446756 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.446833 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:00:53.447495 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:53.450208 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:00:53.450314 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:00:53.451902 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:53.453255 (Thread-4): finished collecting timing info
2021-05-17 22:00:53.453410 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 22:00:53.453784 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bae8300-d38e-482f-a434-61c7f4af1a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110381df0>]}
2021-05-17 22:00:53.454054 (Thread-4): 18:00:53 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.14s]
2021-05-17 22:00:53.454172 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 22:00:53.459564 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-17 22:00:53.461630 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.461737 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 22:00:53.462130 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:53.463771 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.463869 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 22:00:53.464334 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:53.465393 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:00:53.465492 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.465561 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:00:53.466026 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:53.467123 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:00:53.467208 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:00:53.468894 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:53.469848 (Thread-1): finished collecting timing info
2021-05-17 22:00:53.469971 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 22:00:53.470255 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bae8300-d38e-482f-a434-61c7f4af1a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c8fe50>]}
2021-05-17 22:00:53.470503 (Thread-1): 18:00:53 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.16s]
2021-05-17 22:00:53.470617 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 22:00:54.255332 (Thread-3): SQL status: SELECT 1119 in 0.84 seconds
2021-05-17 22:00:54.257867 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:54.277219 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-17 22:00:54.470970 (Thread-2): SQL status: SELECT 6941 in 1.06 seconds
2021-05-17 22:00:54.473119 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:54.473250 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 22:00:54.473721 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:54.475658 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:54.475763 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 22:00:54.476190 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:54.477339 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:00:54.477445 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:54.477520 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:00:54.478040 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:54.478196 (Thread-3): SQL status: ALTER TABLE in 0.20 seconds
2021-05-17 22:00:54.481118 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:00:54.483514 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:54.483672 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:00:54.483808 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-17 22:00:54.484305 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:00:54.485548 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 22:00:54.485659 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:54.485734 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 22:00:54.488109 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:54.489526 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:00:54.489674 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:00:54.489786 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 22:00:54.491063 (Thread-2): finished collecting timing info
2021-05-17 22:00:54.491337 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 22:00:54.491784 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bae8300-d38e-482f-a434-61c7f4af1a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbe4f70>]}
2021-05-17 22:00:54.492104 (Thread-2): 18:00:54 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.18s]
2021-05-17 22:00:54.492243 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 22:00:54.494359 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:00:54.495853 (Thread-3): finished collecting timing info
2021-05-17 22:00:54.496027 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 22:00:54.496402 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bae8300-d38e-482f-a434-61c7f4af1a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e10880>]}
2021-05-17 22:00:54.496744 (Thread-3): 18:00:54 | 3 of 4 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.19s]
2021-05-17 22:00:54.496882 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:00:54.498414 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:00:54.498664 (MainThread): Using postgres connection "master".
2021-05-17 22:00:54.498826 (MainThread): On master: BEGIN
2021-05-17 22:00:54.498956 (MainThread): Opening a new connection, currently in state closed
2021-05-17 22:00:54.508180 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:00:54.527917 (MainThread): On master: COMMIT
2021-05-17 22:00:54.528276 (MainThread): Using postgres connection "master".
2021-05-17 22:00:54.528480 (MainThread): On master: COMMIT
2021-05-17 22:00:54.528980 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:00:54.529303 (MainThread): On master: Close
2021-05-17 22:00:54.530185 (MainThread): 18:00:54 | 
2021-05-17 22:00:54.550878 (MainThread): 18:00:54 | Finished running 4 table models in 1.32s.
2021-05-17 22:00:54.551064 (MainThread): Connection 'master' was properly closed.
2021-05-17 22:00:54.551152 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 22:00:54.551228 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 22:00:54.551300 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 22:00:54.551371 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 22:00:54.574901 (MainThread): 
2021-05-17 22:00:54.575182 (MainThread): Completed successfully
2021-05-17 22:00:54.575404 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-05-17 22:00:54.575701 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108b46a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108b46d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110af8ca0>]}
2021-05-17 22:00:54.576020 (MainThread): Flushing usage events
2021-05-17 22:07:15.509833 (MainThread): Running with dbt=0.19.1
2021-05-17 22:07:15.670142 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 22:07:15.671508 (MainThread): Tracking: tracking
2021-05-17 22:07:15.689273 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113659e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11367f610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11367fe50>]}
2021-05-17 22:07:15.703146 (MainThread): Partial parsing not enabled
2021-05-17 22:07:15.705028 (MainThread): Parsing macros/catalog.sql
2021-05-17 22:07:15.709659 (MainThread): Parsing macros/relations.sql
2021-05-17 22:07:15.711851 (MainThread): Parsing macros/adapters.sql
2021-05-17 22:07:15.734567 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 22:07:15.738242 (MainThread): Parsing macros/core.sql
2021-05-17 22:07:15.742425 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 22:07:15.752071 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 22:07:15.754175 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 22:07:15.774277 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 22:07:15.811840 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 22:07:15.884149 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 22:07:15.886483 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 22:07:15.893576 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 22:07:15.909263 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 22:07:15.918186 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 22:07:15.926679 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 22:07:15.933512 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 22:07:15.934962 (MainThread): Parsing macros/etc/query.sql
2021-05-17 22:07:15.936435 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 22:07:15.938653 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 22:07:15.949850 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 22:07:15.952471 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 22:07:15.954712 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 22:07:16.001814 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 22:07:16.004351 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 22:07:16.006508 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 22:07:16.008803 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 22:07:16.018188 (MainThread): Partial parsing not enabled
2021-05-17 22:07:16.204949 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.216974 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.220662 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:16.224308 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:16.274346 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '436b149b-246b-4a0c-8392-ace8b75e636e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1138122b0>]}
2021-05-17 22:07:16.277698 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '436b149b-246b-4a0c-8392-ace8b75e636e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11381eaf0>]}
2021-05-17 22:07:16.277898 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 22:07:16.278441 (MainThread): 
2021-05-17 22:07:16.278694 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:07:16.279467 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 22:07:16.288666 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 22:07:16.288782 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 22:07:16.288869 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 22:07:16.358900 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.07 seconds
2021-05-17 22:07:16.361683 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 22:07:16.362801 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:07:16.368542 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:07:16.368743 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 22:07:16.368888 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 22:07:16.375994 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:07:16.376142 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:07:16.376226 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 22:07:16.378770 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 22:07:16.379365 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 22:07:16.379531 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 22:07:16.383366 (MainThread): Using postgres connection "master".
2021-05-17 22:07:16.383471 (MainThread): On master: BEGIN
2021-05-17 22:07:16.383557 (MainThread): Opening a new connection, currently in state init
2021-05-17 22:07:16.390500 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:07:16.390659 (MainThread): Using postgres connection "master".
2021-05-17 22:07:16.390750 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 22:07:16.403740 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-17 22:07:16.404324 (MainThread): On master: ROLLBACK
2021-05-17 22:07:16.404538 (MainThread): Using postgres connection "master".
2021-05-17 22:07:16.404625 (MainThread): On master: BEGIN
2021-05-17 22:07:16.404889 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:07:16.405015 (MainThread): On master: COMMIT
2021-05-17 22:07:16.405101 (MainThread): Using postgres connection "master".
2021-05-17 22:07:16.405174 (MainThread): On master: COMMIT
2021-05-17 22:07:16.405342 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:07:16.405459 (MainThread): On master: Close
2021-05-17 22:07:16.405723 (MainThread): 18:07:16 | Concurrency: 4 threads (target='dev')
2021-05-17 22:07:16.405859 (MainThread): 18:07:16 | 
2021-05-17 22:07:16.407986 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 22:07:16.408358 (Thread-1): 18:07:16 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 22:07:16.408503 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 22:07:16.408781 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.408892 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:07:16.409096 (Thread-2): 18:07:16 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 22:07:16.409178 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 22:07:16.409314 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 22:07:16.409477 (Thread-3): 18:07:16 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 22:07:16.409759 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:16.409971 (Thread-4): 18:07:16 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 22:07:16.411108 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:07:16.411377 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:16.411499 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 22:07:16.411928 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.412168 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 22:07:16.413303 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:07:16.413424 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 22:07:16.413507 (Thread-1): finished collecting timing info
2021-05-17 22:07:16.414542 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:07:16.415514 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:07:16.432411 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.432725 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 22:07:16.432835 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 22:07:16.433091 (Thread-3): finished collecting timing info
2021-05-17 22:07:16.433247 (Thread-2): finished collecting timing info
2021-05-17 22:07:16.435456 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:16.438283 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:16.438434 (Thread-4): finished collecting timing info
2021-05-17 22:07:16.438528 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 22:07:16.438631 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 22:07:16.441221 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.441631 (Thread-3): Opening a new connection, currently in state init
2021-05-17 22:07:16.441771 (Thread-2): Opening a new connection, currently in state init
2021-05-17 22:07:16.441864 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 22:07:16.442284 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:07:16.442412 (Thread-4): Opening a new connection, currently in state init
2021-05-17 22:07:16.444796 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.445127 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:07:16.445479 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:07:16.457603 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:07:16.458284 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.458406 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 22:07:16.458532 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:07:16.458703 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:07:16.460672 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:16.460760 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:07:16.460889 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:07:16.462806 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.462931 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:07:16.464801 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:16.489039 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.490113 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:07:16.491425 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 22:07:16.491541 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 22:07:16.491628 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:07:16.491998 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:07:16.493157 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:07:16.493235 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:07:16.494260 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:07:16.495431 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:07:16.495871 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:16.496050 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 22:07:16.496293 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:16.496408 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:07:16.496495 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 22:07:16.496665 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.496751 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:16.496936 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 22:07:16.497029 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:07:16.497152 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-17 22:07:16.497378 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:16.497567 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:07:16.497695 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(json_txt), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from fetch_takehome.receipts
  );
2021-05-17 22:07:16.497812 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.498009 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 22:07:16.513749 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-17 22:07:16.519585 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.519718 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 22:07:16.520114 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:07:16.521926 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.522035 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 22:07:16.522433 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:07:16.529188 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:07:16.529331 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.529417 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:07:16.530183 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:07:16.533252 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:07:16.533397 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:07:16.535216 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:07:16.536314 (Thread-4): finished collecting timing info
2021-05-17 22:07:16.536451 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 22:07:16.536799 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '436b149b-246b-4a0c-8392-ace8b75e636e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136dac10>]}
2021-05-17 22:07:16.537088 (Thread-4): 18:07:16 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.13s]
2021-05-17 22:07:16.537220 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 22:07:16.539464 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-17 22:07:16.541588 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.541696 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 22:07:16.542065 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:07:16.543705 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.543805 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 22:07:16.544195 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:07:16.545282 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:07:16.545418 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.545550 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:07:16.546086 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:07:16.547313 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:07:16.547413 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:07:16.550130 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:07:16.551223 (Thread-1): finished collecting timing info
2021-05-17 22:07:16.551364 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 22:07:16.551706 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '436b149b-246b-4a0c-8392-ace8b75e636e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137efa90>]}
2021-05-17 22:07:16.551989 (Thread-1): 18:07:16 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.14s]
2021-05-17 22:07:16.552120 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 22:07:18.445257 (Thread-3): SQL status: SELECT 1119 in 1.95 seconds
2021-05-17 22:07:18.449470 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:18.449682 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-17 22:07:18.743894 (Thread-2): SQL status: SELECT 6941 in 2.25 seconds
2021-05-17 22:07:18.746675 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:18.746846 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 22:07:18.748600 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:07:18.751138 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:18.751301 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 22:07:18.753158 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:07:18.755142 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:07:18.755356 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:18.755496 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:07:18.758425 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:07:18.762825 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:07:18.763029 (Thread-3): SQL status: ALTER TABLE in 0.31 seconds
2021-05-17 22:07:18.763229 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:07:18.765732 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:18.766025 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-17 22:07:18.772429 (Thread-3): SQL status: ALTER TABLE in 0.01 seconds
2021-05-17 22:07:18.774015 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 22:07:18.774157 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:18.774250 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 22:07:18.779659 (Thread-3): SQL status: COMMIT in 0.01 seconds
2021-05-17 22:07:18.782122 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:07:18.782350 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:07:18.782493 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 22:07:18.784189 (Thread-2): finished collecting timing info
2021-05-17 22:07:18.784528 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 22:07:18.785052 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '436b149b-246b-4a0c-8392-ace8b75e636e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113792b80>]}
2021-05-17 22:07:18.785422 (Thread-2): 18:07:18 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 2.38s]
2021-05-17 22:07:18.785578 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 22:07:18.799797 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:07:18.801165 (Thread-3): finished collecting timing info
2021-05-17 22:07:18.801354 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 22:07:18.801753 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '436b149b-246b-4a0c-8392-ace8b75e636e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136671f0>]}
2021-05-17 22:07:18.802199 (Thread-3): 18:07:18 | 3 of 4 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 2.39s]
2021-05-17 22:07:18.802404 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:07:18.804079 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:07:18.804338 (MainThread): Using postgres connection "master".
2021-05-17 22:07:18.804479 (MainThread): On master: BEGIN
2021-05-17 22:07:18.804621 (MainThread): Opening a new connection, currently in state closed
2021-05-17 22:07:18.892915 (MainThread): SQL status: BEGIN in 0.09 seconds
2021-05-17 22:07:18.893116 (MainThread): On master: COMMIT
2021-05-17 22:07:18.893223 (MainThread): Using postgres connection "master".
2021-05-17 22:07:18.893313 (MainThread): On master: COMMIT
2021-05-17 22:07:18.894335 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:07:18.894535 (MainThread): On master: Close
2021-05-17 22:07:18.894959 (MainThread): 18:07:18 | 
2021-05-17 22:07:18.895136 (MainThread): 18:07:18 | Finished running 4 table models in 2.62s.
2021-05-17 22:07:18.895361 (MainThread): Connection 'master' was properly closed.
2021-05-17 22:07:18.895501 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 22:07:18.895619 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 22:07:18.895714 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 22:07:18.895794 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 22:07:18.902210 (MainThread): 
2021-05-17 22:07:18.902471 (MainThread): Completed successfully
2021-05-17 22:07:18.902671 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-05-17 22:07:18.902945 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137f9c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113636460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136369a0>]}
2021-05-17 22:07:18.903250 (MainThread): Flushing usage events
2021-05-17 22:08:11.865154 (MainThread): Running with dbt=0.19.1
2021-05-17 22:08:11.946259 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-17 22:08:11.947220 (MainThread): Tracking: tracking
2021-05-17 22:08:11.964423 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be23d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be465b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be46df0>]}
2021-05-17 22:08:11.979633 (MainThread): Partial parsing not enabled
2021-05-17 22:08:11.981135 (MainThread): Parsing macros/catalog.sql
2021-05-17 22:08:11.985784 (MainThread): Parsing macros/relations.sql
2021-05-17 22:08:11.987936 (MainThread): Parsing macros/adapters.sql
2021-05-17 22:08:12.012528 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-17 22:08:12.015687 (MainThread): Parsing macros/core.sql
2021-05-17 22:08:12.020062 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-17 22:08:12.029559 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-17 22:08:12.031525 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-17 22:08:12.050904 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-17 22:08:12.148252 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-17 22:08:12.172126 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-17 22:08:12.174319 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-17 22:08:12.181207 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-17 22:08:12.198157 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-17 22:08:12.207018 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-17 22:08:12.214682 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-17 22:08:12.220187 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-17 22:08:12.221744 (MainThread): Parsing macros/etc/query.sql
2021-05-17 22:08:12.223034 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-17 22:08:12.224909 (MainThread): Parsing macros/etc/datetime.sql
2021-05-17 22:08:12.234242 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-17 22:08:12.236449 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-17 22:08:12.238440 (MainThread): Parsing macros/adapters/common.sql
2021-05-17 22:08:12.289319 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-17 22:08:12.292008 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-17 22:08:12.294274 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-17 22:08:12.296742 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-17 22:08:12.306669 (MainThread): Partial parsing not enabled
2021-05-17 22:08:12.406475 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.418489 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.422579 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:12.426264 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:12.481009 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0cf68904-4a6b-42c8-ae05-ff1f95d24f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd6d60>]}
2021-05-17 22:08:12.484980 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0cf68904-4a6b-42c8-ae05-ff1f95d24f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfe3e50>]}
2021-05-17 22:08:12.485241 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-17 22:08:12.485889 (MainThread): 
2021-05-17 22:08:12.486197 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:08:12.487179 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-17 22:08:12.497624 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-17 22:08:12.497757 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-17 22:08:12.497862 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-17 22:08:12.557817 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.06 seconds
2021-05-17 22:08:12.561346 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-17 22:08:12.562779 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:08:12.570311 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:08:12.570479 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-17 22:08:12.570595 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-17 22:08:12.638415 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.07 seconds
2021-05-17 22:08:12.638568 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-17 22:08:12.638650 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-17 22:08:12.641725 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-17 22:08:12.642425 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-17 22:08:12.642684 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-17 22:08:12.646951 (MainThread): Using postgres connection "master".
2021-05-17 22:08:12.647083 (MainThread): On master: BEGIN
2021-05-17 22:08:12.647180 (MainThread): Opening a new connection, currently in state init
2021-05-17 22:08:12.655325 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:08:12.655515 (MainThread): Using postgres connection "master".
2021-05-17 22:08:12.655620 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-17 22:08:12.671143 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-17 22:08:12.671793 (MainThread): On master: ROLLBACK
2021-05-17 22:08:12.672033 (MainThread): Using postgres connection "master".
2021-05-17 22:08:12.672140 (MainThread): On master: BEGIN
2021-05-17 22:08:12.672450 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:08:12.672592 (MainThread): On master: COMMIT
2021-05-17 22:08:12.672704 (MainThread): Using postgres connection "master".
2021-05-17 22:08:12.672797 (MainThread): On master: COMMIT
2021-05-17 22:08:12.673010 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:08:12.673158 (MainThread): On master: Close
2021-05-17 22:08:12.673481 (MainThread): 18:08:12 | Concurrency: 4 threads (target='dev')
2021-05-17 22:08:12.673626 (MainThread): 18:08:12 | 
2021-05-17 22:08:12.676334 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-17 22:08:12.676681 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-17 22:08:12.676947 (Thread-1): 18:08:12 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-17 22:08:12.677053 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:08:12.677198 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-17 22:08:12.677423 (Thread-2): 18:08:12 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-17 22:08:12.677826 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.678024 (Thread-3): 18:08:12 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-17 22:08:12.678231 (Thread-4): 18:08:12 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-17 22:08:12.678534 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:12.678683 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-17 22:08:12.679040 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:12.679340 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.679455 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-17 22:08:12.680826 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:08:12.680969 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-17 22:08:12.681086 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-17 22:08:12.682296 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:08:12.683629 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:08:12.684715 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:08:12.685037 (Thread-1): finished collecting timing info
2021-05-17 22:08:12.685402 (Thread-2): finished collecting timing info
2021-05-17 22:08:12.696695 (Thread-4): finished collecting timing info
2021-05-17 22:08:12.703216 (Thread-3): finished collecting timing info
2021-05-17 22:08:12.738334 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:12.738631 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.749880 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:12.754582 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.754701 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-17 22:08:12.754833 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-17 22:08:12.754941 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-17 22:08:12.755040 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-17 22:08:12.755150 (Thread-2): Opening a new connection, currently in state init
2021-05-17 22:08:12.755246 (Thread-4): Opening a new connection, currently in state init
2021-05-17 22:08:12.755339 (Thread-3): Opening a new connection, currently in state init
2021-05-17 22:08:12.755432 (Thread-1): Opening a new connection, currently in state closed
2021-05-17 22:08:12.765596 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:08:12.765777 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:08:12.768161 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:12.768277 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:08:12.770534 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:12.770674 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-17 22:08:12.770778 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:08:12.772598 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.772720 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 22:08:12.774599 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.774814 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:08:12.774972 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:08:12.775151 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:08:12.775293 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:08:12.786766 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-17 22:08:12.786900 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:08:12.787008 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:08:12.788267 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-17 22:08:12.789830 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-17 22:08:12.791143 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-17 22:08:12.791324 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:12.791908 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:12.792068 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-17 22:08:12.792266 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-17 22:08:12.792498 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.792680 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.792937 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-17 22:08:12.793174 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:08:12.793278 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-17 22:08:12.793354 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:08:12.793534 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:12.793653 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:08:12.793856 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:12.793982 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-17 22:08:12.794083 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-17 22:08:12.794203 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.794306 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-17 22:08:12.794410 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.794592 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-17 22:08:12.794791 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-17 22:08:12.814836 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-17 22:08:12.822778 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.823484 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-17 22:08:12.850927 (Thread-4): SQL status: ALTER TABLE in 0.03 seconds
2021-05-17 22:08:12.853012 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.853146 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-17 22:08:12.853680 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:08:12.862833 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:08:12.863017 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.863136 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-17 22:08:12.863974 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:08:12.867701 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-17 22:08:12.867854 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-17 22:08:12.896118 (Thread-4): SQL status: DROP TABLE in 0.03 seconds
2021-05-17 22:08:12.897521 (Thread-4): finished collecting timing info
2021-05-17 22:08:12.897668 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-17 22:08:12.897985 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cf68904-4a6b-42c8-ae05-ff1f95d24f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c049e50>]}
2021-05-17 22:08:12.898247 (Thread-4): 18:08:12 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.22s]
2021-05-17 22:08:12.898381 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-17 22:08:12.908519 (Thread-1): SQL status: SELECT 1167 in 0.11 seconds
2021-05-17 22:08:12.910975 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.911124 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-17 22:08:12.911586 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:08:12.913491 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.913615 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-17 22:08:12.914066 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:08:12.915214 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:08:12.915321 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.915420 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-17 22:08:12.916013 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:08:12.917268 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-17 22:08:12.917379 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-17 22:08:12.919523 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:08:12.920604 (Thread-1): finished collecting timing info
2021-05-17 22:08:12.920753 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-17 22:08:12.921147 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cf68904-4a6b-42c8-ae05-ff1f95d24f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be9cdc0>]}
2021-05-17 22:08:12.921472 (Thread-1): 18:08:12 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.24s]
2021-05-17 22:08:12.921605 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-17 22:08:13.739968 (Thread-3): SQL status: SELECT 1119 in 0.95 seconds
2021-05-17 22:08:13.742290 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:13.742434 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-17 22:08:14.268084 (Thread-2): SQL status: SELECT 6941 in 1.47 seconds
2021-05-17 22:08:14.269971 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:14.270089 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-17 22:08:14.270507 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:08:14.273775 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:14.273909 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-17 22:08:14.274390 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:08:14.275400 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:08:14.275520 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:14.275609 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-17 22:08:14.285678 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-05-17 22:08:14.287301 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-17 22:08:14.287425 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-17 22:08:14.287597 (Thread-3): SQL status: ALTER TABLE in 0.55 seconds
2021-05-17 22:08:14.289750 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:14.289885 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-17 22:08:14.290072 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-17 22:08:14.291171 (Thread-2): finished collecting timing info
2021-05-17 22:08:14.291328 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-17 22:08:14.291476 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-17 22:08:14.291832 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cf68904-4a6b-42c8-ae05-ff1f95d24f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c172d60>]}
2021-05-17 22:08:14.292877 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 22:08:14.293226 (Thread-2): 18:08:14 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.61s]
2021-05-17 22:08:14.293352 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:14.293496 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-17 22:08:14.293613 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-17 22:08:14.294303 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:08:14.295903 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-17 22:08:14.296027 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-17 22:08:14.303634 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-17 22:08:14.304872 (Thread-3): finished collecting timing info
2021-05-17 22:08:14.305044 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-17 22:08:14.305569 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cf68904-4a6b-42c8-ae05-ff1f95d24f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0cc5e0>]}
2021-05-17 22:08:14.306068 (Thread-3): 18:08:14 | 3 of 4 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.63s]
2021-05-17 22:08:14.306357 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-17 22:08:14.308078 (MainThread): Acquiring new postgres connection "master".
2021-05-17 22:08:14.308356 (MainThread): Using postgres connection "master".
2021-05-17 22:08:14.308530 (MainThread): On master: BEGIN
2021-05-17 22:08:14.308704 (MainThread): Opening a new connection, currently in state closed
2021-05-17 22:08:14.317728 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-17 22:08:14.317917 (MainThread): On master: COMMIT
2021-05-17 22:08:14.318049 (MainThread): Using postgres connection "master".
2021-05-17 22:08:14.318145 (MainThread): On master: COMMIT
2021-05-17 22:08:14.318348 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-17 22:08:14.318476 (MainThread): On master: Close
2021-05-17 22:08:14.318861 (MainThread): 18:08:14 | 
2021-05-17 22:08:14.319030 (MainThread): 18:08:14 | Finished running 4 table models in 1.83s.
2021-05-17 22:08:14.319203 (MainThread): Connection 'master' was properly closed.
2021-05-17 22:08:14.319389 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-17 22:08:14.319658 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-17 22:08:14.319806 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-17 22:08:14.319933 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-17 22:08:14.326454 (MainThread): 
2021-05-17 22:08:14.326682 (MainThread): Completed successfully
2021-05-17 22:08:14.326830 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-05-17 22:08:14.327081 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b665040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6651c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6656a0>]}
2021-05-17 22:08:14.327369 (MainThread): Flushing usage events
2021-05-18 17:40:44.756699 (MainThread): Running with dbt=0.19.1
2021-05-18 17:40:44.860968 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-18 17:40:44.862715 (MainThread): Tracking: tracking
2021-05-18 17:40:44.889542 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123b6d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123d3580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123d37c0>]}
2021-05-18 17:40:44.903617 (MainThread): Partial parsing not enabled
2021-05-18 17:40:44.905118 (MainThread): Parsing macros/catalog.sql
2021-05-18 17:40:44.909791 (MainThread): Parsing macros/relations.sql
2021-05-18 17:40:44.912018 (MainThread): Parsing macros/adapters.sql
2021-05-18 17:40:44.936231 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-18 17:40:44.940806 (MainThread): Parsing macros/core.sql
2021-05-18 17:40:44.945904 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-18 17:40:44.957593 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-18 17:40:44.960115 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-18 17:40:44.983359 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-18 17:40:45.018989 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-18 17:40:45.040960 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-18 17:40:45.043472 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-18 17:40:45.050809 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-18 17:40:45.065640 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-18 17:40:45.073097 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-18 17:40:45.080273 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-18 17:40:45.085969 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-18 17:40:45.087307 (MainThread): Parsing macros/etc/query.sql
2021-05-18 17:40:45.088632 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-18 17:40:45.090624 (MainThread): Parsing macros/etc/datetime.sql
2021-05-18 17:40:45.099946 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-18 17:40:45.102302 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-18 17:40:45.104435 (MainThread): Parsing macros/adapters/common.sql
2021-05-18 17:40:45.149390 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-18 17:40:45.151715 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-18 17:40:45.153675 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-18 17:40:45.155803 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-18 17:40:45.163484 (MainThread): Partial parsing not enabled
2021-05-18 17:40:45.220848 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.234502 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.240460 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:45.245000 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:45.311390 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e506109-9b50-4843-8573-549ad9b58aa6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112564490>]}
2021-05-18 17:40:45.317198 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e506109-9b50-4843-8573-549ad9b58aa6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11258e310>]}
2021-05-18 17:40:45.317486 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-18 17:40:45.318591 (MainThread): 
2021-05-18 17:40:45.318918 (MainThread): Acquiring new postgres connection "master".
2021-05-18 17:40:45.319938 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-18 17:40:45.330707 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-18 17:40:45.330857 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-18 17:40:45.330969 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-18 17:40:45.438523 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.11 seconds
2021-05-18 17:40:45.442488 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-18 17:40:45.443801 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-18 17:40:45.450265 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-18 17:40:45.450410 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-18 17:40:45.450519 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-18 17:40:45.460886 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-18 17:40:45.461057 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-18 17:40:45.461159 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-18 17:40:45.467458 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.01 seconds
2021-05-18 17:40:45.468217 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-18 17:40:45.468797 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-18 17:40:45.473624 (MainThread): Using postgres connection "master".
2021-05-18 17:40:45.473770 (MainThread): On master: BEGIN
2021-05-18 17:40:45.473877 (MainThread): Opening a new connection, currently in state init
2021-05-18 17:40:45.482936 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-18 17:40:45.483146 (MainThread): Using postgres connection "master".
2021-05-18 17:40:45.483252 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-18 17:40:45.514340 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-18 17:40:45.532121 (MainThread): On master: ROLLBACK
2021-05-18 17:40:45.532481 (MainThread): Using postgres connection "master".
2021-05-18 17:40:45.532613 (MainThread): On master: BEGIN
2021-05-18 17:40:45.533006 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-18 17:40:45.533167 (MainThread): On master: COMMIT
2021-05-18 17:40:45.533281 (MainThread): Using postgres connection "master".
2021-05-18 17:40:45.533378 (MainThread): On master: COMMIT
2021-05-18 17:40:45.533590 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-18 17:40:45.533721 (MainThread): On master: Close
2021-05-18 17:40:45.534151 (MainThread): 13:40:45 | Concurrency: 4 threads (target='dev')
2021-05-18 17:40:45.534335 (MainThread): 13:40:45 | 
2021-05-18 17:40:45.537174 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-18 17:40:45.537575 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-18 17:40:45.537723 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-18 17:40:45.537964 (Thread-1): 13:40:45 | 1 of 4 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-18 17:40:45.538069 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-18 17:40:45.538356 (Thread-2): 13:40:45 | 2 of 4 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-18 17:40:45.538571 (Thread-3): 13:40:45 | 3 of 4 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-18 17:40:45.538914 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.539156 (Thread-4): 13:40:45 | 4 of 4 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-18 17:40:45.539480 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:45.539777 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:45.539936 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-18 17:40:45.540210 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.540367 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-18 17:40:45.540506 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-18 17:40:45.541919 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-18 17:40:45.542121 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-18 17:40:45.543465 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-18 17:40:45.544787 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-18 17:40:45.546087 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-18 17:40:45.546593 (Thread-1): finished collecting timing info
2021-05-18 17:40:45.553280 (Thread-2): finished collecting timing info
2021-05-18 17:40:45.553545 (Thread-3): finished collecting timing info
2021-05-18 17:40:45.569655 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.572519 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:45.572698 (Thread-4): finished collecting timing info
2021-05-18 17:40:45.576089 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:45.576253 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-18 17:40:45.576390 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-18 17:40:45.578946 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.579085 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-18 17:40:45.579203 (Thread-1): Opening a new connection, currently in state closed
2021-05-18 17:40:45.579308 (Thread-2): Opening a new connection, currently in state init
2021-05-18 17:40:45.579407 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-18 17:40:45.579512 (Thread-3): Opening a new connection, currently in state init
2021-05-18 17:40:45.579963 (Thread-4): Opening a new connection, currently in state init
2021-05-18 17:40:45.602731 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-18 17:40:45.602940 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-18 17:40:45.603037 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-18 17:40:45.605148 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.605240 (Thread-3): SQL status: DROP TABLE in 0.03 seconds
2021-05-18 17:40:45.607291 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:45.609234 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.609394 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-18 17:40:45.611327 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:45.611455 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-18 17:40:45.611567 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-18 17:40:45.611795 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-18 17:40:45.611909 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-18 17:40:45.612201 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-18 17:40:45.612350 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-18 17:40:45.612500 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-18 17:40:45.625522 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-18 17:40:45.625683 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-18 17:40:45.626958 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-18 17:40:45.628161 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-18 17:40:45.628965 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:45.629083 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-18 17:40:45.629404 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.629519 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-18 17:40:45.629662 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-18 17:40:45.629792 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:45.629885 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-18 17:40:45.630058 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.630173 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-18 17:40:45.630305 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-18 17:40:45.630435 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-18 17:40:45.630563 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:45.630640 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.630740 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.630832 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-18 17:40:45.630927 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-18 17:40:45.631018 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-18 17:40:45.631322 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-18 17:40:45.631436 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:45.631525 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-18 17:40:45.715733 (Thread-4): SQL status: SELECT 495 in 0.08 seconds
2021-05-18 17:40:45.724269 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.724513 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-18 17:40:45.727857 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-18 17:40:45.731359 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.731593 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-18 17:40:45.732331 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-18 17:40:45.743358 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-18 17:40:45.743517 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.743612 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-18 17:40:45.746521 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-18 17:40:45.752138 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-18 17:40:45.752346 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-18 17:40:45.762053 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-18 17:40:45.763453 (Thread-4): finished collecting timing info
2021-05-18 17:40:45.763624 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-18 17:40:45.764200 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e506109-9b50-4843-8573-549ad9b58aa6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11254dd60>]}
2021-05-18 17:40:45.764701 (Thread-4): 13:40:45 | 4 of 4 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.22s]
2021-05-18 17:40:45.764934 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-18 17:40:45.818563 (Thread-1): SQL status: SELECT 1167 in 0.19 seconds
2021-05-18 17:40:45.820616 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.820736 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-18 17:40:45.821137 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-18 17:40:45.823036 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.823198 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-18 17:40:45.823641 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-18 17:40:45.824857 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-18 17:40:45.825040 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.825163 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-18 17:40:45.829307 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-18 17:40:45.831407 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-18 17:40:45.831545 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-18 17:40:45.835714 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-18 17:40:45.837058 (Thread-1): finished collecting timing info
2021-05-18 17:40:45.837212 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-18 17:40:45.837652 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e506109-9b50-4843-8573-549ad9b58aa6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bffc70>]}
2021-05-18 17:40:45.838077 (Thread-1): 13:40:45 | 1 of 4 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.30s]
2021-05-18 17:40:45.838261 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-18 17:40:46.582514 (Thread-3): SQL status: SELECT 1119 in 0.95 seconds
2021-05-18 17:40:46.584454 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:46.584578 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-18 17:40:46.713902 (Thread-2): SQL status: SELECT 6941 in 1.08 seconds
2021-05-18 17:40:46.716046 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:46.716161 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-18 17:40:46.716610 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-18 17:40:46.719564 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:46.719686 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-18 17:40:46.720184 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-18 17:40:46.721111 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-18 17:40:46.721207 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:46.721279 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-18 17:40:46.721969 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-18 17:40:46.723171 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-18 17:40:46.723295 (Thread-3): SQL status: ALTER TABLE in 0.14 seconds
2021-05-18 17:40:46.723385 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-18 17:40:46.725205 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:46.725416 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-18 17:40:46.725934 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-18 17:40:46.726981 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-18 17:40:46.727115 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:46.727199 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-18 17:40:46.727860 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-18 17:40:46.728940 (Thread-2): finished collecting timing info
2021-05-18 17:40:46.729102 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-18 17:40:46.729507 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e506109-9b50-4843-8573-549ad9b58aa6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125fa0a0>]}
2021-05-18 17:40:46.729827 (Thread-2): 13:40:46 | 2 of 4 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.19s]
2021-05-18 17:40:46.729967 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-18 17:40:46.732532 (Thread-3): SQL status: COMMIT in 0.01 seconds
2021-05-18 17:40:46.733970 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-18 17:40:46.734097 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-18 17:40:46.740398 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-18 17:40:46.741863 (Thread-3): finished collecting timing info
2021-05-18 17:40:46.742085 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-18 17:40:46.742555 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e506109-9b50-4843-8573-549ad9b58aa6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126eec10>]}
2021-05-18 17:40:46.742965 (Thread-3): 13:40:46 | 3 of 4 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.20s]
2021-05-18 17:40:46.743117 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-18 17:40:46.744624 (MainThread): Acquiring new postgres connection "master".
2021-05-18 17:40:46.744809 (MainThread): Using postgres connection "master".
2021-05-18 17:40:46.744910 (MainThread): On master: BEGIN
2021-05-18 17:40:46.745013 (MainThread): Opening a new connection, currently in state closed
2021-05-18 17:40:46.753884 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-18 17:40:46.754082 (MainThread): On master: COMMIT
2021-05-18 17:40:46.754190 (MainThread): Using postgres connection "master".
2021-05-18 17:40:46.754284 (MainThread): On master: COMMIT
2021-05-18 17:40:46.754480 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-18 17:40:46.754607 (MainThread): On master: Close
2021-05-18 17:40:46.754973 (MainThread): 13:40:46 | 
2021-05-18 17:40:46.755116 (MainThread): 13:40:46 | Finished running 4 table models in 1.44s.
2021-05-18 17:40:46.755230 (MainThread): Connection 'master' was properly closed.
2021-05-18 17:40:46.755317 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-18 17:40:46.755399 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-18 17:40:46.755564 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-18 17:40:46.755696 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-18 17:40:46.760356 (MainThread): 
2021-05-18 17:40:46.760541 (MainThread): Completed successfully
2021-05-18 17:40:46.760678 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-05-18 17:40:46.760871 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111904340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111904b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c128b0>]}
2021-05-18 17:40:46.761075 (MainThread): Flushing usage events
2021-05-19 19:29:33.587612 (MainThread): Running with dbt=0.19.1
2021-05-19 19:29:33.701453 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:29:33.703013 (MainThread): Tracking: tracking
2021-05-19 19:29:33.727029 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112590f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125b0760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125b0fa0>]}
2021-05-19 19:29:33.741836 (MainThread): Partial parsing not enabled
2021-05-19 19:29:33.743434 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:29:33.748630 (MainThread): Parsing macros/relations.sql
2021-05-19 19:29:33.750846 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:29:33.775464 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:29:33.779891 (MainThread): Parsing macros/core.sql
2021-05-19 19:29:33.784766 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:29:33.796595 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:29:33.799195 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:29:33.823419 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:29:33.858791 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:29:33.882216 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:29:33.884720 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:29:33.892349 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:29:33.907242 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:29:33.914510 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:29:33.922006 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:29:33.928758 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:29:33.932095 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:29:33.934501 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:29:33.937418 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:29:33.949286 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:29:33.952840 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:29:33.955488 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:29:34.004229 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:29:34.006865 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:29:34.009000 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:29:34.011679 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:29:34.020529 (MainThread): Partial parsing not enabled
2021-05-19 19:29:34.077336 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.089810 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.094154 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:34.098394 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:34.102510 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:29:34.105734 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:29:34.109774 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:29:34.113107 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.169036 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74316921-06a2-4481-9f68-4e5efb80012b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127dc670>]}
2021-05-19 19:29:34.176414 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74316921-06a2-4481-9f68-4e5efb80012b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112723bb0>]}
2021-05-19 19:29:34.176740 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:29:34.177573 (MainThread): 
2021-05-19 19:29:34.177915 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:29:34.179032 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:29:34.190339 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:29:34.190497 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:29:34.190614 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:29:34.260078 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.07 seconds
2021-05-19 19:29:34.263552 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:29:34.264961 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:29:34.271187 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:29:34.271325 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:29:34.271430 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:29:34.281836 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:29:34.282013 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:29:34.282112 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:29:34.291118 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.01 seconds
2021-05-19 19:29:34.291927 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:29:34.292528 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:29:34.297863 (MainThread): Using postgres connection "master".
2021-05-19 19:29:34.298034 (MainThread): On master: BEGIN
2021-05-19 19:29:34.298155 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:29:34.309387 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:29:34.311645 (MainThread): Using postgres connection "master".
2021-05-19 19:29:34.312073 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:29:34.345313 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-19 19:29:34.345979 (MainThread): On master: ROLLBACK
2021-05-19 19:29:34.346303 (MainThread): Using postgres connection "master".
2021-05-19 19:29:34.346433 (MainThread): On master: BEGIN
2021-05-19 19:29:34.346763 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:29:34.346890 (MainThread): On master: COMMIT
2021-05-19 19:29:34.346992 (MainThread): Using postgres connection "master".
2021-05-19 19:29:34.347082 (MainThread): On master: COMMIT
2021-05-19 19:29:34.347270 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:29:34.347393 (MainThread): On master: Close
2021-05-19 19:29:34.347703 (MainThread): 15:29:34 | Concurrency: 4 threads (target='dev')
2021-05-19 19:29:34.347848 (MainThread): 15:29:34 | 
2021-05-19 19:29:34.350666 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:29:34.350968 (Thread-1): 15:29:34 | 1 of 5 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:29:34.351148 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:29:34.351476 (Thread-2): 15:29:34 | 2 of 5 START view model fetch_takehome.dim_brands.................... [RUN]
2021-05-19 19:29:34.351841 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.351994 (Thread-3): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:29:34.352217 (Thread-4): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:29:34.352606 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.352739 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:29:34.352971 (Thread-3): 15:29:34 | 3 of 5 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:29:34.353193 (Thread-4): 15:29:34 | 4 of 5 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:29:34.353329 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:29:34.354855 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:29:34.355399 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:34.355853 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:34.357393 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:29:34.357717 (Thread-3): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:29:34.357880 (Thread-4): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:29:34.359458 (Thread-3): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:29:34.360851 (Thread-4): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:29:34.361399 (Thread-1): finished collecting timing info
2021-05-19 19:29:34.367949 (Thread-2): finished collecting timing info
2021-05-19 19:29:34.397963 (Thread-3): finished collecting timing info
2021-05-19 19:29:34.403040 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:34.403168 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:29:34.403840 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.406227 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.406331 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:29:34.406410 (Thread-4): finished collecting timing info
2021-05-19 19:29:34.406525 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:29:34.406611 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop view if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:29:34.409366 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:34.409525 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:29:34.409642 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:29:34.409748 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:29:34.410158 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:29:34.417564 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:29:34.419954 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:34.420285 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:29:34.420611 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:29:34.420759 (Thread-2): SQL status: DROP VIEW in 0.01 seconds
2021-05-19 19:29:34.426222 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:29:34.426332 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:29:34.427588 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:29:34.429599 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.431350 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.433075 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:34.433328 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop view if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:29:34.433436 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:29:34.433533 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:29:34.433895 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:29:34.434970 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:29:34.435154 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-05-19 19:29:34.439250 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:29:34.439421 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:29:34.440400 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:29:34.440860 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.441002 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:34.441161 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:29:34.441265 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.441355 (Thread-4): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:29:34.441442 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:34.441585 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:29:34.441699 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:29:34.441834 (Thread-3): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:29:34.441933 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:29:34.442071 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.442161 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:29:34.442312 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:34.442428 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:29:34.442509 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:29:34.442603 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.442681 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:29:34.442775 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:34.442907 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */

  create view "postgres"."fetch_takehome"."dim_brands__dbt_tmp" as (
    select
brandId::bigint as brandId,
barcode::bigint as barcode,
category as category,
categoryCode as categoryCode,
cpgId::bigint as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );

2021-05-19 19:29:34.443052 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:29:34.462698 (Thread-2): SQL status: CREATE VIEW in 0.02 seconds
2021-05-19 19:29:34.468193 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.468317 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 19:29:34.470120 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:34.476765 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:29:34.476909 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.476992 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:29:34.478003 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:29:34.480960 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:29:34.481092 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop view if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:29:34.481350 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-05-19 19:29:34.482302 (Thread-2): finished collecting timing info
2021-05-19 19:29:34.482424 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:29:34.482755 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74316921-06a2-4481-9f68-4e5efb80012b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11292ca60>]}
2021-05-19 19:29:34.483027 (Thread-2): 15:29:34 | 2 of 5 OK created view model fetch_takehome.dim_brands............... [CREATE VIEW in 0.13s]
2021-05-19 19:29:34.483146 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:29:34.483318 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:29:34.483596 (Thread-2): 15:29:34 | 5 of 5 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:29:34.483868 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.483975 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:29:34.486148 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:29:34.486520 (Thread-2): finished collecting timing info
2021-05-19 19:29:34.488508 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.488599 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:29:34.488680 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:29:34.495916 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:29:34.497724 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.497839 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:29:34.498073 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:29:34.499378 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:29:34.499758 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.499845 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:29:34.500084 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:29:34.500192 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.500268 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:29:34.527563 (Thread-2): SQL status: SELECT 495 in 0.03 seconds
2021-05-19 19:29:34.529505 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.529616 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:29:34.530044 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:34.531849 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.531950 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:29:34.532319 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:34.533258 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:29:34.533360 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.533441 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:29:34.534744 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:29:34.535932 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:29:34.536026 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:29:34.540384 (Thread-1): SQL status: SELECT 1167 in 0.10 seconds
2021-05-19 19:29:34.542517 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.542639 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:29:34.542756 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:29:34.543935 (Thread-2): finished collecting timing info
2021-05-19 19:29:34.544094 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:34.544220 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:29:34.546272 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.546501 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:29:34.546947 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74316921-06a2-4481-9f68-4e5efb80012b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126f28b0>]}
2021-05-19 19:29:34.547383 (Thread-2): 15:29:34 | 5 of 5 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-19 19:29:34.547495 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:34.547692 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:29:34.548780 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:29:34.549058 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.549145 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:29:34.552978 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:29:34.554377 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:29:34.554514 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:29:34.558511 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:29:34.559597 (Thread-1): finished collecting timing info
2021-05-19 19:29:34.559742 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:29:34.560083 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74316921-06a2-4481-9f68-4e5efb80012b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112606be0>]}
2021-05-19 19:29:34.560369 (Thread-1): 15:29:34 | 1 of 5 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.21s]
2021-05-19 19:29:34.560493 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:29:35.302053 (Thread-4): SQL status: SELECT 1119 in 0.86 seconds
2021-05-19 19:29:35.304770 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:35.304920 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:29:35.468936 (Thread-3): SQL status: SELECT 6941 in 1.03 seconds
2021-05-19 19:29:35.471418 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:35.471563 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:29:35.472040 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:35.474859 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:35.475021 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:29:35.477072 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:35.478314 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:29:35.478440 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:35.478532 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:29:35.479173 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:29:35.480711 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:29:35.480842 (Thread-4): SQL status: ALTER TABLE in 0.18 seconds
2021-05-19 19:29:35.480974 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:29:35.482941 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:35.483170 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:29:35.483629 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:29:35.484945 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:29:35.485063 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:35.485157 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:29:35.485698 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:29:35.487053 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:29:35.487200 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:29:35.487368 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:29:35.488651 (Thread-3): finished collecting timing info
2021-05-19 19:29:35.488841 (Thread-3): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:29:35.489244 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74316921-06a2-4481-9f68-4e5efb80012b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11292ce80>]}
2021-05-19 19:29:35.489588 (Thread-3): 15:29:35 | 3 of 5 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.13s]
2021-05-19 19:29:35.489754 (Thread-3): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:29:35.492105 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:29:35.493413 (Thread-4): finished collecting timing info
2021-05-19 19:29:35.493584 (Thread-4): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:29:35.493959 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74316921-06a2-4481-9f68-4e5efb80012b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11293a670>]}
2021-05-19 19:29:35.494286 (Thread-4): 15:29:35 | 4 of 5 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.14s]
2021-05-19 19:29:35.494435 (Thread-4): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:29:35.495780 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:29:35.496111 (MainThread): Using postgres connection "master".
2021-05-19 19:29:35.496309 (MainThread): On master: BEGIN
2021-05-19 19:29:35.496534 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:29:35.506224 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:29:35.506414 (MainThread): On master: COMMIT
2021-05-19 19:29:35.506516 (MainThread): Using postgres connection "master".
2021-05-19 19:29:35.506605 (MainThread): On master: COMMIT
2021-05-19 19:29:35.506801 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:29:35.506927 (MainThread): On master: Close
2021-05-19 19:29:35.507295 (MainThread): 15:29:35 | 
2021-05-19 19:29:35.507436 (MainThread): 15:29:35 | Finished running 1 view model, 4 table models in 1.33s.
2021-05-19 19:29:35.507546 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:29:35.507631 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:29:35.507711 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:29:35.507788 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:29:35.507864 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:29:35.512814 (MainThread): 
2021-05-19 19:29:35.512996 (MainThread): Completed successfully
2021-05-19 19:29:35.513133 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-05-19 19:29:35.513320 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128c0c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126e4a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129289d0>]}
2021-05-19 19:29:35.513521 (MainThread): Flushing usage events
2021-05-19 19:30:58.175811 (MainThread): Running with dbt=0.19.1
2021-05-19 19:30:58.241583 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:30:58.242891 (MainThread): Tracking: tracking
2021-05-19 19:30:58.254379 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1bdcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1e3580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1e37c0>]}
2021-05-19 19:30:58.267805 (MainThread): Partial parsing not enabled
2021-05-19 19:30:58.268872 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:30:58.272750 (MainThread): Parsing macros/relations.sql
2021-05-19 19:30:58.274711 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:30:58.297602 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:30:58.300453 (MainThread): Parsing macros/core.sql
2021-05-19 19:30:58.304464 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:30:58.313624 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:30:58.315427 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:30:58.334273 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:30:58.368776 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:30:58.390208 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:30:58.392369 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:30:58.398879 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:30:58.413207 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:30:58.420340 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:30:58.426904 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:30:58.431958 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:30:58.432923 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:30:58.433988 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:30:58.435642 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:30:58.444732 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:30:58.446712 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:30:58.448420 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:30:58.491955 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:30:58.493894 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:30:58.495427 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:30:58.497180 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:30:58.504627 (MainThread): Partial parsing not enabled
2021-05-19 19:30:58.556711 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.568017 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.571403 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:58.574683 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:58.578032 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:30:58.581009 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:30:58.584769 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:30:58.587886 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:30:58.632766 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3bb8b3a8-2c6e-4eea-b6d1-d588eca3eb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f432c40>]}
2021-05-19 19:30:58.636303 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3bb8b3a8-2c6e-4eea-b6d1-d588eca3eb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f34ec10>]}
2021-05-19 19:30:58.636576 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:30:58.637172 (MainThread): 
2021-05-19 19:30:58.637430 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:30:58.638307 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:30:58.647479 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:30:58.647601 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:30:58.647686 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:30:58.675403 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 19:30:58.678398 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:30:58.679882 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:30:58.686505 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:30:58.686637 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:30:58.686744 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:30:58.695455 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:30:58.695629 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:30:58.695731 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:30:58.698699 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-19 19:30:58.699437 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:30:58.699777 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:30:58.704957 (MainThread): Using postgres connection "master".
2021-05-19 19:30:58.705099 (MainThread): On master: BEGIN
2021-05-19 19:30:58.705207 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:30:58.713545 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:30:58.713709 (MainThread): Using postgres connection "master".
2021-05-19 19:30:58.713805 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:30:58.727484 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-19 19:30:58.728080 (MainThread): On master: ROLLBACK
2021-05-19 19:30:58.728307 (MainThread): Using postgres connection "master".
2021-05-19 19:30:58.728405 (MainThread): On master: BEGIN
2021-05-19 19:30:58.728709 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:30:58.728836 (MainThread): On master: COMMIT
2021-05-19 19:30:58.728939 (MainThread): Using postgres connection "master".
2021-05-19 19:30:58.729027 (MainThread): On master: COMMIT
2021-05-19 19:30:58.729212 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:30:58.729327 (MainThread): On master: Close
2021-05-19 19:30:58.729609 (MainThread): 15:30:58 | Concurrency: 4 threads (target='dev')
2021-05-19 19:30:58.729739 (MainThread): 15:30:58 | 
2021-05-19 19:30:58.731881 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:30:58.732159 (Thread-1): 15:30:58 | 1 of 5 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:30:58.732328 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:30:58.732578 (Thread-2): 15:30:58 | 2 of 5 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:30:58.732901 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.733107 (Thread-3): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:30:58.733519 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:30:58.733644 (Thread-4): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:30:58.733825 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:30:58.734071 (Thread-3): 15:30:58 | 3 of 5 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:30:58.734199 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:30:58.734390 (Thread-4): 15:30:58 | 4 of 5 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:30:58.735688 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:30:58.736051 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:58.737192 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:30:58.737478 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:58.737705 (Thread-3): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:30:58.737988 (Thread-4): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:30:58.739278 (Thread-3): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:30:58.739422 (Thread-1): finished collecting timing info
2021-05-19 19:30:58.740552 (Thread-4): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:30:58.740680 (Thread-2): finished collecting timing info
2021-05-19 19:30:58.757959 (Thread-3): finished collecting timing info
2021-05-19 19:30:58.764709 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.763820 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:30:58.764983 (Thread-4): finished collecting timing info
2021-05-19 19:30:58.768034 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:58.768207 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:30:58.768341 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:30:58.770875 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:58.771058 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:30:58.771178 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:30:58.771291 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:30:58.771401 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:30:58.771503 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:30:58.771970 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:30:58.781761 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:30:58.781952 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:30:58.784148 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:58.784246 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:30:58.786174 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:58.786308 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:30:58.786408 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:30:58.788351 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:30:58.788467 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:30:58.790911 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.791159 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:30:58.791412 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:58.791565 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:58.791669 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:30:58.797210 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:30:58.803749 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:30:58.804888 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:30:58.805967 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:30:58.806161 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:58.806576 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:58.807651 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:30:58.807941 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:30:58.808016 (Thread-4): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:30:58.808173 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:58.808316 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:30:58.808546 (Thread-3): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:30:58.808731 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.808807 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:30:58.808871 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:30:58.809017 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:30:58.809117 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:30:58.809186 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:58.809268 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:30:58.809410 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:58.809501 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:30:58.809563 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:30:58.809663 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId::bigint as brandId,
barcode::bigint as barcode,
category as category,
categoryCode as categoryCode,
cpgId::bigint as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:30:58.809767 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:30:58.809861 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.810104 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:30:58.817556 (Thread-2): Postgres error: invalid input syntax for type bigint: "601ac115be37ce2ead437551"

2021-05-19 19:30:58.817715 (Thread-2): On model.fetch_takehome.dim_brands: ROLLBACK
2021-05-19 19:30:58.818025 (Thread-2): finished collecting timing info
2021-05-19 19:30:58.818173 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:30:58.818581 (Thread-2): Database Error in model dim_brands (models/transformations/dim_brands.sql)
  invalid input syntax for type bigint: "601ac115be37ce2ead437551"
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type bigint: "601ac115be37ce2ead437551"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model dim_brands (models/transformations/dim_brands.sql)
  invalid input syntax for type bigint: "601ac115be37ce2ead437551"
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:30:58.826623 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bb8b3a8-2c6e-4eea-b6d1-d588eca3eb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f56d490>]}
2021-05-19 19:30:58.826978 (Thread-2): 15:30:58 | 2 of 5 ERROR creating table model fetch_takehome.dim_brands.......... [ERROR in 0.09s]
2021-05-19 19:30:58.827122 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:30:58.827272 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:30:58.827614 (Thread-2): 15:30:58 | 5 of 5 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:30:58.827912 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.828029 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:30:58.829199 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:30:58.829600 (Thread-2): finished collecting timing info
2021-05-19 19:30:58.832028 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.832139 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:30:58.832233 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:30:58.841142 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:30:58.843991 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.844103 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:30:58.844368 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:58.845744 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:30:58.846319 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.846463 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:30:58.846802 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:30:58.846945 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.847062 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:30:58.861537 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-19 19:30:58.870181 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.870376 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 19:30:58.870530 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:30:58.873120 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.873422 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:30:58.873765 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:30:58.877100 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.877274 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:30:58.877375 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:30:58.880647 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.880957 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:30:58.881360 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:30:58.881495 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:30:58.888618 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:30:58.889693 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:30:58.889819 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.889919 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.890015 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:30:58.890160 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:30:58.891138 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:30:58.894843 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:30:58.894989 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:30:58.895153 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:30:58.896456 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:30:58.896571 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:30:58.897220 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:58.898471 (Thread-1): finished collecting timing info
2021-05-19 19:30:58.898626 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:30:58.898760 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:58.899126 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bb8b3a8-2c6e-4eea-b6d1-d588eca3eb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f44f400>]}
2021-05-19 19:30:58.900153 (Thread-2): finished collecting timing info
2021-05-19 19:30:58.900532 (Thread-1): 15:30:58 | 1 of 5 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.17s]
2021-05-19 19:30:58.900672 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:30:58.900906 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:30:58.901337 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bb8b3a8-2c6e-4eea-b6d1-d588eca3eb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5fb910>]}
2021-05-19 19:30:58.901985 (Thread-2): 15:30:58 | 5 of 5 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.07s]
2021-05-19 19:30:58.902207 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:30:59.470266 (Thread-4): SQL status: SELECT 1119 in 0.66 seconds
2021-05-19 19:30:59.472477 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:59.472617 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:30:59.636595 (Thread-3): SQL status: SELECT 6941 in 0.83 seconds
2021-05-19 19:30:59.638783 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:59.638890 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:30:59.639229 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:30:59.640810 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:59.640901 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:30:59.641293 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:30:59.642243 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:30:59.642334 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:59.642407 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:30:59.643158 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:30:59.643265 (Thread-4): SQL status: ALTER TABLE in 0.17 seconds
2021-05-19 19:30:59.644411 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:30:59.646211 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:59.646352 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:30:59.646472 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:30:59.647012 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:30:59.648019 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:30:59.648135 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:59.648212 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:30:59.648680 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:30:59.650037 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:30:59.650144 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:30:59.650297 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:59.651331 (Thread-3): finished collecting timing info
2021-05-19 19:30:59.651461 (Thread-3): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:30:59.651766 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bb8b3a8-2c6e-4eea-b6d1-d588eca3eb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f560ca0>]}
2021-05-19 19:30:59.652086 (Thread-3): 15:30:59 | 3 of 5 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.92s]
2021-05-19 19:30:59.652248 (Thread-3): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:30:59.652837 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:30:59.654037 (Thread-4): finished collecting timing info
2021-05-19 19:30:59.654198 (Thread-4): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:30:59.654527 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bb8b3a8-2c6e-4eea-b6d1-d588eca3eb2f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5abdf0>]}
2021-05-19 19:30:59.654804 (Thread-4): 15:30:59 | 4 of 5 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.92s]
2021-05-19 19:30:59.654922 (Thread-4): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:30:59.656151 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:30:59.656324 (MainThread): Using postgres connection "master".
2021-05-19 19:30:59.656412 (MainThread): On master: BEGIN
2021-05-19 19:30:59.656497 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:30:59.664079 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:30:59.684855 (MainThread): On master: COMMIT
2021-05-19 19:30:59.686004 (MainThread): Using postgres connection "master".
2021-05-19 19:30:59.686219 (MainThread): On master: COMMIT
2021-05-19 19:30:59.686722 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:30:59.686992 (MainThread): On master: Close
2021-05-19 19:30:59.687368 (MainThread): 15:30:59 | 
2021-05-19 19:30:59.687489 (MainThread): 15:30:59 | Finished running 5 table models in 1.05s.
2021-05-19 19:30:59.687587 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:30:59.687679 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:30:59.687773 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:30:59.687846 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:30:59.687912 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:30:59.693502 (MainThread): 
2021-05-19 19:30:59.693675 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 19:30:59.693801 (MainThread): 
2021-05-19 19:30:59.693919 (MainThread): Database Error in model dim_brands (models/transformations/dim_brands.sql)
2021-05-19 19:30:59.694024 (MainThread):   invalid input syntax for type bigint: "601ac115be37ce2ead437551"
2021-05-19 19:30:59.694120 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:30:59.694234 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-05-19 19:30:59.694438 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f432c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f25abb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f56d0a0>]}
2021-05-19 19:30:59.694664 (MainThread): Flushing usage events
2021-05-19 19:33:00.707945 (MainThread): Running with dbt=0.19.1
2021-05-19 19:33:00.774962 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:33:00.775723 (MainThread): Tracking: tracking
2021-05-19 19:33:00.787709 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd68e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd825b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd82df0>]}
2021-05-19 19:33:00.801652 (MainThread): Partial parsing not enabled
2021-05-19 19:33:00.802733 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:33:00.806589 (MainThread): Parsing macros/relations.sql
2021-05-19 19:33:00.808315 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:33:00.829810 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:33:00.832628 (MainThread): Parsing macros/core.sql
2021-05-19 19:33:00.836598 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:33:00.845719 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:33:00.847528 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:33:00.866608 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:33:00.901191 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:33:00.922884 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:33:00.924849 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:33:00.931424 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:33:00.945904 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:33:00.953180 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:33:00.959677 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:33:00.964783 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:33:00.965746 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:33:00.966802 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:33:00.968444 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:33:00.977582 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:33:00.979607 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:33:00.981317 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:33:01.025109 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:33:01.027049 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:33:01.028579 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:33:01.030397 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:33:01.037847 (MainThread): Partial parsing not enabled
2021-05-19 19:33:01.090790 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.101932 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.105461 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:01.108987 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:01.112443 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:33:01.115450 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:33:01.119228 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:33:01.122352 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:01.168947 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9329365f-7ab2-4d09-b75d-00064cde9155', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cfcdc70>]}
2021-05-19 19:33:01.172711 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9329365f-7ab2-4d09-b75d-00064cde9155', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cefac10>]}
2021-05-19 19:33:01.172948 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:33:01.173666 (MainThread): 
2021-05-19 19:33:01.173957 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:33:01.174854 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:33:01.183527 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:33:01.183654 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:33:01.183742 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:33:01.204707 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-19 19:33:01.207565 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:33:01.209384 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:33:01.216803 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:33:01.216947 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:33:01.217053 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:33:01.225118 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:33:01.225279 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:33:01.225374 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:33:01.228469 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-19 19:33:01.229173 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:33:01.229374 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:33:01.234112 (MainThread): Using postgres connection "master".
2021-05-19 19:33:01.234240 (MainThread): On master: BEGIN
2021-05-19 19:33:01.234342 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:33:01.242438 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:33:01.242594 (MainThread): Using postgres connection "master".
2021-05-19 19:33:01.242684 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:33:01.256094 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-19 19:33:01.256673 (MainThread): On master: ROLLBACK
2021-05-19 19:33:01.256885 (MainThread): Using postgres connection "master".
2021-05-19 19:33:01.256980 (MainThread): On master: BEGIN
2021-05-19 19:33:01.257229 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:01.257335 (MainThread): On master: COMMIT
2021-05-19 19:33:01.257424 (MainThread): Using postgres connection "master".
2021-05-19 19:33:01.257504 (MainThread): On master: COMMIT
2021-05-19 19:33:01.257669 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:01.257779 (MainThread): On master: Close
2021-05-19 19:33:01.258056 (MainThread): 15:33:01 | Concurrency: 4 threads (target='dev')
2021-05-19 19:33:01.258185 (MainThread): 15:33:01 | 
2021-05-19 19:33:01.260231 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:33:01.260500 (Thread-1): 15:33:01 | 1 of 5 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:33:01.260664 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:33:01.260898 (Thread-2): 15:33:01 | 2 of 5 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:33:01.261057 (Thread-3): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:33:01.261294 (Thread-3): 15:33:01 | 3 of 5 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:33:01.261614 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.261743 (Thread-4): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:33:01.261877 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:33:01.262120 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:01.262413 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:01.262598 (Thread-4): 15:33:01 | 4 of 5 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:33:01.263844 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:33:01.263968 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:33:01.264073 (Thread-3): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:33:01.264322 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:01.265483 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:33:01.266759 (Thread-3): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:33:01.266883 (Thread-4): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:33:01.266962 (Thread-1): finished collecting timing info
2021-05-19 19:33:01.268160 (Thread-4): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:33:01.273399 (Thread-2): finished collecting timing info
2021-05-19 19:33:01.290522 (Thread-3): finished collecting timing info
2021-05-19 19:33:01.301348 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:01.301490 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:33:01.301584 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:33:01.303094 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.304575 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:01.304672 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:33:01.304765 (Thread-4): finished collecting timing info
2021-05-19 19:33:01.304891 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:33:01.304984 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:33:01.307239 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:01.307387 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:33:01.307672 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:33:01.307937 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:33:01.309309 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:33:01.312200 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:01.312352 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:33:01.312663 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:01.324634 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:33:01.324817 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:33:01.327024 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.327145 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:33:01.327304 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:33:01.327428 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:33:01.327568 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:01.329531 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:01.331506 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:01.331677 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:01.332816 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:33:01.332936 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:33:01.333068 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:33:01.333198 (Thread-3): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:33:01.333647 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:01.333784 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:01.334906 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:33:01.334984 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:01.335090 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.335193 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:01.336510 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:33:01.336678 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:33:01.336796 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:33:01.336917 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:01.337413 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:01.337623 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:01.337712 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:33:01.337825 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.337921 (Thread-4): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:33:01.338082 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:33:01.338210 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:01.338468 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:01.338572 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:01.338693 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:01.338793 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode::bigint as barcode,
category as category,
categoryCode as categoryCode,
cpgId::bigint as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:33:01.338892 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:33:01.343193 (Thread-2): Postgres error: invalid input syntax for type bigint: "601ac114be37ce2ead437550"

2021-05-19 19:33:01.343369 (Thread-2): On model.fetch_takehome.dim_brands: ROLLBACK
2021-05-19 19:33:01.343666 (Thread-2): finished collecting timing info
2021-05-19 19:33:01.343849 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:33:01.344396 (Thread-2): Database Error in model dim_brands (models/transformations/dim_brands.sql)
  invalid input syntax for type bigint: "601ac114be37ce2ead437550"
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type bigint: "601ac114be37ce2ead437550"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model dim_brands (models/transformations/dim_brands.sql)
  invalid input syntax for type bigint: "601ac114be37ce2ead437550"
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:33:01.347862 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9329365f-7ab2-4d09-b75d-00064cde9155', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1038b0>]}
2021-05-19 19:33:01.348390 (Thread-2): 15:33:01 | 2 of 5 ERROR creating table model fetch_takehome.dim_brands.......... [ERROR in 0.09s]
2021-05-19 19:33:01.348610 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:33:01.348821 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:33:01.349288 (Thread-2): 15:33:01 | 5 of 5 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:33:01.349751 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.349919 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:33:01.352442 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:33:01.352917 (Thread-2): finished collecting timing info
2021-05-19 19:33:01.357203 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.357419 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:33:01.357547 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:33:01.367520 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:33:01.369572 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.369701 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:33:01.369954 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:01.371134 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:33:01.371905 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.372036 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:33:01.372291 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:01.372403 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.372489 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:33:01.391818 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 19:33:01.398467 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.398603 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:33:01.398995 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:01.400989 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.401113 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:33:01.401252 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-19 19:33:01.403079 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.403189 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:33:01.403314 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:01.410021 (Thread-1): SQL status: ALTER TABLE in 0.01 seconds
2021-05-19 19:33:01.410373 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:33:01.412414 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.412563 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.412667 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:33:01.412765 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:33:01.413287 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:01.414433 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:33:01.414576 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:01.414694 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.418163 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:01.418318 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:33:01.418423 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:33:01.419538 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:01.421108 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:01.421250 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:01.421388 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:33:01.422586 (Thread-2): finished collecting timing info
2021-05-19 19:33:01.422855 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:33:01.423304 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9329365f-7ab2-4d09-b75d-00064cde9155', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1121f0>]}
2021-05-19 19:33:01.423676 (Thread-2): 15:33:01 | 5 of 5 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.07s]
2021-05-19 19:33:01.423890 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:33:01.425803 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:01.427239 (Thread-1): finished collecting timing info
2021-05-19 19:33:01.427411 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:33:01.427786 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9329365f-7ab2-4d09-b75d-00064cde9155', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d11f040>]}
2021-05-19 19:33:01.428104 (Thread-1): 15:33:01 | 1 of 5 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.17s]
2021-05-19 19:33:01.428246 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:33:01.971269 (Thread-4): SQL status: SELECT 1119 in 0.63 seconds
2021-05-19 19:33:01.973252 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:01.973358 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:33:02.147216 (Thread-3): SQL status: SELECT 6941 in 0.81 seconds
2021-05-19 19:33:02.149636 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:02.149834 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:33:02.150268 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:02.153382 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:02.153602 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:33:02.154361 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:02.155628 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:33:02.155755 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:02.155852 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:33:02.156555 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:02.156771 (Thread-4): SQL status: ALTER TABLE in 0.18 seconds
2021-05-19 19:33:02.158208 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:02.160406 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:02.160540 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:33:02.160649 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:33:02.161246 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:02.162359 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:33:02.162477 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:02.162568 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:33:02.163062 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:02.164487 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:02.164606 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:33:02.164743 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:02.165897 (Thread-3): finished collecting timing info
2021-05-19 19:33:02.166052 (Thread-3): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:33:02.166556 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9329365f-7ab2-4d09-b75d-00064cde9155', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d103b20>]}
2021-05-19 19:33:02.166972 (Thread-3): 15:33:02 | 3 of 5 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.90s]
2021-05-19 19:33:02.167158 (Thread-3): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:33:02.167916 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:02.169143 (Thread-4): finished collecting timing info
2021-05-19 19:33:02.169310 (Thread-4): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:33:02.169718 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9329365f-7ab2-4d09-b75d-00064cde9155', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1513d0>]}
2021-05-19 19:33:02.170050 (Thread-4): 15:33:02 | 4 of 5 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.91s]
2021-05-19 19:33:02.170192 (Thread-4): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:33:02.171474 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:33:02.171659 (MainThread): Using postgres connection "master".
2021-05-19 19:33:02.171765 (MainThread): On master: BEGIN
2021-05-19 19:33:02.171909 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:33:02.180772 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:33:02.180959 (MainThread): On master: COMMIT
2021-05-19 19:33:02.181063 (MainThread): Using postgres connection "master".
2021-05-19 19:33:02.181156 (MainThread): On master: COMMIT
2021-05-19 19:33:02.181347 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:02.181471 (MainThread): On master: Close
2021-05-19 19:33:02.181834 (MainThread): 15:33:02 | 
2021-05-19 19:33:02.181975 (MainThread): 15:33:02 | Finished running 5 table models in 1.01s.
2021-05-19 19:33:02.182091 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:33:02.182177 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:33:02.182259 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:33:02.182339 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:33:02.182416 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:33:02.186816 (MainThread): 
2021-05-19 19:33:02.186966 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 19:33:02.187083 (MainThread): 
2021-05-19 19:33:02.187220 (MainThread): Database Error in model dim_brands (models/transformations/dim_brands.sql)
2021-05-19 19:33:02.187322 (MainThread):   invalid input syntax for type bigint: "601ac114be37ce2ead437550"
2021-05-19 19:33:02.187418 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:33:02.187529 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-05-19 19:33:02.187702 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cebb340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cfcdc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cfb34f0>]}
2021-05-19 19:33:02.187893 (MainThread): Flushing usage events
2021-05-19 19:33:30.876584 (MainThread): Running with dbt=0.19.1
2021-05-19 19:33:30.943642 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:33:30.945146 (MainThread): Tracking: tracking
2021-05-19 19:33:30.957363 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122a8e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122d0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122d0e50>]}
2021-05-19 19:33:30.970738 (MainThread): Partial parsing not enabled
2021-05-19 19:33:30.971827 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:33:30.975556 (MainThread): Parsing macros/relations.sql
2021-05-19 19:33:30.977392 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:33:30.999177 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:33:31.001931 (MainThread): Parsing macros/core.sql
2021-05-19 19:33:31.005842 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:33:31.014767 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:33:31.016546 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:33:31.036067 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:33:31.070899 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:33:31.093438 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:33:31.095351 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:33:31.101824 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:33:31.116114 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:33:31.123324 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:33:31.129837 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:33:31.135004 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:33:31.135986 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:33:31.137053 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:33:31.138697 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:33:31.147726 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:33:31.149728 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:33:31.151413 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:33:31.195201 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:33:31.197198 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:33:31.198754 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:33:31.200487 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:33:31.208017 (MainThread): Partial parsing not enabled
2021-05-19 19:33:31.261975 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.273559 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.277147 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:31.280679 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:31.284161 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:33:31.287396 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:33:31.291533 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:33:31.294893 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.346400 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac49b771-f948-448f-b95c-47f24d93be99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112504520>]}
2021-05-19 19:33:31.350857 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac49b771-f948-448f-b95c-47f24d93be99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11243a6a0>]}
2021-05-19 19:33:31.351107 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:33:31.351804 (MainThread): 
2021-05-19 19:33:31.352100 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:33:31.353092 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:33:31.363357 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:33:31.363492 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:33:31.363594 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:33:31.392867 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 19:33:31.395391 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:33:31.396821 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:33:31.403952 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:33:31.404108 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:33:31.404227 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:33:31.412915 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:33:31.413087 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:33:31.413191 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:33:31.416700 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.00 seconds
2021-05-19 19:33:31.417477 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:33:31.417712 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:33:31.422830 (MainThread): Using postgres connection "master".
2021-05-19 19:33:31.422985 (MainThread): On master: BEGIN
2021-05-19 19:33:31.423101 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:33:31.431488 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:33:31.431656 (MainThread): Using postgres connection "master".
2021-05-19 19:33:31.431759 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:33:31.445557 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-19 19:33:31.446141 (MainThread): On master: ROLLBACK
2021-05-19 19:33:31.446364 (MainThread): Using postgres connection "master".
2021-05-19 19:33:31.446463 (MainThread): On master: BEGIN
2021-05-19 19:33:31.446740 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:31.446857 (MainThread): On master: COMMIT
2021-05-19 19:33:31.446950 (MainThread): Using postgres connection "master".
2021-05-19 19:33:31.447031 (MainThread): On master: COMMIT
2021-05-19 19:33:31.447268 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:31.447407 (MainThread): On master: Close
2021-05-19 19:33:31.447708 (MainThread): 15:33:31 | Concurrency: 4 threads (target='dev')
2021-05-19 19:33:31.447848 (MainThread): 15:33:31 | 
2021-05-19 19:33:31.449938 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:33:31.450217 (Thread-1): 15:33:31 | 1 of 5 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:33:31.450365 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:33:31.450687 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.450838 (Thread-3): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:33:31.451043 (Thread-2): 15:33:31 | 2 of 5 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:33:31.451141 (Thread-4): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:33:31.451301 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:33:31.451493 (Thread-3): 15:33:31 | 3 of 5 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:33:31.451776 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.451994 (Thread-4): 15:33:31 | 4 of 5 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:33:31.453309 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:33:31.453604 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:31.453737 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:33:31.453995 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:31.454254 (Thread-3): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:33:31.455464 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:33:31.455730 (Thread-4): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:33:31.457049 (Thread-3): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:33:31.457153 (Thread-1): finished collecting timing info
2021-05-19 19:33:31.458350 (Thread-4): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:33:31.478677 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.478807 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:33:31.478897 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:33:31.479124 (Thread-2): finished collecting timing info
2021-05-19 19:33:31.481469 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.481598 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:33:31.481745 (Thread-3): finished collecting timing info
2021-05-19 19:33:31.481903 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:33:31.484196 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:31.484362 (Thread-4): finished collecting timing info
2021-05-19 19:33:31.484628 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:33:31.487235 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:31.487458 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:33:31.487571 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:33:31.487839 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:33:31.487970 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:33:31.490788 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.490946 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:33:31.491261 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.503266 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:33:31.503440 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:33:31.503698 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:33:31.506042 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:31.507912 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:31.508006 (Thread-2): SQL status: DROP TABLE in 0.03 seconds
2021-05-19 19:33:31.508119 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.508229 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:33:31.508330 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:33:31.510174 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.510284 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:33:31.510573 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:33:31.510754 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.510879 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.511005 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:31.512180 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:33:31.513232 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:33:31.513305 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.513403 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.514778 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:33:31.514897 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:33:31.515017 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:31.515158 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:31.515384 (Thread-4): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:33:31.515479 (Thread-3): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:33:31.515744 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.515904 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:31.515994 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:31.516102 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:33:31.516192 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:31.516272 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:31.516430 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:33:31.516540 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:33:31.516614 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:31.516820 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.516896 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode::bigint as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:33:31.523766 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-19 19:33:31.529888 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.530014 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 19:33:31.530526 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:31.536831 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:33:31.536965 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.537065 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:33:31.538013 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:31.540958 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:33:31.541066 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:33:31.541361 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.542392 (Thread-2): finished collecting timing info
2021-05-19 19:33:31.542525 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:33:31.542987 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac49b771-f948-448f-b95c-47f24d93be99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112654eb0>]}
2021-05-19 19:33:31.543411 (Thread-2): 15:33:31 | 2 of 5 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.09s]
2021-05-19 19:33:31.543591 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:33:31.543776 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:33:31.544097 (Thread-2): 15:33:31 | 5 of 5 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:33:31.544366 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.544469 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:33:31.546696 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:33:31.547183 (Thread-2): finished collecting timing info
2021-05-19 19:33:31.551224 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.551416 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:33:31.551565 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:33:31.564151 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:33:31.566447 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.566585 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:33:31.566937 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.569250 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:33:31.569834 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.569946 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:33:31.570265 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:33:31.570396 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.570502 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:33:31.571883 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-19 19:33:31.574700 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.574854 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:33:31.575275 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:31.577577 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.577702 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:33:31.578203 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:31.579297 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:33:31.579405 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.579492 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:33:31.580106 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:31.581438 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:33:31.581546 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:33:31.583565 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.584851 (Thread-1): finished collecting timing info
2021-05-19 19:33:31.584995 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:33:31.585341 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac49b771-f948-448f-b95c-47f24d93be99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11231c880>]}
2021-05-19 19:33:31.585621 (Thread-1): 15:33:31 | 1 of 5 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.13s]
2021-05-19 19:33:31.585748 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:33:31.587795 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 19:33:31.589960 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.590092 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:33:31.590552 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:31.593081 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.593300 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:33:31.594090 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:31.595245 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:33:31.595362 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.595445 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:33:31.595955 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:31.597741 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:33:31.597928 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:33:31.600158 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:31.601433 (Thread-2): finished collecting timing info
2021-05-19 19:33:31.601597 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:33:31.602027 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac49b771-f948-448f-b95c-47f24d93be99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124e1070>]}
2021-05-19 19:33:31.602346 (Thread-2): 15:33:31 | 5 of 5 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-19 19:33:31.602491 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:33:32.163212 (Thread-4): SQL status: SELECT 1119 in 0.65 seconds
2021-05-19 19:33:32.165828 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:32.165971 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:33:32.358874 (Thread-3): SQL status: SELECT 6941 in 0.84 seconds
2021-05-19 19:33:32.361107 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:32.361217 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:33:32.361620 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:32.363326 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:32.363426 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:33:32.364258 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:32.365329 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:33:32.365445 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:32.365532 (Thread-3): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:33:32.366133 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:32.367627 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:33:32.367769 (Thread-4): SQL status: ALTER TABLE in 0.20 seconds
2021-05-19 19:33:32.367859 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:33:32.369727 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:32.369932 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:33:32.370378 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:33:32.371430 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:33:32.371542 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:32.371632 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:33:32.372113 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:33:32.373132 (Thread-3): finished collecting timing info
2021-05-19 19:33:32.373266 (Thread-3): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:33:32.373395 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:32.373744 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac49b771-f948-448f-b95c-47f24d93be99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112661340>]}
2021-05-19 19:33:32.374990 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:33:32.375456 (Thread-3): 15:33:32 | 3 of 5 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.92s]
2021-05-19 19:33:32.375599 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:33:32.375791 (Thread-3): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:33:32.381409 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:33:32.382621 (Thread-4): finished collecting timing info
2021-05-19 19:33:32.382775 (Thread-4): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:33:32.383122 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac49b771-f948-448f-b95c-47f24d93be99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11269ed60>]}
2021-05-19 19:33:32.383414 (Thread-4): 15:33:32 | 4 of 5 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.93s]
2021-05-19 19:33:32.383544 (Thread-4): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:33:32.384712 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:33:32.384879 (MainThread): Using postgres connection "master".
2021-05-19 19:33:32.384972 (MainThread): On master: BEGIN
2021-05-19 19:33:32.385067 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:33:32.393079 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:33:32.393253 (MainThread): On master: COMMIT
2021-05-19 19:33:32.393348 (MainThread): Using postgres connection "master".
2021-05-19 19:33:32.393435 (MainThread): On master: COMMIT
2021-05-19 19:33:32.393622 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:33:32.393740 (MainThread): On master: Close
2021-05-19 19:33:32.394135 (MainThread): 15:33:32 | 
2021-05-19 19:33:32.394283 (MainThread): 15:33:32 | Finished running 5 table models in 1.04s.
2021-05-19 19:33:32.394403 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:33:32.394495 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:33:32.394575 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:33:32.394653 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:33:32.394730 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:33:32.399081 (MainThread): 
2021-05-19 19:33:32.399244 (MainThread): Completed successfully
2021-05-19 19:33:32.399373 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-05-19 19:33:32.399552 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124430a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112514f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11266e6a0>]}
2021-05-19 19:33:32.399751 (MainThread): Flushing usage events
2021-05-19 19:55:27.380340 (MainThread): Running with dbt=0.19.1
2021-05-19 19:55:27.479817 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:55:27.481311 (MainThread): Tracking: tracking
2021-05-19 19:55:27.500919 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffdbe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110000670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110000eb0>]}
2021-05-19 19:55:27.516669 (MainThread): Partial parsing not enabled
2021-05-19 19:55:27.518665 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:55:27.523752 (MainThread): Parsing macros/relations.sql
2021-05-19 19:55:27.526133 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:55:27.554830 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:55:27.559396 (MainThread): Parsing macros/core.sql
2021-05-19 19:55:27.564915 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:55:27.577458 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:55:27.580058 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:55:27.605384 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:55:27.649311 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:55:27.674443 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:55:27.676492 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:55:27.682989 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:55:27.697545 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:55:27.704830 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:55:27.711636 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:55:27.716975 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:55:27.718094 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:55:27.719436 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:55:27.721270 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:55:27.730559 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:55:27.732730 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:55:27.734558 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:55:27.778199 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:55:27.780248 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:55:27.781913 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:55:27.783706 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:55:27.791102 (MainThread): Partial parsing not enabled
2021-05-19 19:55:27.843458 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:27.854325 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:27.857631 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:27.860747 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:27.863935 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:55:27.866842 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:55:27.870569 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:55:27.873528 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:55:27.919098 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110287c10>]}
2021-05-19 19:55:27.923736 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110169640>]}
2021-05-19 19:55:27.923977 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:55:27.924617 (MainThread): 
2021-05-19 19:55:27.924879 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:55:27.925786 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:55:27.935713 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:55:27.935862 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:55:27.935969 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:55:27.969359 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 19:55:27.972618 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:55:27.974104 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:55:27.980435 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:55:27.980629 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:55:27.980734 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:55:27.988796 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:55:27.988964 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:55:27.989060 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:55:27.992009 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.00 seconds
2021-05-19 19:55:27.992729 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:55:27.992927 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:55:27.997662 (MainThread): Using postgres connection "master".
2021-05-19 19:55:27.997789 (MainThread): On master: BEGIN
2021-05-19 19:55:27.997888 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:55:28.005438 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:55:28.005588 (MainThread): Using postgres connection "master".
2021-05-19 19:55:28.005679 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:55:28.020385 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-05-19 19:55:28.020914 (MainThread): On master: ROLLBACK
2021-05-19 19:55:28.021101 (MainThread): Using postgres connection "master".
2021-05-19 19:55:28.021186 (MainThread): On master: BEGIN
2021-05-19 19:55:28.021443 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:55:28.021549 (MainThread): On master: COMMIT
2021-05-19 19:55:28.021630 (MainThread): Using postgres connection "master".
2021-05-19 19:55:28.021700 (MainThread): On master: COMMIT
2021-05-19 19:55:28.021858 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:55:28.021955 (MainThread): On master: Close
2021-05-19 19:55:28.022231 (MainThread): 15:55:28 | Concurrency: 4 threads (target='dev')
2021-05-19 19:55:28.022354 (MainThread): 15:55:28 | 
2021-05-19 19:55:28.024492 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:55:28.024617 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:55:28.024847 (Thread-1): 15:55:28 | 1 of 6 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:55:28.024932 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 19:55:28.025114 (Thread-2): 15:55:28 | 2 of 6 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:55:28.025197 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:55:28.025518 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.025680 (Thread-3): 15:55:28 | 3 of 6 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 19:55:28.025924 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:55:28.026099 (Thread-4): 15:55:28 | 4 of 6 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:55:28.026227 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:55:28.026373 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:55:28.026556 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:55:28.026867 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.027953 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:55:28.028839 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:55:28.028944 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 19:55:28.029033 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:55:28.030135 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:55:28.031090 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:55:28.031377 (Thread-1): finished collecting timing info
2021-05-19 19:55:28.031591 (Thread-2): finished collecting timing info
2021-05-19 19:55:28.037200 (Thread-3): finished collecting timing info
2021-05-19 19:55:28.061047 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:55:28.062595 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.064625 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:55:28.064799 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:55:28.064934 (Thread-4): finished collecting timing info
2021-05-19 19:55:28.065020 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:55:28.065111 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 19:55:28.065205 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:55:28.067130 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.067241 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:55:28.067328 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:55:28.067574 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:55:28.067944 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:55:28.075202 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:55:28.077277 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:55:28.077391 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:55:28.077624 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:55:28.077736 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.079470 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.088982 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:55:28.089107 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:55:28.089220 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.089325 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:55:28.091231 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:55:28.092893 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.093004 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 19:55:28.093100 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:55:28.093162 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.093249 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.093414 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:55:28.093537 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.094643 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:55:28.095818 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:55:28.096014 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.096202 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:55:28.097238 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:55:28.097390 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:55:28.097494 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.097705 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:55:28.097778 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode::bigserial as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:55:28.097930 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:55:28.098029 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 19:55:28.098121 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.098401 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:55:28.098505 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:55:28.098651 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:55:28.098737 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:55:28.098801 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:55:28.098889 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.098966 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode::bigserial as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcod as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 19:55:28.099048 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.099123 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:55:28.099265 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:55:28.103477 (Thread-2): Postgres error: type "bigserial" does not exist
LINE 8: barcode::bigserial as barcode,
                 ^

2021-05-19 19:55:28.103617 (Thread-2): On model.fetch_takehome.dim_brands: ROLLBACK
2021-05-19 19:55:28.103699 (Thread-3): Postgres error: type "bigserial" does not exist
LINE 9: barcode::bigserial as barcode,
                 ^

2021-05-19 19:55:28.103853 (Thread-3): On model.fetch_takehome.fact_items: ROLLBACK
2021-05-19 19:55:28.104027 (Thread-2): finished collecting timing info
2021-05-19 19:55:28.104166 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:55:28.104318 (Thread-3): finished collecting timing info
2021-05-19 19:55:28.104451 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 19:55:28.104718 (Thread-2): Database Error in model dim_brands (models/transformations/dim_brands.sql)
  type "bigserial" does not exist
  LINE 8: barcode::bigserial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "bigserial" does not exist
LINE 8: barcode::bigserial as barcode,
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model dim_brands (models/transformations/dim_brands.sql)
  type "bigserial" does not exist
  LINE 8: barcode::bigserial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:55:28.105172 (Thread-3): Database Error in model fact_items (models/transformations/fact_items.sql)
  type "bigserial" does not exist
  LINE 9: barcode::bigserial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "bigserial" does not exist
LINE 9: barcode::bigserial as barcode,
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_items (models/transformations/fact_items.sql)
  type "bigserial" does not exist
  LINE 9: barcode::bigserial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:55:28.113360 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110149130>]}
2021-05-19 19:55:28.113564 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103bf4c0>]}
2021-05-19 19:55:28.113927 (Thread-3): 15:55:28 | 3 of 6 ERROR creating table model fetch_takehome.fact_items.......... [ERROR in 0.09s]
2021-05-19 19:55:28.114049 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 19:55:28.114303 (Thread-2): 15:55:28 | 2 of 6 ERROR creating table model fetch_takehome.dim_brands.......... [ERROR in 0.09s]
2021-05-19 19:55:28.114430 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:55:28.114715 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:55:28.114875 (Thread-3): 15:55:28 | 5 of 6 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:55:28.115006 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:55:28.115491 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.115679 (Thread-2): 15:55:28 | 6 of 6 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:55:28.115806 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:55:28.116188 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.117283 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:55:28.117403 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:55:28.118689 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:55:28.119027 (Thread-3): finished collecting timing info
2021-05-19 19:55:28.122151 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.122267 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:55:28.122358 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 19:55:28.122671 (Thread-2): finished collecting timing info
2021-05-19 19:55:28.124893 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.125019 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:55:28.125105 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:55:28.130132 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:55:28.132010 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.132121 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.132375 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.133395 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:55:28.133796 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.133880 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:55:28.133991 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:55:28.135670 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.135766 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.135882 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:55:28.135989 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.136063 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.137038 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:55:28.137137 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:55:28.137572 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.137656 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:55:28.137897 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:55:28.137996 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.138072 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:55:28.143998 (Thread-1): SQL status: SELECT 1167 in 0.04 seconds
2021-05-19 19:55:28.150590 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.150771 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:55:28.151262 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:55:28.154316 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.154533 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:55:28.155196 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 19:55:28.158498 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.158774 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:55:28.158884 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:55:28.168465 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:55:28.168777 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.168912 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:55:28.169090 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:55:28.172423 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.172635 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:55:28.172793 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:55:28.176874 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:55:28.177183 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.177655 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:55:28.179171 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:55:28.179306 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.179398 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:55:28.179849 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:55:28.181212 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:55:28.181323 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.181475 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.182632 (Thread-1): finished collecting timing info
2021-05-19 19:55:28.182778 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:55:28.183117 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11015cc40>]}
2021-05-19 19:55:28.183414 (Thread-1): 15:55:28 | 1 of 6 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.16s]
2021-05-19 19:55:28.183565 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:55:28.183727 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.184940 (Thread-2): finished collecting timing info
2021-05-19 19:55:28.185095 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:55:28.185459 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104164c0>]}
2021-05-19 19:55:28.185749 (Thread-2): 15:55:28 | 6 of 6 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.07s]
2021-05-19 19:55:28.185879 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:55:28.753110 (Thread-3): SQL status: SELECT 1119 in 0.62 seconds
2021-05-19 19:55:28.755478 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.755613 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:55:28.869901 (Thread-4): SQL status: SELECT 6941 in 0.77 seconds
2021-05-19 19:55:28.871914 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.872044 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:55:28.872444 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:55:28.874359 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.874483 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:55:28.875045 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:55:28.876056 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:55:28.876161 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.876236 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:55:28.877001 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:55:28.878300 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:55:28.878408 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.878526 (Thread-3): SQL status: ALTER TABLE in 0.12 seconds
2021-05-19 19:55:28.880155 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.880246 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:55:28.880382 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.881291 (Thread-4): finished collecting timing info
2021-05-19 19:55:28.881407 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:55:28.881517 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:55:28.882448 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:55:28.882785 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110395fa0>]}
2021-05-19 19:55:28.882881 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.883186 (Thread-4): 15:55:28 | 4 of 6 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.86s]
2021-05-19 19:55:28.883283 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:55:28.883471 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:55:28.884090 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:55:28.885505 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:55:28.885624 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:55:28.888444 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:55:28.889610 (Thread-3): finished collecting timing info
2021-05-19 19:55:28.889773 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:55:28.890106 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a1e4f5-4ad9-490b-8eb8-9bd84a21a2f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103bf490>]}
2021-05-19 19:55:28.890400 (Thread-3): 15:55:28 | 5 of 6 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.77s]
2021-05-19 19:55:28.890530 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:55:28.891652 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:55:28.891817 (MainThread): Using postgres connection "master".
2021-05-19 19:55:28.891910 (MainThread): On master: BEGIN
2021-05-19 19:55:28.892007 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:55:28.900939 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:55:28.901135 (MainThread): On master: COMMIT
2021-05-19 19:55:28.901236 (MainThread): Using postgres connection "master".
2021-05-19 19:55:28.901329 (MainThread): On master: COMMIT
2021-05-19 19:55:28.901544 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:55:28.901694 (MainThread): On master: Close
2021-05-19 19:55:28.902083 (MainThread): 15:55:28 | 
2021-05-19 19:55:28.902239 (MainThread): 15:55:28 | Finished running 6 table models in 0.98s.
2021-05-19 19:55:28.902366 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:55:28.902492 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:55:28.902652 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:55:28.902751 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:55:28.902836 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:55:28.908576 (MainThread): 
2021-05-19 19:55:28.908756 (MainThread): Completed with 2 errors and 0 warnings:
2021-05-19 19:55:28.908894 (MainThread): 
2021-05-19 19:55:28.909078 (MainThread): Database Error in model fact_items (models/transformations/fact_items.sql)
2021-05-19 19:55:28.909224 (MainThread):   type "bigserial" does not exist
2021-05-19 19:55:28.909353 (MainThread):   LINE 9: barcode::bigserial as barcode,
2021-05-19 19:55:28.909546 (MainThread):                    ^
2021-05-19 19:55:28.909677 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:55:28.909792 (MainThread): 
2021-05-19 19:55:28.909907 (MainThread): Database Error in model dim_brands (models/transformations/dim_brands.sql)
2021-05-19 19:55:28.910012 (MainThread):   type "bigserial" does not exist
2021-05-19 19:55:28.910106 (MainThread):   LINE 8: barcode::bigserial as barcode,
2021-05-19 19:55:28.910198 (MainThread):                    ^
2021-05-19 19:55:28.910287 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:55:28.910397 (MainThread): 
Done. PASS=4 WARN=0 ERROR=2 SKIP=0 TOTAL=6
2021-05-19 19:55:28.910582 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11017d1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110169580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110169a00>]}
2021-05-19 19:55:28.910785 (MainThread): Flushing usage events
2021-05-19 19:56:21.830640 (MainThread): Running with dbt=0.19.1
2021-05-19 19:56:21.904866 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:56:21.905538 (MainThread): Tracking: tracking
2021-05-19 19:56:21.918206 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110649dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106665e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110666e20>]}
2021-05-19 19:56:21.932212 (MainThread): Partial parsing not enabled
2021-05-19 19:56:21.933309 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:56:21.937152 (MainThread): Parsing macros/relations.sql
2021-05-19 19:56:21.939003 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:56:21.963892 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:56:21.966962 (MainThread): Parsing macros/core.sql
2021-05-19 19:56:21.971440 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:56:21.980772 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:56:21.982723 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:56:22.001883 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:56:22.036318 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:56:22.058029 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:56:22.059943 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:56:22.066405 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:56:22.080995 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:56:22.088083 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:56:22.094551 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:56:22.099738 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:56:22.100693 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:56:22.101749 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:56:22.103475 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:56:22.112567 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:56:22.114571 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:56:22.116282 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:56:22.160535 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:56:22.162458 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:56:22.163992 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:56:22.165843 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:56:22.173458 (MainThread): Partial parsing not enabled
2021-05-19 19:56:22.228723 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.240190 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.243611 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:22.246980 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:22.250476 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:56:22.253563 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:56:22.257710 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:56:22.260878 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:56:22.311574 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108b0ca0>]}
2021-05-19 19:56:22.316128 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107cc4c0>]}
2021-05-19 19:56:22.316402 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:56:22.317138 (MainThread): 
2021-05-19 19:56:22.317444 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:56:22.318522 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:56:22.329972 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:56:22.330132 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:56:22.330250 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:56:22.357840 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 19:56:22.360637 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:56:22.362296 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:56:22.369166 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:56:22.369325 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:56:22.369449 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:56:22.378828 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:56:22.378998 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:56:22.379099 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:56:22.382339 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.00 seconds
2021-05-19 19:56:22.383116 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:56:22.383339 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:56:22.388584 (MainThread): Using postgres connection "master".
2021-05-19 19:56:22.388732 (MainThread): On master: BEGIN
2021-05-19 19:56:22.388846 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:56:22.397247 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:56:22.397408 (MainThread): Using postgres connection "master".
2021-05-19 19:56:22.397507 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:56:22.413812 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 19:56:22.414411 (MainThread): On master: ROLLBACK
2021-05-19 19:56:22.414640 (MainThread): Using postgres connection "master".
2021-05-19 19:56:22.414739 (MainThread): On master: BEGIN
2021-05-19 19:56:22.415038 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:56:22.415163 (MainThread): On master: COMMIT
2021-05-19 19:56:22.415262 (MainThread): Using postgres connection "master".
2021-05-19 19:56:22.415349 (MainThread): On master: COMMIT
2021-05-19 19:56:22.415533 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:56:22.415648 (MainThread): On master: Close
2021-05-19 19:56:22.415935 (MainThread): 15:56:22 | Concurrency: 4 threads (target='dev')
2021-05-19 19:56:22.416068 (MainThread): 15:56:22 | 
2021-05-19 19:56:22.418184 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:56:22.418454 (Thread-1): 15:56:22 | 1 of 6 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:56:22.418627 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:56:22.418950 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.419059 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 19:56:22.419256 (Thread-2): 15:56:22 | 2 of 6 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:56:22.419352 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:56:22.419508 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:56:22.419692 (Thread-3): 15:56:22 | 3 of 6 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 19:56:22.420122 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:56:22.420386 (Thread-4): 15:56:22 | 4 of 6 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:56:22.421776 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:56:22.422110 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:56:22.422243 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:56:22.422511 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:22.422761 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 19:56:22.424078 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:56:22.424211 (Thread-1): finished collecting timing info
2021-05-19 19:56:22.424329 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:56:22.425492 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:56:22.444606 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:56:22.446539 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.446700 (Thread-2): finished collecting timing info
2021-05-19 19:56:22.447166 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:56:22.449581 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:56:22.449797 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:56:22.449940 (Thread-4): finished collecting timing info
2021-05-19 19:56:22.450029 (Thread-3): finished collecting timing info
2021-05-19 19:56:22.450104 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:56:22.452748 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:22.455443 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:56:22.455680 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:56:22.455826 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:56:22.455951 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 19:56:22.456239 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:56:22.456356 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:56:22.459577 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:56:22.461804 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.461933 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:56:22.462243 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.474780 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:56:22.474980 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:56:22.477220 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:56:22.477342 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 19:56:22.477570 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:56:22.479488 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:56:22.479600 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:56:22.479759 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:56:22.479893 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.479985 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.482306 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:22.483617 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:56:22.483799 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.484899 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:56:22.485018 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:56:22.485252 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:56:22.485894 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:56:22.486022 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 19:56:22.486177 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:56:22.486326 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:56:22.486415 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.486492 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:56:22.486618 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.486732 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:56:22.488000 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:56:22.488176 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:56:22.488283 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:56:22.488587 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode::serial as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcod as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 19:56:22.488711 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:56:22.489018 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:56:22.489115 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode::serial as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:56:22.489307 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:22.489439 (Thread-3): Postgres error: type "serial" does not exist
LINE 9: barcode::serial as barcode,
                 ^

2021-05-19 19:56:22.489532 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:56:22.489660 (Thread-3): On model.fetch_takehome.fact_items: ROLLBACK
2021-05-19 19:56:22.489754 (Thread-2): Postgres error: type "serial" does not exist
LINE 8: barcode::serial as barcode,
                 ^

2021-05-19 19:56:22.490002 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:56:22.490106 (Thread-2): On model.fetch_takehome.dim_brands: ROLLBACK
2021-05-19 19:56:22.490231 (Thread-3): finished collecting timing info
2021-05-19 19:56:22.490358 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:22.490578 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 19:56:22.490740 (Thread-2): finished collecting timing info
2021-05-19 19:56:22.490841 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:56:22.491484 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:56:22.491180 (Thread-3): Database Error in model fact_items (models/transformations/fact_items.sql)
  type "serial" does not exist
  LINE 9: barcode::serial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "serial" does not exist
LINE 9: barcode::serial as barcode,
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_items (models/transformations/fact_items.sql)
  type "serial" does not exist
  LINE 9: barcode::serial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:56:22.492515 (Thread-2): Database Error in model dim_brands (models/transformations/dim_brands.sql)
  type "serial" does not exist
  LINE 8: barcode::serial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "serial" does not exist
LINE 8: barcode::serial as barcode,
                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model dim_brands (models/transformations/dim_brands.sql)
  type "serial" does not exist
  LINE 8: barcode::serial as barcode,
                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:56:22.496390 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a045b0>]}
2021-05-19 19:56:22.496675 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a046d0>]}
2021-05-19 19:56:22.497119 (Thread-3): 15:56:22 | 3 of 6 ERROR creating table model fetch_takehome.fact_items.......... [ERROR in 0.07s]
2021-05-19 19:56:22.497451 (Thread-2): 15:56:22 | 2 of 6 ERROR creating table model fetch_takehome.dim_brands.......... [ERROR in 0.08s]
2021-05-19 19:56:22.497712 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 19:56:22.497942 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:56:22.498100 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:56:22.498399 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:56:22.498746 (Thread-3): 15:56:22 | 5 of 6 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:56:22.498977 (Thread-2): 15:56:22 | 6 of 6 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:56:22.499400 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:22.499542 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:56:22.499805 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.501311 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:56:22.501482 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:56:22.502854 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:56:22.503344 (Thread-3): finished collecting timing info
2021-05-19 19:56:22.503582 (Thread-2): finished collecting timing info
2021-05-19 19:56:22.506986 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:22.511062 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.511252 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:56:22.511410 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:56:22.511559 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 19:56:22.511681 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:56:22.521588 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:56:22.523912 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.524071 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:56:22.524300 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:56:22.526846 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:22.526990 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:56:22.527187 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.527315 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.528528 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:56:22.529675 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:56:22.530317 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:22.530429 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:56:22.530605 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.530722 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:56:22.530867 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:56:22.530977 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:56:22.531069 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:22.531172 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.531267 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:56:22.531368 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:56:22.547736 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-19 19:56:22.559013 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.559277 (Thread-2): SQL status: SELECT 495 in 0.03 seconds
2021-05-19 19:56:22.559439 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:56:22.562289 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.562591 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:56:22.562960 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:56:22.563129 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:56:22.566907 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.569914 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.570205 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:56:22.570447 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:56:22.571253 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:56:22.571479 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:56:22.580326 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:56:22.581912 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:56:22.582206 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.582460 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.582657 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:56:22.582805 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:56:22.583752 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:56:22.587407 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:56:22.587615 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:56:22.587739 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:56:22.589519 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:56:22.589769 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:56:22.591823 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.593621 (Thread-2): finished collecting timing info
2021-05-19 19:56:22.593854 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:22.594041 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:56:22.595186 (Thread-1): finished collecting timing info
2021-05-19 19:56:22.595599 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110873340>]}
2021-05-19 19:56:22.595757 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:56:22.596159 (Thread-2): 15:56:22 | 6 of 6 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.10s]
2021-05-19 19:56:22.596623 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f68e0>]}
2021-05-19 19:56:22.596879 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:56:22.597327 (Thread-1): 15:56:22 | 1 of 6 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.18s]
2021-05-19 19:56:22.597740 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:56:23.248653 (Thread-3): SQL status: SELECT 1119 in 0.72 seconds
2021-05-19 19:56:23.250549 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:23.250651 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:56:23.368524 (Thread-4): SQL status: SELECT 6941 in 0.88 seconds
2021-05-19 19:56:23.370620 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:23.370733 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:56:23.371101 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:56:23.372657 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:23.372748 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:56:23.373163 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:56:23.374144 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:56:23.374237 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:23.374311 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:56:23.375356 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:56:23.376498 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:56:23.376597 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:56:23.376712 (Thread-3): SQL status: ALTER TABLE in 0.13 seconds
2021-05-19 19:56:23.378392 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:23.378485 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:56:23.378671 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:23.379582 (Thread-4): finished collecting timing info
2021-05-19 19:56:23.379709 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:56:23.379824 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:56:23.380118 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a047c0>]}
2021-05-19 19:56:23.381086 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:56:23.381390 (Thread-4): 15:56:23 | 4 of 6 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.96s]
2021-05-19 19:56:23.381490 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:23.381678 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:56:23.381762 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:56:23.382369 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:56:23.383637 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:56:23.383732 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:56:23.386002 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:56:23.386993 (Thread-3): finished collecting timing info
2021-05-19 19:56:23.387132 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:56:23.387435 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09674a82-6358-46e6-9da8-b216d87ae815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a124c0>]}
2021-05-19 19:56:23.387700 (Thread-3): 15:56:23 | 5 of 6 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.89s]
2021-05-19 19:56:23.387816 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:56:23.388847 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:56:23.388991 (MainThread): Using postgres connection "master".
2021-05-19 19:56:23.389070 (MainThread): On master: BEGIN
2021-05-19 19:56:23.389151 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:56:23.396486 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:56:23.396654 (MainThread): On master: COMMIT
2021-05-19 19:56:23.396749 (MainThread): Using postgres connection "master".
2021-05-19 19:56:23.396833 (MainThread): On master: COMMIT
2021-05-19 19:56:23.397017 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:56:23.397135 (MainThread): On master: Close
2021-05-19 19:56:23.397468 (MainThread): 15:56:23 | 
2021-05-19 19:56:23.397594 (MainThread): 15:56:23 | Finished running 6 table models in 1.08s.
2021-05-19 19:56:23.397696 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:56:23.397774 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:56:23.397848 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:56:23.397920 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:56:23.397990 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:56:23.403605 (MainThread): 
2021-05-19 19:56:23.403769 (MainThread): Completed with 2 errors and 0 warnings:
2021-05-19 19:56:23.403888 (MainThread): 
2021-05-19 19:56:23.403998 (MainThread): Database Error in model fact_items (models/transformations/fact_items.sql)
2021-05-19 19:56:23.404099 (MainThread):   type "serial" does not exist
2021-05-19 19:56:23.404324 (MainThread):   LINE 9: barcode::serial as barcode,
2021-05-19 19:56:23.404482 (MainThread):                    ^
2021-05-19 19:56:23.404622 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:56:23.404749 (MainThread): 
2021-05-19 19:56:23.404904 (MainThread): Database Error in model dim_brands (models/transformations/dim_brands.sql)
2021-05-19 19:56:23.405009 (MainThread):   type "serial" does not exist
2021-05-19 19:56:23.405106 (MainThread):   LINE 8: barcode::serial as barcode,
2021-05-19 19:56:23.405195 (MainThread):                    ^
2021-05-19 19:56:23.405304 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/dim_brands.sql
2021-05-19 19:56:23.405414 (MainThread): 
Done. PASS=4 WARN=0 ERROR=2 SKIP=0 TOTAL=6
2021-05-19 19:56:23.405591 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108ba9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f0190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f0ac0>]}
2021-05-19 19:56:23.405783 (MainThread): Flushing usage events
2021-05-19 19:57:44.229881 (MainThread): Running with dbt=0.19.1
2021-05-19 19:57:44.295303 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:57:44.296214 (MainThread): Tracking: tracking
2021-05-19 19:57:44.308617 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9096a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9335b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d933df0>]}
2021-05-19 19:57:44.322090 (MainThread): Partial parsing not enabled
2021-05-19 19:57:44.323150 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:57:44.326838 (MainThread): Parsing macros/relations.sql
2021-05-19 19:57:44.328638 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:57:44.350564 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:57:44.353341 (MainThread): Parsing macros/core.sql
2021-05-19 19:57:44.357245 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:57:44.366214 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:57:44.368053 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:57:44.386885 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:57:44.421162 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:57:44.442776 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:57:44.444645 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:57:44.450840 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:57:44.464904 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:57:44.472020 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:57:44.478330 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:57:44.483250 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:57:44.484193 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:57:44.485237 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:57:44.486855 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:57:44.495703 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:57:44.497640 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:57:44.499295 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:57:44.542461 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:57:44.544349 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:57:44.545839 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:57:44.547507 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:57:44.554716 (MainThread): Partial parsing not enabled
2021-05-19 19:57:44.608770 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.620285 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:44.623774 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:44.627314 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:44.630883 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:57:44.634080 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:57:44.638201 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:57:44.641370 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.686766 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db82c70>]}
2021-05-19 19:57:44.690327 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da9e940>]}
2021-05-19 19:57:44.690516 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:57:44.691110 (MainThread): 
2021-05-19 19:57:44.691457 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:57:44.692485 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:57:44.701032 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:57:44.701234 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:57:44.701321 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:57:44.727733 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 19:57:44.730415 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:57:44.731965 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:57:44.738805 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:57:44.738965 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:57:44.739077 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:57:44.747414 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:57:44.747574 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:57:44.747674 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:57:44.750765 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.00 seconds
2021-05-19 19:57:44.751477 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:57:44.751672 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:57:44.756560 (MainThread): Using postgres connection "master".
2021-05-19 19:57:44.756686 (MainThread): On master: BEGIN
2021-05-19 19:57:44.756787 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:57:44.764612 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:57:44.764763 (MainThread): Using postgres connection "master".
2021-05-19 19:57:44.764857 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:57:44.780676 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 19:57:44.781279 (MainThread): On master: ROLLBACK
2021-05-19 19:57:44.781503 (MainThread): Using postgres connection "master".
2021-05-19 19:57:44.781603 (MainThread): On master: BEGIN
2021-05-19 19:57:44.781870 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:57:44.781980 (MainThread): On master: COMMIT
2021-05-19 19:57:44.782072 (MainThread): Using postgres connection "master".
2021-05-19 19:57:44.782154 (MainThread): On master: COMMIT
2021-05-19 19:57:44.782320 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:57:44.782436 (MainThread): On master: Close
2021-05-19 19:57:44.782721 (MainThread): 15:57:44 | Concurrency: 4 threads (target='dev')
2021-05-19 19:57:44.782860 (MainThread): 15:57:44 | 
2021-05-19 19:57:44.784918 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:57:44.785101 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:57:44.785330 (Thread-1): 15:57:44 | 1 of 6 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:57:44.785425 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 19:57:44.785645 (Thread-2): 15:57:44 | 2 of 6 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:57:44.785735 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:57:44.786040 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.786290 (Thread-3): 15:57:44 | 3 of 6 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 19:57:44.786585 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.786795 (Thread-4): 15:57:44 | 4 of 6 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:57:44.786949 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:57:44.787234 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:57:44.787359 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:57:44.787609 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:44.788877 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:57:44.789000 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 19:57:44.790008 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:57:44.790128 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:57:44.791363 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:57:44.792563 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:57:44.792672 (Thread-1): finished collecting timing info
2021-05-19 19:57:44.793191 (Thread-2): finished collecting timing info
2021-05-19 19:57:44.799041 (Thread-4): finished collecting timing info
2021-05-19 19:57:44.817335 (Thread-3): finished collecting timing info
2021-05-19 19:57:44.821986 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.825110 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.827129 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:44.829073 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:57:44.829186 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:57:44.829274 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:57:44.829355 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:57:44.829433 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 19:57:44.829523 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:57:44.829598 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:57:44.829672 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:57:44.829745 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:57:44.838174 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:57:44.840399 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:57:44.840509 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 19:57:44.840672 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:57:44.842274 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.842372 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:57:44.842486 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:57:44.842605 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:57:44.842682 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:57:44.842743 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:57:44.844197 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:44.845742 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.856099 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:57:44.856495 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:57:44.856601 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:57:44.856688 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:57:44.857336 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.857452 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:57:44.857537 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:57:44.857604 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:57:44.857693 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:57:44.858727 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:57:44.859711 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:57:44.859880 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 19:57:44.860001 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:57:44.860438 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:44.860544 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.860638 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.860698 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:57:44.860783 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:57:44.860861 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:57:44.860939 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode::bigint as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:57:44.861016 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:57:44.861307 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:57:44.861398 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode::bigint as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcod as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 19:57:44.861480 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:57:44.861573 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:44.861723 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.861827 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:57:44.861922 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:57:44.883980 (Thread-3): Postgres error: column "userflaggedbarcod" does not exist
LINE 26: userFlaggedBarcod as userFlaggedBarcode,
         ^
HINT:  Perhaps you meant to reference the column "items_json_extract.userflaggedbarcode".

2021-05-19 19:57:44.884142 (Thread-3): On model.fetch_takehome.fact_items: ROLLBACK
2021-05-19 19:57:44.884370 (Thread-3): finished collecting timing info
2021-05-19 19:57:44.884491 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 19:57:44.884793 (Thread-3): Database Error in model fact_items (models/transformations/fact_items.sql)
  column "userflaggedbarcod" does not exist
  LINE 26: userFlaggedBarcod as userFlaggedBarcode,
           ^
  HINT:  Perhaps you meant to reference the column "items_json_extract.userflaggedbarcode".
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "userflaggedbarcod" does not exist
LINE 26: userFlaggedBarcod as userFlaggedBarcode,
         ^
HINT:  Perhaps you meant to reference the column "items_json_extract.userflaggedbarcode".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_items (models/transformations/fact_items.sql)
  column "userflaggedbarcod" does not exist
  LINE 26: userFlaggedBarcod as userFlaggedBarcode,
           ^
  HINT:  Perhaps you meant to reference the column "items_json_extract.userflaggedbarcode".
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:57:44.886634 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcd8970>]}
2021-05-19 19:57:44.886927 (Thread-3): 15:57:44 | 3 of 6 ERROR creating table model fetch_takehome.fact_items.......... [ERROR in 0.10s]
2021-05-19 19:57:44.887047 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 19:57:44.887171 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:57:44.887460 (Thread-3): 15:57:44 | 5 of 6 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:57:44.887726 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:44.887827 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:57:44.888828 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:57:44.889156 (Thread-3): finished collecting timing info
2021-05-19 19:57:44.892446 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:44.892561 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:57:44.892646 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 19:57:44.896829 (Thread-2): SQL status: SELECT 1167 in 0.04 seconds
2021-05-19 19:57:44.903096 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.903268 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 19:57:44.903767 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:44.906045 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.906215 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:57:44.906316 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 19:57:44.908289 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:44.908496 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:57:44.908821 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:57:44.908943 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:44.910197 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:57:44.916944 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:57:44.917059 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.917138 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:57:44.917416 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:44.917507 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:57:44.917727 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:57:44.917822 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:44.917896 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:57:44.933761 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-19 19:57:44.936325 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.936472 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:57:44.958850 (Thread-2): SQL status: COMMIT in 0.04 seconds
2021-05-19 19:57:44.959005 (Thread-1): SQL status: ALTER TABLE in 0.02 seconds
2021-05-19 19:57:44.961686 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:57:44.963388 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.963495 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:57:44.963581 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:57:44.964035 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:44.964973 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:57:44.965069 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.965141 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:57:44.988024 (Thread-1): SQL status: COMMIT in 0.02 seconds
2021-05-19 19:57:44.989409 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:57:44.989517 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:57:44.989638 (Thread-2): SQL status: DROP TABLE in 0.03 seconds
2021-05-19 19:57:44.990589 (Thread-2): finished collecting timing info
2021-05-19 19:57:44.990716 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:57:44.991036 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da97f70>]}
2021-05-19 19:57:44.991296 (Thread-2): 15:57:44 | 2 of 6 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.20s]
2021-05-19 19:57:44.991414 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:57:44.991528 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:57:44.991670 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:57:44.993014 (Thread-1): finished collecting timing info
2021-05-19 19:57:44.993220 (Thread-2): 15:57:44 | 6 of 6 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:57:44.993334 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:57:44.993576 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:44.993861 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd64b20>]}
2021-05-19 19:57:44.993964 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:57:44.994246 (Thread-1): 15:57:44 | 1 of 6 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.21s]
2021-05-19 19:57:44.995321 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:57:44.995472 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:57:44.995928 (Thread-2): finished collecting timing info
2021-05-19 19:57:44.999430 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:44.999587 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:57:44.999682 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:57:45.007622 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:57:45.009644 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:45.009767 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:57:45.010072 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:57:45.011219 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:57:45.011630 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:45.011722 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:57:45.011970 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:57:45.012068 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:45.012148 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:57:45.035892 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 19:57:45.038496 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:45.038648 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:57:45.039120 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:45.041194 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:45.041336 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:57:45.041937 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:45.043044 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:57:45.043163 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:45.043253 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:57:45.049839 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-05-19 19:57:45.051659 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:57:45.051825 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:57:45.086452 (Thread-2): SQL status: DROP TABLE in 0.03 seconds
2021-05-19 19:57:45.087704 (Thread-2): finished collecting timing info
2021-05-19 19:57:45.087898 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:57:45.088310 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd50190>]}
2021-05-19 19:57:45.088634 (Thread-2): 15:57:45 | 6 of 6 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.09s]
2021-05-19 19:57:45.088786 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:57:45.580196 (Thread-3): SQL status: SELECT 1119 in 0.66 seconds
2021-05-19 19:57:45.582098 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:45.582197 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:57:45.675201 (Thread-4): SQL status: SELECT 6941 in 0.81 seconds
2021-05-19 19:57:45.677245 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:45.677349 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:57:45.677722 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:45.679334 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:45.679424 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:57:45.679797 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:45.680688 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:57:45.680779 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:45.680852 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:57:45.697241 (Thread-4): SQL status: COMMIT in 0.02 seconds
2021-05-19 19:57:45.697390 (Thread-3): SQL status: ALTER TABLE in 0.12 seconds
2021-05-19 19:57:45.719889 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:57:45.722670 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:57:45.722556 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:45.722849 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:57:45.723266 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:57:45.724138 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:57:45.724227 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:45.724298 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:57:45.757219 (Thread-4): SQL status: DROP TABLE in 0.03 seconds
2021-05-19 19:57:45.758266 (Thread-4): finished collecting timing info
2021-05-19 19:57:45.758399 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:57:45.758702 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddf84f0>]}
2021-05-19 19:57:45.758952 (Thread-4): 15:57:45 | 4 of 6 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.97s]
2021-05-19 19:57:45.759070 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:57:45.766610 (Thread-3): SQL status: COMMIT in 0.04 seconds
2021-05-19 19:57:45.768004 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:57:45.768108 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:57:45.800789 (Thread-3): SQL status: DROP TABLE in 0.03 seconds
2021-05-19 19:57:45.802096 (Thread-3): finished collecting timing info
2021-05-19 19:57:45.802306 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:57:45.802773 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '863f04c3-d25e-4d00-8984-3d44c4389bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d99cd30>]}
2021-05-19 19:57:45.803105 (Thread-3): 15:57:45 | 5 of 6 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.92s]
2021-05-19 19:57:45.803245 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:57:45.804424 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:57:45.804577 (MainThread): Using postgres connection "master".
2021-05-19 19:57:45.804672 (MainThread): On master: BEGIN
2021-05-19 19:57:45.804770 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:57:45.813471 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:57:45.813648 (MainThread): On master: COMMIT
2021-05-19 19:57:45.813749 (MainThread): Using postgres connection "master".
2021-05-19 19:57:45.813841 (MainThread): On master: COMMIT
2021-05-19 19:57:45.814033 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:57:45.814156 (MainThread): On master: Close
2021-05-19 19:57:45.814519 (MainThread): 15:57:45 | 
2021-05-19 19:57:45.814655 (MainThread): 15:57:45 | Finished running 6 table models in 1.12s.
2021-05-19 19:57:45.814769 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:57:45.814855 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:57:45.814936 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:57:45.815020 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:57:45.815101 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:57:45.819477 (MainThread): 
2021-05-19 19:57:45.819639 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 19:57:45.819760 (MainThread): 
2021-05-19 19:57:45.819877 (MainThread): Database Error in model fact_items (models/transformations/fact_items.sql)
2021-05-19 19:57:45.819981 (MainThread):   column "userflaggedbarcod" does not exist
2021-05-19 19:57:45.820077 (MainThread):   LINE 26: userFlaggedBarcod as userFlaggedBarcode,
2021-05-19 19:57:45.820251 (MainThread):            ^
2021-05-19 19:57:45.820373 (MainThread):   HINT:  Perhaps you meant to reference the column "items_json_extract.userflaggedbarcode".
2021-05-19 19:57:45.820492 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:57:45.820637 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2021-05-19 19:57:45.820855 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d99cd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dce65e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddceb20>]}
2021-05-19 19:57:45.821082 (MainThread): Flushing usage events
2021-05-19 19:58:01.372190 (MainThread): Running with dbt=0.19.1
2021-05-19 19:58:01.459982 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:58:01.461028 (MainThread): Tracking: tracking
2021-05-19 19:58:01.475604 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dff1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e00d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e00de20>]}
2021-05-19 19:58:01.490268 (MainThread): Partial parsing not enabled
2021-05-19 19:58:01.491630 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:58:01.496562 (MainThread): Parsing macros/relations.sql
2021-05-19 19:58:01.498505 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:58:01.525408 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:58:01.528964 (MainThread): Parsing macros/core.sql
2021-05-19 19:58:01.533952 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:58:01.545720 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:58:01.548107 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:58:01.573912 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:58:01.619443 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:58:01.647079 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:58:01.649578 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:58:01.657562 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:58:01.674011 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:58:01.681183 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:58:01.688015 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:58:01.693228 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:58:01.694278 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:58:01.695387 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:58:01.697055 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:58:01.706701 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:58:01.708805 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:58:01.710587 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:58:01.755947 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:58:01.758218 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:58:01.759937 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:58:01.761932 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:58:01.769648 (MainThread): Partial parsing not enabled
2021-05-19 19:58:01.824316 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:01.835753 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:01.839235 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:01.842834 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:01.846384 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:01.849539 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:58:01.853964 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:58:01.857434 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:01.911663 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e256ca0>]}
2021-05-19 19:58:01.916694 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e16e490>]}
2021-05-19 19:58:01.916990 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:58:01.917790 (MainThread): 
2021-05-19 19:58:01.918256 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:58:01.919675 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:58:01.930601 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:58:01.930751 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:58:01.930859 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:58:01.958834 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 19:58:01.963192 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:58:01.965350 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:58:01.973924 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:58:01.974092 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:58:01.974210 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:58:01.984168 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:58:01.984365 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:58:01.984485 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:58:01.989446 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.00 seconds
2021-05-19 19:58:01.990420 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:58:01.990746 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:58:01.996474 (MainThread): Using postgres connection "master".
2021-05-19 19:58:01.996647 (MainThread): On master: BEGIN
2021-05-19 19:58:01.996768 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:58:02.007383 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:58:02.007603 (MainThread): Using postgres connection "master".
2021-05-19 19:58:02.007744 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:58:02.025688 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 19:58:02.026330 (MainThread): On master: ROLLBACK
2021-05-19 19:58:02.026608 (MainThread): Using postgres connection "master".
2021-05-19 19:58:02.026729 (MainThread): On master: BEGIN
2021-05-19 19:58:02.027054 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:02.027189 (MainThread): On master: COMMIT
2021-05-19 19:58:02.027295 (MainThread): Using postgres connection "master".
2021-05-19 19:58:02.027384 (MainThread): On master: COMMIT
2021-05-19 19:58:02.027575 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:02.027698 (MainThread): On master: Close
2021-05-19 19:58:02.028018 (MainThread): 15:58:02 | Concurrency: 4 threads (target='dev')
2021-05-19 19:58:02.028161 (MainThread): 15:58:02 | 
2021-05-19 19:58:02.030958 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:58:02.031184 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:58:02.031450 (Thread-1): 15:58:02 | 1 of 6 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:58:02.031556 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 19:58:02.031727 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:58:02.032090 (Thread-2): 15:58:02 | 2 of 6 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:58:02.032476 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.032704 (Thread-3): 15:58:02 | 3 of 6 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 19:58:02.032906 (Thread-4): 15:58:02 | 4 of 6 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:58:02.033209 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.033405 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:58:02.033857 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:02.034208 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:02.034359 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:58:02.036038 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:58:02.036216 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 19:58:02.036404 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:58:02.037892 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:58:02.039338 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:58:02.040547 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:58:02.040888 (Thread-1): finished collecting timing info
2021-05-19 19:58:02.059559 (Thread-3): finished collecting timing info
2021-05-19 19:58:02.070786 (Thread-4): finished collecting timing info
2021-05-19 19:58:02.071022 (Thread-2): finished collecting timing info
2021-05-19 19:58:02.086343 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:02.086704 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.089958 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:02.092764 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.092949 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 19:58:02.093104 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:58:02.093234 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:58:02.093346 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:58:02.093469 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:58:02.093574 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:58:02.093673 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:58:02.093772 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:58:02.104231 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:02.104438 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:02.106988 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:02.109498 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:02.109733 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:58:02.109902 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:58:02.110058 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 19:58:02.112363 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.112515 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:58:02.112838 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:58:02.112981 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:02.114992 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.115093 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:02.120696 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:02.120853 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:58:02.129684 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:58:02.131073 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:58:02.132478 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:58:02.133026 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:02.134698 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:58:02.134933 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:02.135179 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.135544 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 19:58:02.135773 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:02.135924 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:58:02.136111 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.136302 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:58:02.136525 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:58:02.136650 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:02.136769 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:02.137084 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:02.137271 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.137393 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:02.137544 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:02.137663 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode::bigint as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 19:58:02.137819 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:58:02.137968 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.138108 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:02.138443 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode::bigint as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:58:02.138597 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:58:02.146968 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-19 19:58:02.159090 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.159308 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 19:58:02.159937 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:02.163628 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.163832 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 19:58:02.164527 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:02.174445 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:58:02.174613 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.174742 (Thread-3): Postgres error: invalid input syntax for type bigint: "B076FJ92M4"

2021-05-19 19:58:02.174851 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:58:02.175004 (Thread-3): On model.fetch_takehome.fact_items: ROLLBACK
2021-05-19 19:58:02.175435 (Thread-3): finished collecting timing info
2021-05-19 19:58:02.175573 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:02.175707 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 19:58:02.179107 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:02.179731 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:58:02.182188 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:02.183686 (Thread-2): finished collecting timing info
2021-05-19 19:58:02.183850 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:58:02.184345 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e42e640>]}
2021-05-19 19:58:02.179492 (Thread-3): Database Error in model fact_items (models/transformations/fact_items.sql)
  invalid input syntax for type bigint: "B076FJ92M4"
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type bigint: "B076FJ92M4"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_items (models/transformations/fact_items.sql)
  invalid input syntax for type bigint: "B076FJ92M4"
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:58:02.185014 (Thread-2): 15:58:02 | 2 of 6 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.15s]
2021-05-19 19:58:02.185395 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3ac9a0>]}
2021-05-19 19:58:02.185675 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:58:02.186287 (Thread-3): 15:58:02 | 3 of 6 ERROR creating table model fetch_takehome.fact_items.......... [ERROR in 0.15s]
2021-05-19 19:58:02.186497 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:58:02.186901 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 19:58:02.187159 (Thread-2): 15:58:02 | 5 of 6 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:58:02.187331 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:58:02.187750 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:02.188018 (Thread-3): 15:58:02 | 6 of 6 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:58:02.188360 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:58:02.188718 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.189956 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:58:02.190119 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:58:02.191581 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:58:02.192068 (Thread-2): finished collecting timing info
2021-05-19 19:58:02.195357 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:02.195599 (Thread-3): finished collecting timing info
2021-05-19 19:58:02.195768 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:58:02.199830 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.200082 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:58:02.200243 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:58:02.200574 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 19:58:02.208956 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-19 19:58:02.212092 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.212253 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:58:02.212693 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:02.214886 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.215023 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:58:02.215695 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:02.215848 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:58:02.217006 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:58:02.217104 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:58:02.219165 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.219320 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.221674 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:02.221928 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:58:02.222156 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:58:02.222314 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:58:02.222824 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:02.222987 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:02.224332 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:58:02.224441 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:02.225810 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:58:02.227827 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:02.228254 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:58:02.228610 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.228753 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:58:02.228931 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:02.229141 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:58:02.229380 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:02.229529 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.229626 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:58:02.229782 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:02.229957 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:02.230102 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:58:02.234153 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:02.235670 (Thread-1): finished collecting timing info
2021-05-19 19:58:02.235899 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:58:02.236507 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3ac4c0>]}
2021-05-19 19:58:02.237039 (Thread-1): 15:58:02 | 1 of 6 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.20s]
2021-05-19 19:58:02.237269 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:58:02.275333 (Thread-3): SQL status: SELECT 495 in 0.05 seconds
2021-05-19 19:58:02.278196 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.278359 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:58:02.278849 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:02.281401 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.281561 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:58:02.282146 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:02.283372 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:58:02.283508 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.283612 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:58:02.284203 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:02.286748 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:02.286911 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:58:02.289229 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:02.290633 (Thread-3): finished collecting timing info
2021-05-19 19:58:02.290822 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:58:02.291240 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e39c9d0>]}
2021-05-19 19:58:02.291587 (Thread-3): 15:58:02 | 6 of 6 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.10s]
2021-05-19 19:58:02.291764 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:58:02.938983 (Thread-2): SQL status: SELECT 1119 in 0.71 seconds
2021-05-19 19:58:02.941203 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:02.941326 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:58:03.069273 (Thread-4): SQL status: SELECT 6941 in 0.93 seconds
2021-05-19 19:58:03.071267 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:03.071364 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:58:03.071819 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:03.074669 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:03.074772 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:58:03.075275 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:03.076177 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:58:03.076269 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:03.076343 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:58:03.077188 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:03.078352 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:03.078460 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:58:03.078575 (Thread-2): SQL status: ALTER TABLE in 0.14 seconds
2021-05-19 19:58:03.080365 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:03.080472 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:58:03.080591 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:03.081495 (Thread-4): finished collecting timing info
2021-05-19 19:58:03.081620 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:58:03.081717 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:03.082015 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4dd280>]}
2021-05-19 19:58:03.082895 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:58:03.083226 (Thread-4): 15:58:03 | 4 of 6 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.05s]
2021-05-19 19:58:03.083330 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:03.083497 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:58:03.083642 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:58:03.084390 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:03.086076 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:03.086217 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:58:03.089042 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:03.090455 (Thread-2): finished collecting timing info
2021-05-19 19:58:03.090674 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:58:03.091115 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd426f3b-22ea-4028-bcf9-ac21b9403559', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4c9df0>]}
2021-05-19 19:58:03.091460 (Thread-2): 15:58:03 | 5 of 6 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.90s]
2021-05-19 19:58:03.091621 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:58:03.093061 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:58:03.093332 (MainThread): Using postgres connection "master".
2021-05-19 19:58:03.093448 (MainThread): On master: BEGIN
2021-05-19 19:58:03.093550 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:58:03.102876 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:58:03.103060 (MainThread): On master: COMMIT
2021-05-19 19:58:03.103214 (MainThread): Using postgres connection "master".
2021-05-19 19:58:03.103326 (MainThread): On master: COMMIT
2021-05-19 19:58:03.103543 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:03.103690 (MainThread): On master: Close
2021-05-19 19:58:03.104124 (MainThread): 15:58:03 | 
2021-05-19 19:58:03.104263 (MainThread): 15:58:03 | Finished running 6 table models in 1.19s.
2021-05-19 19:58:03.104414 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:58:03.104594 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:58:03.104735 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:58:03.104894 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:58:03.105046 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:58:03.110027 (MainThread): 
2021-05-19 19:58:03.110202 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 19:58:03.110420 (MainThread): 
2021-05-19 19:58:03.110586 (MainThread): Database Error in model fact_items (models/transformations/fact_items.sql)
2021-05-19 19:58:03.110705 (MainThread):   invalid input syntax for type bigint: "B076FJ92M4"
2021-05-19 19:58:03.110805 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-19 19:58:03.110941 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2021-05-19 19:58:03.111152 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e067a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2568e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e333b80>]}
2021-05-19 19:58:03.111350 (MainThread): Flushing usage events
2021-05-19 19:58:40.592945 (MainThread): Running with dbt=0.19.1
2021-05-19 19:58:40.668763 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 19:58:40.669520 (MainThread): Tracking: tracking
2021-05-19 19:58:40.682028 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff3ad00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff59610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff59e50>]}
2021-05-19 19:58:40.695789 (MainThread): Partial parsing not enabled
2021-05-19 19:58:40.696962 (MainThread): Parsing macros/catalog.sql
2021-05-19 19:58:40.701022 (MainThread): Parsing macros/relations.sql
2021-05-19 19:58:40.702827 (MainThread): Parsing macros/adapters.sql
2021-05-19 19:58:40.726659 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 19:58:40.729583 (MainThread): Parsing macros/core.sql
2021-05-19 19:58:40.733796 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 19:58:40.744125 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 19:58:40.745992 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 19:58:40.765328 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 19:58:40.800080 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 19:58:40.821993 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 19:58:40.823982 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 19:58:40.830795 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 19:58:40.845883 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 19:58:40.853057 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 19:58:40.859576 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 19:58:40.864659 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 19:58:40.865622 (MainThread): Parsing macros/etc/query.sql
2021-05-19 19:58:40.866696 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 19:58:40.868615 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 19:58:40.877934 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 19:58:40.879962 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 19:58:40.881683 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 19:58:40.925994 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 19:58:40.927955 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 19:58:40.929512 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 19:58:40.931254 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 19:58:40.939750 (MainThread): Partial parsing not enabled
2021-05-19 19:58:40.995989 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.008140 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.011724 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:41.015174 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:41.018750 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.022308 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 19:58:41.026692 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 19:58:41.030126 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.087827 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110189520>]}
2021-05-19 19:58:41.093114 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100bfa60>]}
2021-05-19 19:58:41.093440 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 19:58:41.094281 (MainThread): 
2021-05-19 19:58:41.094638 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:58:41.095832 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 19:58:41.108016 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 19:58:41.108185 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 19:58:41.108307 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 19:58:41.136442 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 19:58:41.139117 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 19:58:41.140684 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:58:41.147846 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:58:41.148006 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 19:58:41.148125 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 19:58:41.156755 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:58:41.156929 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 19:58:41.157036 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 19:58:41.160345 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.00 seconds
2021-05-19 19:58:41.161141 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 19:58:41.161375 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 19:58:41.166495 (MainThread): Using postgres connection "master".
2021-05-19 19:58:41.166653 (MainThread): On master: BEGIN
2021-05-19 19:58:41.166768 (MainThread): Opening a new connection, currently in state init
2021-05-19 19:58:41.175263 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:58:41.175430 (MainThread): Using postgres connection "master".
2021-05-19 19:58:41.175533 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 19:58:41.191871 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 19:58:41.192471 (MainThread): On master: ROLLBACK
2021-05-19 19:58:41.192711 (MainThread): Using postgres connection "master".
2021-05-19 19:58:41.192815 (MainThread): On master: BEGIN
2021-05-19 19:58:41.193116 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:41.193249 (MainThread): On master: COMMIT
2021-05-19 19:58:41.193350 (MainThread): Using postgres connection "master".
2021-05-19 19:58:41.193437 (MainThread): On master: COMMIT
2021-05-19 19:58:41.193646 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:41.193798 (MainThread): On master: Close
2021-05-19 19:58:41.194163 (MainThread): 15:58:41 | Concurrency: 4 threads (target='dev')
2021-05-19 19:58:41.194313 (MainThread): 15:58:41 | 
2021-05-19 19:58:41.196915 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 19:58:41.197132 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 19:58:41.197384 (Thread-1): 15:58:41 | 1 of 6 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 19:58:41.197512 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 19:58:41.197656 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 19:58:41.197874 (Thread-2): 15:58:41 | 2 of 6 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 19:58:41.198276 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.198473 (Thread-3): 15:58:41 | 3 of 6 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 19:58:41.198671 (Thread-4): 15:58:41 | 4 of 6 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 19:58:41.198962 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.199102 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 19:58:41.199469 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.199766 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:41.199899 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 19:58:41.201255 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:58:41.201394 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 19:58:41.201507 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 19:58:41.202652 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:58:41.204075 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:58:41.205236 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:58:41.205527 (Thread-1): finished collecting timing info
2021-05-19 19:58:41.211697 (Thread-3): finished collecting timing info
2021-05-19 19:58:41.211870 (Thread-2): finished collecting timing info
2021-05-19 19:58:41.239893 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.240031 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 19:58:41.240124 (Thread-2): Opening a new connection, currently in state init
2021-05-19 19:58:41.244129 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.244332 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 19:58:41.245771 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.245916 (Thread-3): Opening a new connection, currently in state init
2021-05-19 19:58:41.246076 (Thread-4): finished collecting timing info
2021-05-19 19:58:41.246176 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 19:58:41.249127 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:41.249377 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 19:58:41.249498 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 19:58:41.249857 (Thread-4): Opening a new connection, currently in state init
2021-05-19 19:58:41.250075 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:41.252749 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.252917 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:58:41.253284 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.265240 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 19:58:41.265624 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:58:41.267784 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.267954 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:58:41.268180 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:58:41.268319 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 19:58:41.268416 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.270277 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:41.272455 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.273851 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 19:58:41.273980 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.274094 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:58:41.274232 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 19:58:41.274499 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 19:58:41.274905 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.275076 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 19:58:41.275208 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:41.275304 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.275379 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.275541 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.275738 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:41.276956 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 19:58:41.278112 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 19:58:41.278228 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 19:58:41.278337 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.278925 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 19:58:41.279112 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.279306 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:41.279389 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 19:58:41.279493 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 19:58:41.279770 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:41.279890 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.279983 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 19:58:41.280137 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:41.280257 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:41.280348 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 19:58:41.286465 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-19 19:58:41.293847 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.294048 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 19:58:41.294629 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:41.298396 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.298618 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 19:58:41.299381 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:41.308869 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:58:41.309052 (Thread-3): SQL status: SELECT 6941 in 0.03 seconds
2021-05-19 19:58:41.309177 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.311213 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.311376 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 19:58:41.311511 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 19:58:41.312196 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:41.314727 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 19:58:41.314860 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.314954 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 19:58:41.315075 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:41.318340 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 19:58:41.318463 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 19:58:41.318613 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:41.319932 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 19:58:41.320044 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 19:58:41.320330 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.321352 (Thread-3): finished collecting timing info
2021-05-19 19:58:41.321491 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 19:58:41.321624 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.322595 (Thread-2): finished collecting timing info
2021-05-19 19:58:41.322920 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039a550>]}
2021-05-19 19:58:41.323033 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 19:58:41.323368 (Thread-3): 15:58:41 | 3 of 6 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.12s]
2021-05-19 19:58:41.323683 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039a910>]}
2021-05-19 19:58:41.323818 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 19:58:41.324085 (Thread-2): 15:58:41 | 2 of 6 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.12s]
2021-05-19 19:58:41.324229 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:58:41.324487 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 19:58:41.324664 (Thread-3): 15:58:41 | 5 of 6 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 19:58:41.324810 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 19:58:41.325187 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:41.325338 (Thread-2): 15:58:41 | 6 of 6 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 19:58:41.325449 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 19:58:41.325667 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.326797 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:58:41.326905 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 19:58:41.327876 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:58:41.328294 (Thread-2): finished collecting timing info
2021-05-19 19:58:41.330313 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.330412 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 19:58:41.330498 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 19:58:41.330592 (Thread-3): finished collecting timing info
2021-05-19 19:58:41.333012 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:41.333140 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 19:58:41.333232 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 19:58:41.333911 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-19 19:58:41.336005 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.336124 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 19:58:41.336524 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:41.338374 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.338498 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 19:58:41.338907 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:41.339811 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:58:41.339913 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.340015 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:41.340108 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 19:58:41.342304 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.342655 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:58:41.342994 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.343167 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:41.343300 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:41.344999 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 19:58:41.347111 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:41.348712 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 19:58:41.349148 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:58:41.349368 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 19:58:41.349780 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.349935 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.350063 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 19:58:41.351913 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 19:58:41.352308 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:41.352537 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.352719 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 19:58:41.353019 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:41.353128 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 19:58:41.353418 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 19:58:41.353539 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:41.353632 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 19:58:41.359322 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 19:58:41.360891 (Thread-1): finished collecting timing info
2021-05-19 19:58:41.361125 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 19:58:41.361668 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffa1fa0>]}
2021-05-19 19:58:41.362114 (Thread-1): 15:58:41 | 1 of 6 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.16s]
2021-05-19 19:58:41.362319 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 19:58:41.372266 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 19:58:41.374418 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.374532 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 19:58:41.374913 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:41.376601 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.376698 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 19:58:41.377109 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:41.378152 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:58:41.378254 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.378334 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 19:58:41.378884 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:41.380152 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 19:58:41.380246 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 19:58:41.381935 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:41.382953 (Thread-2): finished collecting timing info
2021-05-19 19:58:41.383096 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 19:58:41.383419 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102eb8b0>]}
2021-05-19 19:58:41.383708 (Thread-2): 15:58:41 | 6 of 6 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-19 19:58:41.383836 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 19:58:41.975271 (Thread-3): SQL status: SELECT 1119 in 0.62 seconds
2021-05-19 19:58:41.977804 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:41.977938 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 19:58:42.111315 (Thread-4): SQL status: SELECT 6941 in 0.83 seconds
2021-05-19 19:58:42.113385 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:42.113491 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 19:58:42.113888 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:42.116849 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:42.116967 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 19:58:42.117443 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:42.118711 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:58:42.142341 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:42.142497 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 19:58:42.144013 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:42.144223 (Thread-3): SQL status: ALTER TABLE in 0.17 seconds
2021-05-19 19:58:42.145662 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 19:58:42.147328 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:42.147460 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 19:58:42.147597 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 19:58:42.148093 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 19:58:42.149217 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:58:42.149388 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:42.149497 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 19:58:42.150028 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:42.151448 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 19:58:42.151608 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:42.151703 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 19:58:42.152680 (Thread-4): finished collecting timing info
2021-05-19 19:58:42.152962 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 19:58:42.153401 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11035a160>]}
2021-05-19 19:58:42.153891 (Thread-4): 15:58:42 | 4 of 6 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.95s]
2021-05-19 19:58:42.154042 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 19:58:42.155512 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 19:58:42.156646 (Thread-3): finished collecting timing info
2021-05-19 19:58:42.156801 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 19:58:42.157115 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f669195-a2e0-4d69-af28-aa27ba24c9e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110346f70>]}
2021-05-19 19:58:42.157386 (Thread-3): 15:58:42 | 5 of 6 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.83s]
2021-05-19 19:58:42.157533 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 19:58:42.158678 (MainThread): Acquiring new postgres connection "master".
2021-05-19 19:58:42.158855 (MainThread): Using postgres connection "master".
2021-05-19 19:58:42.158952 (MainThread): On master: BEGIN
2021-05-19 19:58:42.159044 (MainThread): Opening a new connection, currently in state closed
2021-05-19 19:58:42.167116 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 19:58:42.167357 (MainThread): On master: COMMIT
2021-05-19 19:58:42.167465 (MainThread): Using postgres connection "master".
2021-05-19 19:58:42.167559 (MainThread): On master: COMMIT
2021-05-19 19:58:42.167793 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 19:58:42.167922 (MainThread): On master: Close
2021-05-19 19:58:42.168283 (MainThread): 15:58:42 | 
2021-05-19 19:58:42.168418 (MainThread): 15:58:42 | Finished running 6 table models in 1.07s.
2021-05-19 19:58:42.168530 (MainThread): Connection 'master' was properly closed.
2021-05-19 19:58:42.168618 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 19:58:42.168747 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 19:58:42.168854 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 19:58:42.168939 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 19:58:42.173200 (MainThread): 
2021-05-19 19:58:42.173350 (MainThread): Completed successfully
2021-05-19 19:58:42.173482 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-05-19 19:58:42.173662 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100bf940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100c3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103cb0d0>]}
2021-05-19 19:58:42.173850 (MainThread): Flushing usage events
2021-05-19 20:19:23.291012 (MainThread): Running with dbt=0.19.1
2021-05-19 20:19:23.404092 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:19:23.406490 (MainThread): Tracking: tracking
2021-05-19 20:19:23.430188 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112373d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112390610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112390e50>]}
2021-05-19 20:19:23.445569 (MainThread): Partial parsing not enabled
2021-05-19 20:19:23.447871 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:19:23.452845 (MainThread): Parsing macros/relations.sql
2021-05-19 20:19:23.455056 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:19:23.480487 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:19:23.485016 (MainThread): Parsing macros/core.sql
2021-05-19 20:19:23.490251 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:19:23.500754 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:19:23.503570 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:19:23.527332 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:19:23.564616 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:19:23.586579 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:19:23.588742 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:19:23.595417 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:19:23.610707 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:19:23.618119 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:19:23.625256 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:19:23.631051 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:19:23.632396 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:19:23.633701 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:19:23.635673 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:19:23.645159 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:19:23.647541 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:19:23.649711 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:19:23.697585 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:19:23.700414 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:19:23.702272 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:19:23.704273 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:19:23.712667 (MainThread): Partial parsing not enabled
2021-05-19 20:19:23.773154 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:23.785307 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:23.788816 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:23.792503 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:23.796075 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:23.799314 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:19:23.804039 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:19:23.808228 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:23.865616 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125c0520>]}
2021-05-19 20:19:23.871261 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124f6a60>]}
2021-05-19 20:19:23.871571 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:19:23.872416 (MainThread): 
2021-05-19 20:19:23.872757 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:19:23.873987 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:19:23.884803 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:19:23.884946 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:19:23.885052 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:19:24.045551 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.16 seconds
2021-05-19 20:19:24.049911 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:19:24.051537 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:19:24.058515 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:19:24.058684 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:19:24.058798 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:19:24.068723 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:19:24.068897 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:19:24.069112 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:19:24.073850 (ThreadPoolExecutor-1_0): SQL status: SELECT 9 in 0.00 seconds
2021-05-19 20:19:24.075237 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:19:24.075652 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:19:24.082157 (MainThread): Using postgres connection "master".
2021-05-19 20:19:24.082331 (MainThread): On master: BEGIN
2021-05-19 20:19:24.082452 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:19:24.092685 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:19:24.092972 (MainThread): Using postgres connection "master".
2021-05-19 20:19:24.093161 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:19:24.116198 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 20:19:24.116825 (MainThread): On master: ROLLBACK
2021-05-19 20:19:24.117105 (MainThread): Using postgres connection "master".
2021-05-19 20:19:24.117223 (MainThread): On master: BEGIN
2021-05-19 20:19:24.117575 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.117713 (MainThread): On master: COMMIT
2021-05-19 20:19:24.117819 (MainThread): Using postgres connection "master".
2021-05-19 20:19:24.117907 (MainThread): On master: COMMIT
2021-05-19 20:19:24.118099 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:19:24.118219 (MainThread): On master: Close
2021-05-19 20:19:24.118529 (MainThread): 16:19:24 | Concurrency: 4 threads (target='dev')
2021-05-19 20:19:24.118673 (MainThread): 16:19:24 | 
2021-05-19 20:19:24.121320 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:19:24.121516 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:19:24.121658 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:19:24.121887 (Thread-1): 16:19:24 | 1 of 7 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:19:24.121992 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:19:24.122226 (Thread-2): 16:19:24 | 2 of 7 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:19:24.122428 (Thread-3): 16:19:24 | 3 of 7 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:19:24.122832 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.123040 (Thread-4): 16:19:24 | 4 of 7 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:19:24.123452 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.123773 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.123946 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:19:24.124309 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:19:24.124418 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:19:24.124538 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:19:24.126303 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:19:24.126482 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:19:24.127728 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:19:24.129017 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:19:24.130466 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:19:24.130851 (Thread-1): finished collecting timing info
2021-05-19 20:19:24.142766 (Thread-2): finished collecting timing info
2021-05-19 20:19:24.156313 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.156533 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.156642 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:19:24.156790 (Thread-4): finished collecting timing info
2021-05-19 20:19:24.156980 (Thread-3): finished collecting timing info
2021-05-19 20:19:24.157090 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:19:24.157211 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:19:24.159666 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:19:24.162486 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.162709 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:19:24.163025 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:19:24.163165 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:19:24.163479 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:19:24.163617 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:19:24.173948 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:19:24.176310 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.176659 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:19:24.176949 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.177107 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.177205 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.177283 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.189851 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:19:24.192146 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:19:24.194357 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.196390 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.196675 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:19:24.196813 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:19:24.196990 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:19:24.197198 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.197428 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.197539 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.197681 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.197779 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:19:24.199030 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:19:24.200321 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:19:24.201635 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:19:24.202237 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.202376 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.202498 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:19:24.202824 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:19:24.202958 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:19:24.203245 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.203418 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.203574 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.203666 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:19:24.203779 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:19:24.203883 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:19:24.203979 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate / 1000)::date as createDate,
--to_timestamp(dateScanned / 1000)::date as dateScanned,
--to_timestamp(finishedDate / 1000)::date as finishedDate,
--to_timestamp(modifyDate / 1000)::date as modifyDate,
--as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
--as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:19:24.204270 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.204408 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.204504 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.204631 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.204762 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:19:24.204965 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:19:24.211529 (Thread-4): Postgres error: operator does not exist: character varying / integer
LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

2021-05-19 20:19:24.211724 (Thread-4): On model.fetch_takehome.fact_receipts: ROLLBACK
2021-05-19 20:19:24.212035 (Thread-4): finished collecting timing info
2021-05-19 20:19:24.212219 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:19:24.212596 (Thread-4): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  operator does not exist: character varying / integer
  LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying / integer
LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  operator does not exist: character varying / integer
  LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:19:24.227281 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112723a60>]}
2021-05-19 20:19:24.227976 (Thread-4): 16:19:24 | 4 of 7 ERROR creating table model fetch_takehome.fact_receipts....... [ERROR in 0.10s]
2021-05-19 20:19:24.228214 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:19:24.228956 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:19:24.229396 (Thread-4): 16:19:24 | 5 of 7 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:19:24.229755 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:24.229894 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:19:24.231583 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:19:24.231840 (Thread-2): SQL status: SELECT 1167 in 0.03 seconds
2021-05-19 20:19:24.238936 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.239191 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:19:24.239450 (Thread-4): finished collecting timing info
2021-05-19 20:19:24.243675 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:24.243832 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:19:24.243948 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:19:24.244230 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.246720 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.246865 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:19:24.247413 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.255036 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:19:24.255187 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.255285 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:19:24.255467 (Thread-3): SQL status: SELECT 6941 in 0.05 seconds
2021-05-19 20:19:24.257747 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.257916 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.258080 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:19:24.258364 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:19:24.260191 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:24.263561 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:19:24.263747 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.263855 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:19:24.263991 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:19:24.266092 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.266432 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:19:24.266592 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.268502 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:19:24.268821 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.270012 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:19:24.270136 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.270231 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:19:24.270583 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:24.270691 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:19:24.270955 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.271080 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:24.271176 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:19:24.275950 (Thread-3): SQL status: COMMIT in 0.01 seconds
2021-05-19 20:19:24.277640 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:19:24.277791 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:19:24.281467 (Thread-1): SQL status: SELECT 1167 in 0.08 seconds
2021-05-19 20:19:24.283922 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.284052 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:19:24.284502 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.286861 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.286998 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:19:24.287574 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.288724 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:19:24.288854 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.288950 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:19:24.289094 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.289238 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:19:24.290330 (Thread-3): finished collecting timing info
2021-05-19 20:19:24.290478 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:19:24.291478 (Thread-2): finished collecting timing info
2021-05-19 20:19:24.291634 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:19:24.293055 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:19:24.293233 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:19:24.293635 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112707fa0>]}
2021-05-19 20:19:24.293765 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:19:24.294298 (Thread-3): 16:19:24 | 3 of 7 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.17s]
2021-05-19 20:19:24.294644 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112707d30>]}
2021-05-19 20:19:24.294935 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:19:24.295286 (Thread-2): 16:19:24 | 2 of 7 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.17s]
2021-05-19 20:19:24.295504 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:19:24.295886 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:19:24.296115 (Thread-3): 16:19:24 | 6 of 7 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:19:24.296339 (Thread-2): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:19:24.296705 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:24.297010 (Thread-2): 16:19:24 | 7 of 7 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:19:24.297156 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:19:24.297439 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.298934 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:19:24.299121 (Thread-2): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:19:24.300368 (Thread-2): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:19:24.300757 (Thread-3): finished collecting timing info
2021-05-19 20:19:24.303345 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:24.303477 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:19:24.303591 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:19:24.303853 (Thread-2): finished collecting timing info
2021-05-19 20:19:24.306701 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.306855 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:19:24.306965 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:19:24.307556 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.308916 (Thread-1): finished collecting timing info
2021-05-19 20:19:24.309078 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:19:24.309460 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125081f0>]}
2021-05-19 20:19:24.309764 (Thread-1): 16:19:24 | 1 of 7 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.19s]
2021-05-19 20:19:24.309902 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:19:24.312216 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.314431 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:24.314563 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:19:24.314829 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.316076 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:19:24.316546 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:24.316650 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:19:24.316788 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:24.318773 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.320349 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:19:24.320529 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.320715 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:24.320816 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:19:24.320973 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.322211 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:19:24.322653 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.322758 (Thread-2): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:19:24.323034 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:19:24.323139 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.323227 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:19:24.343859 (Thread-2): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 20:19:24.347681 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.347910 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:19:24.348680 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.352077 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.352304 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:19:24.353052 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:24.354850 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:19:24.355052 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.355200 (Thread-2): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:19:24.364809 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-05-19 20:19:24.367554 (Thread-2): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:19:24.367767 (Thread-2): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:19:24.370738 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:24.372808 (Thread-2): finished collecting timing info
2021-05-19 20:19:24.373081 (Thread-2): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:19:24.373709 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11267ed60>]}
2021-05-19 20:19:24.374220 (Thread-2): 16:19:24 | 7 of 7 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.08s]
2021-05-19 20:19:24.374558 (Thread-2): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:19:25.156900 (Thread-3): SQL status: SELECT 1119 in 0.84 seconds
2021-05-19 20:19:25.158885 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:25.158986 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:19:25.299474 (Thread-4): SQL status: SELECT 6941 in 1.03 seconds
2021-05-19 20:19:25.301754 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:25.301877 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:19:25.302336 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:25.304248 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:25.304362 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:19:25.304885 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:25.306170 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:19:25.306293 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:25.306382 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:19:25.306970 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:19:25.308397 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:19:25.308540 (Thread-3): SQL status: ALTER TABLE in 0.15 seconds
2021-05-19 20:19:25.308645 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:19:25.310960 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:25.311188 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:19:25.311831 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:19:25.313121 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:19:25.313256 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:25.313361 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:19:25.313833 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:19:25.314005 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:19:25.315426 (Thread-4): finished collecting timing info
2021-05-19 20:19:25.317248 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:19:25.317514 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:19:25.317723 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:19:25.318451 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126ecf70>]}
2021-05-19 20:19:25.318994 (Thread-4): 16:19:25 | 5 of 7 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.09s]
2021-05-19 20:19:25.319237 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:19:25.330981 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:19:25.332482 (Thread-3): finished collecting timing info
2021-05-19 20:19:25.332689 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:19:25.333250 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f2ef806-f6ed-44d0-bad1-9970c998f6d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112707f40>]}
2021-05-19 20:19:25.333737 (Thread-3): 16:19:25 | 6 of 7 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.04s]
2021-05-19 20:19:25.333969 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:19:25.336200 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:19:25.336505 (MainThread): Using postgres connection "master".
2021-05-19 20:19:25.336681 (MainThread): On master: BEGIN
2021-05-19 20:19:25.336846 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:19:25.347644 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:19:25.347845 (MainThread): On master: COMMIT
2021-05-19 20:19:25.347953 (MainThread): Using postgres connection "master".
2021-05-19 20:19:25.348048 (MainThread): On master: COMMIT
2021-05-19 20:19:25.348259 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:19:25.348389 (MainThread): On master: Close
2021-05-19 20:19:25.348793 (MainThread): 16:19:25 | 
2021-05-19 20:19:25.348955 (MainThread): 16:19:25 | Finished running 7 table models in 1.48s.
2021-05-19 20:19:25.349109 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:19:25.349224 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 20:19:25.349324 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:19:25.349405 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:19:25.349549 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:19:25.355753 (MainThread): 
2021-05-19 20:19:25.356020 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 20:19:25.356213 (MainThread): 
2021-05-19 20:19:25.356383 (MainThread): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
2021-05-19 20:19:25.356509 (MainThread):   operator does not exist: character varying / integer
2021-05-19 20:19:25.356630 (MainThread):   LINE 10: to_timestamp(createDate / 1000)::date as createDate,
2021-05-19 20:19:25.356744 (MainThread):                                    ^
2021-05-19 20:19:25.356865 (MainThread):   HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2021-05-19 20:19:25.356991 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:19:25.357144 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-05-19 20:19:25.357366 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125d0f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11281d250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112723a30>]}
2021-05-19 20:19:25.357648 (MainThread): Flushing usage events
2021-05-19 20:20:37.112757 (MainThread): Running with dbt=0.19.1
2021-05-19 20:20:37.192005 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:20:37.193077 (MainThread): Tracking: tracking
2021-05-19 20:20:37.207428 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081a5e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081c16a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081c1ee0>]}
2021-05-19 20:20:37.220116 (MainThread): Partial parsing not enabled
2021-05-19 20:20:37.221476 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:20:37.225392 (MainThread): Parsing macros/relations.sql
2021-05-19 20:20:37.227320 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:20:37.248436 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:20:37.251642 (MainThread): Parsing macros/core.sql
2021-05-19 20:20:37.255927 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:20:37.265486 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:20:37.267544 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:20:37.287285 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:20:37.321760 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:20:37.343487 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:20:37.345682 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:20:37.352272 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:20:37.366992 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:20:37.374394 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:20:37.381476 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:20:37.387058 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:20:37.388385 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:20:37.389638 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:20:37.391459 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:20:37.401069 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:20:37.404285 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:20:37.407016 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:20:37.457683 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:20:37.460480 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:20:37.463023 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:20:37.465553 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:20:37.475452 (MainThread): Partial parsing not enabled
2021-05-19 20:20:37.537888 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.553656 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.557383 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:37.561089 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:37.564809 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.568255 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:20:37.572583 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:20:37.576542 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.635464 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108413a90>]}
2021-05-19 20:20:37.640822 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108326af0>]}
2021-05-19 20:20:37.641111 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:20:37.641944 (MainThread): 
2021-05-19 20:20:37.642283 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:20:37.643612 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:20:37.655360 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:20:37.655518 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:20:37.655630 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:20:37.688887 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 20:20:37.691970 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:20:37.693598 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:20:37.700665 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:20:37.700835 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:20:37.700949 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:20:37.709385 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:20:37.709562 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:20:37.709663 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:20:37.713270 (ThreadPoolExecutor-1_0): SQL status: SELECT 9 in 0.00 seconds
2021-05-19 20:20:37.714107 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:20:37.714338 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:20:37.719498 (MainThread): Using postgres connection "master".
2021-05-19 20:20:37.719659 (MainThread): On master: BEGIN
2021-05-19 20:20:37.719771 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:20:37.730220 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:20:37.730396 (MainThread): Using postgres connection "master".
2021-05-19 20:20:37.730497 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:20:37.750801 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 20:20:37.751460 (MainThread): On master: ROLLBACK
2021-05-19 20:20:37.751717 (MainThread): Using postgres connection "master".
2021-05-19 20:20:37.751826 (MainThread): On master: BEGIN
2021-05-19 20:20:37.752140 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.752279 (MainThread): On master: COMMIT
2021-05-19 20:20:37.752385 (MainThread): Using postgres connection "master".
2021-05-19 20:20:37.752476 (MainThread): On master: COMMIT
2021-05-19 20:20:37.752684 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:37.752810 (MainThread): On master: Close
2021-05-19 20:20:37.753136 (MainThread): 16:20:37 | Concurrency: 4 threads (target='dev')
2021-05-19 20:20:37.753286 (MainThread): 16:20:37 | 
2021-05-19 20:20:37.756139 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:20:37.756359 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:20:37.756624 (Thread-1): 16:20:37 | 1 of 7 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:20:37.756727 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:20:37.756902 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:20:37.757152 (Thread-2): 16:20:37 | 2 of 7 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:20:37.757518 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.757756 (Thread-3): 16:20:37 | 3 of 7 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:20:37.757971 (Thread-4): 16:20:37 | 4 of 7 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:20:37.758267 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.758413 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:20:37.758692 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.758974 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:20:37.759148 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:20:37.760573 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:20:37.760714 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:20:37.760830 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:20:37.761966 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:20:37.763356 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:20:37.764553 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:20:37.764924 (Thread-1): finished collecting timing info
2021-05-19 20:20:37.765378 (Thread-2): finished collecting timing info
2021-05-19 20:20:37.770947 (Thread-4): finished collecting timing info
2021-05-19 20:20:37.776330 (Thread-3): finished collecting timing info
2021-05-19 20:20:37.806736 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:20:37.806888 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.808379 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.810816 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.810970 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:20:37.811078 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:20:37.811176 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:20:37.811280 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:20:37.811402 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:20:37.811548 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:20:37.811685 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:20:37.811815 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:20:37.823106 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:20:37.825416 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.825558 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:20:37.825860 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:20:37.826070 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.828222 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:20:37.828365 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:20:37.828463 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:20:37.840137 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:20:37.840259 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:20:37.842632 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.844509 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.845002 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:20:37.845185 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.845288 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.845373 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:20:37.845547 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:20:37.847114 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:20:37.847271 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.847676 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.847818 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.849143 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:20:37.850421 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:20:37.850602 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:20:37.850700 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.851027 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:20:37.851219 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:20:37.851586 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.851708 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.851937 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.852060 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:20:37.852170 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:20:37.852273 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:20:37.852439 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
cast(to_timestamp(createDate / 1000)::date as createDate),
--to_timestamp(dateScanned / 1000)::date as dateScanned,
--to_timestamp(finishedDate / 1000)::date as finishedDate,
--to_timestamp(modifyDate / 1000)::date as modifyDate,
--as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
--as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:20:37.852568 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.852796 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.852902 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:20:37.853036 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.853135 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.853228 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:20:37.853366 (Thread-4): Postgres error: type "createdate" does not exist
LINE 10: cast(to_timestamp(createDate / 1000)::date as createDate),
                                                       ^

2021-05-19 20:20:37.853572 (Thread-4): On model.fetch_takehome.fact_receipts: ROLLBACK
2021-05-19 20:20:37.853897 (Thread-4): finished collecting timing info
2021-05-19 20:20:37.854111 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:20:37.854470 (Thread-4): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  type "createdate" does not exist
  LINE 10: cast(to_timestamp(createDate / 1000)::date as createDate),
                                                         ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "createdate" does not exist
LINE 10: cast(to_timestamp(createDate / 1000)::date as createDate),
                                                       ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  type "createdate" does not exist
  LINE 10: cast(to_timestamp(createDate / 1000)::date as createDate),
                                                         ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:20:37.862461 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108555af0>]}
2021-05-19 20:20:37.862807 (Thread-4): 16:20:37 | 4 of 7 ERROR creating table model fetch_takehome.fact_receipts....... [ERROR in 0.10s]
2021-05-19 20:20:37.862952 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:20:37.863100 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:20:37.863305 (Thread-4): 16:20:37 | 5 of 7 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:20:37.863755 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:37.863885 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:20:37.865085 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:20:37.865436 (Thread-4): finished collecting timing info
2021-05-19 20:20:37.868130 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:37.868256 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:20:37.868362 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:20:37.875309 (Thread-2): SQL status: SELECT 1167 in 0.02 seconds
2021-05-19 20:20:37.884642 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.884852 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:20:37.885056 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:20:37.887277 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:37.887432 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.887545 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:20:37.889931 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.890161 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:20:37.890325 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.891582 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:20:37.891708 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.899706 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:20:37.899930 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.900056 (Thread-3): SQL status: SELECT 6941 in 0.05 seconds
2021-05-19 20:20:37.900200 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:20:37.902799 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.903030 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:37.903438 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:20:37.903284 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:20:37.903750 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.903916 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:37.904026 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:20:37.904145 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.907094 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.907304 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:37.907427 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:20:37.911349 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:20:37.911674 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:20:37.912071 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.914092 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:20:37.914231 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.914329 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:20:37.914476 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.915610 (Thread-2): finished collecting timing info
2021-05-19 20:20:37.915744 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:37.915903 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:20:37.917462 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:20:37.918055 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108536e20>]}
2021-05-19 20:20:37.918172 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:20:37.918550 (Thread-2): 16:20:37 | 2 of 7 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.16s]
2021-05-19 20:20:37.918798 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:20:37.919053 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:20:37.919483 (Thread-2): 16:20:37 | 6 of 7 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:20:37.919796 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:37.919925 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:20:37.921234 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:20:37.921363 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.922661 (Thread-3): finished collecting timing info
2021-05-19 20:20:37.922920 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:20:37.923342 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085369d0>]}
2021-05-19 20:20:37.923526 (Thread-2): finished collecting timing info
2021-05-19 20:20:37.923898 (Thread-3): 16:20:37 | 3 of 7 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.16s]
2021-05-19 20:20:37.926857 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:37.927090 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:20:37.927287 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:20:37.927393 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-19 20:20:37.927559 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:20:37.927796 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:20:37.930162 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.930531 (Thread-3): 16:20:37 | 7 of 7 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:20:37.930936 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:20:37.931372 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.931704 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:20:37.933622 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:20:37.933787 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.936505 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.936674 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:20:37.937219 (Thread-3): finished collecting timing info
2021-05-19 20:20:37.937394 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.940547 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.941884 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:20:37.942033 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:20:37.942140 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:20:37.942267 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.944345 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:37.944487 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:20:37.944604 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:20:37.944749 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:20:37.945388 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.945551 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:37.947466 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:20:37.949116 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:20:37.949444 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:20:37.949805 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:37.949921 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:20:37.951801 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.951981 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:37.952119 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:20:37.954553 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:20:37.957190 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.957348 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:20:37.957482 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:20:37.958635 (Thread-1): finished collecting timing info
2021-05-19 20:20:37.958983 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:20:37.959142 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.959579 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108532040>]}
2021-05-19 20:20:37.960966 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:20:37.961395 (Thread-1): 16:20:37 | 1 of 7 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.20s]
2021-05-19 20:20:37.961777 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:20:37.962325 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.962443 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:20:37.962728 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:20:37.962857 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.962954 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:20:37.981559 (Thread-3): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 20:20:37.984644 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.984864 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:20:37.985495 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.988048 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.988238 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:20:37.988749 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:37.989923 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:20:37.990042 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.990133 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:20:37.990865 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:37.992599 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:20:37.992735 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:20:37.994893 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:37.996116 (Thread-3): finished collecting timing info
2021-05-19 20:20:37.996293 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:20:37.996837 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108674bb0>]}
2021-05-19 20:20:37.997487 (Thread-3): 16:20:37 | 7 of 7 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.07s]
2021-05-19 20:20:37.997764 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:20:38.689627 (Thread-2): SQL status: SELECT 1119 in 0.74 seconds
2021-05-19 20:20:38.691598 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:38.691696 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:20:38.793835 (Thread-4): SQL status: SELECT 6941 in 0.89 seconds
2021-05-19 20:20:38.795812 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:38.795916 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:20:38.796294 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:38.797954 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:38.798045 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:20:38.798450 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:38.799326 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:20:38.799416 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:38.799491 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:20:38.800262 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:38.801490 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:20:38.801592 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:20:38.801710 (Thread-2): SQL status: ALTER TABLE in 0.11 seconds
2021-05-19 20:20:38.803298 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:38.803388 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:20:38.803598 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:38.804495 (Thread-4): finished collecting timing info
2021-05-19 20:20:38.804624 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:20:38.804741 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:20:38.805049 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108527f40>]}
2021-05-19 20:20:38.805979 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:20:38.806277 (Thread-4): 16:20:38 | 5 of 7 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.94s]
2021-05-19 20:20:38.806377 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:38.806543 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:20:38.806635 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:20:38.807252 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:38.808630 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:20:38.808731 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:20:38.811531 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:20:38.812585 (Thread-2): finished collecting timing info
2021-05-19 20:20:38.812717 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:20:38.813024 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29735d4a-6b16-427d-a367-cf4c2dc85d85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083d7790>]}
2021-05-19 20:20:38.813293 (Thread-2): 16:20:38 | 6 of 7 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.89s]
2021-05-19 20:20:38.813450 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:20:38.814711 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:20:38.814867 (MainThread): Using postgres connection "master".
2021-05-19 20:20:38.814951 (MainThread): On master: BEGIN
2021-05-19 20:20:38.815034 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:20:38.822798 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:20:38.822971 (MainThread): On master: COMMIT
2021-05-19 20:20:38.823077 (MainThread): Using postgres connection "master".
2021-05-19 20:20:38.823179 (MainThread): On master: COMMIT
2021-05-19 20:20:38.823362 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:20:38.823478 (MainThread): On master: Close
2021-05-19 20:20:38.823820 (MainThread): 16:20:38 | 
2021-05-19 20:20:38.823947 (MainThread): 16:20:38 | Finished running 7 table models in 1.18s.
2021-05-19 20:20:38.824053 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:20:38.824139 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 20:20:38.824234 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:20:38.824310 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:20:38.824383 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:20:38.829171 (MainThread): 
2021-05-19 20:20:38.829347 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 20:20:38.829516 (MainThread): 
2021-05-19 20:20:38.829662 (MainThread): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
2021-05-19 20:20:38.829774 (MainThread):   type "createdate" does not exist
2021-05-19 20:20:38.829874 (MainThread):   LINE 10: cast(to_timestamp(createDate / 1000)::date as createDate),
2021-05-19 20:20:38.829970 (MainThread):                                                          ^
2021-05-19 20:20:38.830063 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:20:38.830175 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-05-19 20:20:38.830360 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084136d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10857e7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085321f0>]}
2021-05-19 20:20:38.830560 (MainThread): Flushing usage events
2021-05-19 20:21:04.359530 (MainThread): Running with dbt=0.19.1
2021-05-19 20:21:04.435268 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:21:04.435978 (MainThread): Tracking: tracking
2021-05-19 20:21:04.451365 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f343dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3685e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f368e20>]}
2021-05-19 20:21:04.463447 (MainThread): Partial parsing not enabled
2021-05-19 20:21:04.464907 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:21:04.469052 (MainThread): Parsing macros/relations.sql
2021-05-19 20:21:04.471007 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:21:04.493547 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:21:04.496890 (MainThread): Parsing macros/core.sql
2021-05-19 20:21:04.501674 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:21:04.511450 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:21:04.513568 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:21:04.533073 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:21:04.568263 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:21:04.591282 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:21:04.593360 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:21:04.600769 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:21:04.616945 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:21:04.624586 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:21:04.632095 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:21:04.638072 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:21:04.639422 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:21:04.640710 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:21:04.642603 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:21:04.652532 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:21:04.654813 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:21:04.656867 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:21:04.704636 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:21:04.706829 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:21:04.708548 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:21:04.710557 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:21:04.718575 (MainThread): Partial parsing not enabled
2021-05-19 20:21:04.773781 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:04.789158 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:04.793488 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:04.797024 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:04.800410 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:04.803168 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:04.806802 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:21:04.810509 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:04.858567 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5b6ca0>]}
2021-05-19 20:21:04.862557 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4d3a30>]}
2021-05-19 20:21:04.862801 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:21:04.863449 (MainThread): 
2021-05-19 20:21:04.863716 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:21:04.864667 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:21:04.873305 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:21:04.873438 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:21:04.873529 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:21:04.894744 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-19 20:21:04.897549 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:21:04.899059 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:21:04.905260 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:21:04.905395 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:21:04.905489 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:21:04.912535 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:21:04.912690 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:21:04.912806 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:21:04.915794 (ThreadPoolExecutor-1_0): SQL status: SELECT 9 in 0.00 seconds
2021-05-19 20:21:04.916540 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:21:04.916730 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:21:04.921168 (MainThread): Using postgres connection "master".
2021-05-19 20:21:04.921295 (MainThread): On master: BEGIN
2021-05-19 20:21:04.921393 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:21:04.928671 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:21:04.928826 (MainThread): Using postgres connection "master".
2021-05-19 20:21:04.928913 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:21:04.945506 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 20:21:04.946144 (MainThread): On master: ROLLBACK
2021-05-19 20:21:04.946427 (MainThread): Using postgres connection "master".
2021-05-19 20:21:04.946527 (MainThread): On master: BEGIN
2021-05-19 20:21:04.946814 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:04.946948 (MainThread): On master: COMMIT
2021-05-19 20:21:04.947089 (MainThread): Using postgres connection "master".
2021-05-19 20:21:04.947172 (MainThread): On master: COMMIT
2021-05-19 20:21:04.947356 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:04.947489 (MainThread): On master: Close
2021-05-19 20:21:04.947799 (MainThread): 16:21:04 | Concurrency: 4 threads (target='dev')
2021-05-19 20:21:04.947933 (MainThread): 16:21:04 | 
2021-05-19 20:21:04.950523 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:21:04.950790 (Thread-1): 16:21:04 | 1 of 7 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:21:04.950941 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:21:04.951237 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:04.951359 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:21:04.951556 (Thread-2): 16:21:04 | 2 of 7 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:21:04.951641 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:21:04.951787 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:21:04.951956 (Thread-3): 16:21:04 | 3 of 7 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:21:04.952296 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:04.952458 (Thread-4): 16:21:04 | 4 of 7 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:21:04.953641 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:21:04.953934 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:04.954050 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:21:04.954287 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:04.954518 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:21:04.955579 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:21:04.955754 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:21:04.955852 (Thread-1): finished collecting timing info
2021-05-19 20:21:04.956937 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:21:04.957945 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:21:04.963553 (Thread-2): finished collecting timing info
2021-05-19 20:21:04.981400 (Thread-3): finished collecting timing info
2021-05-19 20:21:04.995027 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:04.999737 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.001228 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.001441 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:21:05.001662 (Thread-4): finished collecting timing info
2021-05-19 20:21:05.001870 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:21:05.002015 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:21:05.002301 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:21:05.004648 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:05.004818 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:21:05.004915 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:21:05.005187 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:21:05.005588 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:21:05.014600 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:05.014762 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:05.016816 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.017047 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:05.018810 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:05.018946 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:21:05.019019 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:05.020663 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:05.020791 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:21:05.022653 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.022788 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.022878 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.023050 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:21:05.023183 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.034595 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:21:05.036085 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:21:05.036226 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.036318 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.037719 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:21:05.039119 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:21:05.039310 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.039502 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:05.039767 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:21:05.039970 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:21:05.040308 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.040437 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:05.040589 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:05.040673 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:21:05.040750 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:05.040859 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:21:05.040951 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.041093 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:05.041224 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:05.041313 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:21:05.041393 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:05.041489 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
cast(to_timestamp(createDate / 1000) as createDate),
--to_timestamp(dateScanned / 1000)::date as dateScanned,
--to_timestamp(finishedDate / 1000)::date as finishedDate,
--to_timestamp(modifyDate / 1000)::date as modifyDate,
--as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
--as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:21:05.041579 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.041734 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:05.041907 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:21:05.042016 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:21:05.042355 (Thread-4): Postgres error: type "createdate" does not exist
LINE 10: cast(to_timestamp(createDate / 1000) as createDate),
                                                 ^

2021-05-19 20:21:05.042510 (Thread-4): On model.fetch_takehome.fact_receipts: ROLLBACK
2021-05-19 20:21:05.042813 (Thread-4): finished collecting timing info
2021-05-19 20:21:05.043010 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:21:05.043471 (Thread-4): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  type "createdate" does not exist
  LINE 10: cast(to_timestamp(createDate / 1000) as createDate),
                                                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "createdate" does not exist
LINE 10: cast(to_timestamp(createDate / 1000) as createDate),
                                                 ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  type "createdate" does not exist
  LINE 10: cast(to_timestamp(createDate / 1000) as createDate),
                                                   ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:21:05.050412 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6ffb50>]}
2021-05-19 20:21:05.050731 (Thread-4): 16:21:05 | 4 of 7 ERROR creating table model fetch_takehome.fact_receipts....... [ERROR in 0.10s]
2021-05-19 20:21:05.050862 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:21:05.050994 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:21:05.051175 (Thread-4): 16:21:05 | 5 of 7 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:21:05.051435 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.051544 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:21:05.052690 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:21:05.053296 (Thread-4): finished collecting timing info
2021-05-19 20:21:05.055874 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.056005 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:21:05.056100 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:21:05.060506 (Thread-2): SQL status: SELECT 1167 in 0.02 seconds
2021-05-19 20:21:05.068043 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.068289 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:21:05.068700 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.068833 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:05.070722 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.072365 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.072479 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:21:05.072577 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.072953 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.074250 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:21:05.074458 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.080594 (Thread-3): SQL status: SELECT 6941 in 0.04 seconds
2021-05-19 20:21:05.083098 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.083263 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:21:05.084999 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:21:05.085287 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.085522 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.085652 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:21:05.085760 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.085915 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:21:05.088050 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.088283 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:21:05.088452 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:05.088655 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.088793 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:21:05.089072 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.090779 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:21:05.090978 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.091076 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:21:05.091650 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-05-19 20:21:05.095178 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:05.095405 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:05.095550 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:21:05.097980 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:05.098223 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:21:05.100531 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.100723 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.102112 (Thread-2): finished collecting timing info
2021-05-19 20:21:05.103180 (Thread-3): finished collecting timing info
2021-05-19 20:21:05.103369 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:21:05.103527 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:21:05.104014 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4dcdc0>]}
2021-05-19 20:21:05.104306 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6ef790>]}
2021-05-19 20:21:05.104731 (Thread-2): 16:21:05 | 2 of 7 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.15s]
2021-05-19 20:21:05.105132 (Thread-3): 16:21:05 | 3 of 7 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.15s]
2021-05-19 20:21:05.105321 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:21:05.105598 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:21:05.105791 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:21:05.106044 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:21:05.106403 (Thread-2): 16:21:05 | 6 of 7 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:21:05.106675 (Thread-3): 16:21:05 | 7 of 7 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:21:05.107148 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.107409 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.107538 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:21:05.107644 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:21:05.108801 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:21:05.110004 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:21:05.110091 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-19 20:21:05.112383 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:05.112575 (Thread-2): finished collecting timing info
2021-05-19 20:21:05.112705 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:21:05.115303 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.115460 (Thread-3): finished collecting timing info
2021-05-19 20:21:05.115631 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:21:05.118095 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.118245 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.118339 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:21:05.118432 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:21:05.120196 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:05.120487 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:21:05.120593 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:21:05.121287 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.122439 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:21:05.122586 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:05.122679 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:21:05.123191 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:05.124568 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:05.124679 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.126428 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.127538 (Thread-1): finished collecting timing info
2021-05-19 20:21:05.127710 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:21:05.128262 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5d30a0>]}
2021-05-19 20:21:05.128711 (Thread-1): 16:21:05 | 1 of 7 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.18s]
2021-05-19 20:21:05.129062 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:21:05.129586 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:05.129775 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:05.131900 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.136005 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.136208 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.136351 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.136723 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.136852 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.138076 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:21:05.139468 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:21:05.140197 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.140359 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:21:05.140538 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.140694 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:21:05.140849 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:05.141024 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:05.141118 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.141232 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.141353 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:21:05.141487 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:21:05.161358 (Thread-3): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 20:21:05.163996 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.164154 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:21:05.164616 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.166565 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.166733 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:21:05.167310 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.168493 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:21:05.168614 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.168702 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:21:05.169336 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:05.170916 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:05.171037 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.172957 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.174090 (Thread-3): finished collecting timing info
2021-05-19 20:21:05.174244 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:21:05.174614 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f57a340>]}
2021-05-19 20:21:05.174924 (Thread-3): 16:21:05 | 7 of 7 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.07s]
2021-05-19 20:21:05.175066 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:21:05.807545 (Thread-2): SQL status: SELECT 1119 in 0.67 seconds
2021-05-19 20:21:05.809572 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.809677 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:21:05.929313 (Thread-4): SQL status: SELECT 6941 in 0.84 seconds
2021-05-19 20:21:05.931485 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.931590 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:21:05.931974 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.933712 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.933810 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:21:05.934288 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.935224 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:21:05.935321 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.935399 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:21:05.936242 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:05.937365 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:05.937467 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.937591 (Thread-2): SQL status: ALTER TABLE in 0.13 seconds
2021-05-19 20:21:05.939457 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.939566 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:21:05.939687 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.940631 (Thread-4): finished collecting timing info
2021-05-19 20:21:05.940768 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:05.940882 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:21:05.941798 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:21:05.942149 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f70cbe0>]}
2021-05-19 20:21:05.942243 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.942645 (Thread-4): 16:21:05 | 5 of 7 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.89s]
2021-05-19 20:21:05.942792 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:21:05.943086 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:21:05.943709 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:05.945366 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:05.945488 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:21:05.947531 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:05.948639 (Thread-2): finished collecting timing info
2021-05-19 20:21:05.948786 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:21:05.949184 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42ecc8fb-bb09-4f74-8828-5f0e0224e15d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5c09d0>]}
2021-05-19 20:21:05.949627 (Thread-2): 16:21:05 | 6 of 7 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.84s]
2021-05-19 20:21:05.949827 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:21:05.951115 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:21:05.951282 (MainThread): Using postgres connection "master".
2021-05-19 20:21:05.951370 (MainThread): On master: BEGIN
2021-05-19 20:21:05.951461 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:21:05.959702 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:21:05.959880 (MainThread): On master: COMMIT
2021-05-19 20:21:05.959978 (MainThread): Using postgres connection "master".
2021-05-19 20:21:05.960068 (MainThread): On master: COMMIT
2021-05-19 20:21:05.960264 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:05.960436 (MainThread): On master: Close
2021-05-19 20:21:05.960801 (MainThread): 16:21:05 | 
2021-05-19 20:21:05.960939 (MainThread): 16:21:05 | Finished running 7 table models in 1.10s.
2021-05-19 20:21:05.961065 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:21:05.961153 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 20:21:05.961232 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:21:05.961310 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:21:05.961387 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:21:05.965686 (MainThread): 
2021-05-19 20:21:05.965836 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 20:21:05.965954 (MainThread): 
2021-05-19 20:21:05.966069 (MainThread): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
2021-05-19 20:21:05.966171 (MainThread):   type "createdate" does not exist
2021-05-19 20:21:05.966268 (MainThread):   LINE 10: cast(to_timestamp(createDate / 1000) as createDate),
2021-05-19 20:21:05.966371 (MainThread):                                                    ^
2021-05-19 20:21:05.966465 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:21:05.966578 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-05-19 20:21:05.966748 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f70cbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f75dd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7427c0>]}
2021-05-19 20:21:05.966942 (MainThread): Flushing usage events
2021-05-19 20:21:51.549224 (MainThread): Running with dbt=0.19.1
2021-05-19 20:21:51.658147 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:21:51.659591 (MainThread): Tracking: tracking
2021-05-19 20:21:51.675795 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b43a760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4616d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b461f10>]}
2021-05-19 20:21:51.690864 (MainThread): Partial parsing not enabled
2021-05-19 20:21:51.692386 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:21:51.697342 (MainThread): Parsing macros/relations.sql
2021-05-19 20:21:51.699556 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:21:51.723521 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:21:51.726995 (MainThread): Parsing macros/core.sql
2021-05-19 20:21:51.731890 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:21:51.741954 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:21:51.744156 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:21:51.766821 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:21:51.802696 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:21:51.824737 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:21:51.827017 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:21:51.833708 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:21:51.848274 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:21:51.855512 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:21:51.862479 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:21:51.868017 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:21:51.869372 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:21:51.870669 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:21:51.872729 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:21:51.883348 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:21:51.885679 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:21:51.887636 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:21:51.931955 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:21:51.934437 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:21:51.936337 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:21:51.938612 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:21:51.947414 (MainThread): Partial parsing not enabled
2021-05-19 20:21:52.000209 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.011443 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.014842 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:52.018344 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:52.021924 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.025278 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:52.029555 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:21:52.034230 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.088773 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6b8a60>]}
2021-05-19 20:21:52.093182 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5cfd90>]}
2021-05-19 20:21:52.093443 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:21:52.094183 (MainThread): 
2021-05-19 20:21:52.094489 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:21:52.095662 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:21:52.106028 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:21:52.106138 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:21:52.106228 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:21:52.140795 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 20:21:52.143949 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:21:52.145625 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:21:52.152910 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:21:52.153072 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:21:52.153186 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:21:52.161872 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:21:52.162040 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:21:52.162148 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:21:52.165370 (ThreadPoolExecutor-1_0): SQL status: SELECT 9 in 0.00 seconds
2021-05-19 20:21:52.166142 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:21:52.166350 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:21:52.171249 (MainThread): Using postgres connection "master".
2021-05-19 20:21:52.171376 (MainThread): On master: BEGIN
2021-05-19 20:21:52.171477 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:21:52.179380 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:21:52.179543 (MainThread): Using postgres connection "master".
2021-05-19 20:21:52.179642 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:21:52.200912 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 20:21:52.201814 (MainThread): On master: ROLLBACK
2021-05-19 20:21:52.202119 (MainThread): Using postgres connection "master".
2021-05-19 20:21:52.202239 (MainThread): On master: BEGIN
2021-05-19 20:21:52.202679 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.202879 (MainThread): On master: COMMIT
2021-05-19 20:21:52.203039 (MainThread): Using postgres connection "master".
2021-05-19 20:21:52.203183 (MainThread): On master: COMMIT
2021-05-19 20:21:52.203469 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:52.203662 (MainThread): On master: Close
2021-05-19 20:21:52.204166 (MainThread): 16:21:52 | Concurrency: 4 threads (target='dev')
2021-05-19 20:21:52.204406 (MainThread): 16:21:52 | 
2021-05-19 20:21:52.207624 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:21:52.207853 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:21:52.208124 (Thread-1): 16:21:52 | 1 of 7 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:21:52.208228 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:21:52.208393 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:21:52.208688 (Thread-2): 16:21:52 | 2 of 7 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:21:52.209056 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.209279 (Thread-3): 16:21:52 | 3 of 7 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:21:52.209526 (Thread-4): 16:21:52 | 4 of 7 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:21:52.209867 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.210025 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:21:52.210430 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.210768 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:52.210910 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:21:52.212298 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:21:52.212447 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:21:52.212565 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:21:52.213685 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:21:52.215035 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:21:52.216145 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:21:52.216542 (Thread-1): finished collecting timing info
2021-05-19 20:21:52.239923 (Thread-2): finished collecting timing info
2021-05-19 20:21:52.240138 (Thread-3): finished collecting timing info
2021-05-19 20:21:52.244930 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.245230 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.245383 (Thread-4): finished collecting timing info
2021-05-19 20:21:52.247922 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.248065 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:21:52.248176 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:21:52.250666 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:52.250801 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:21:52.250924 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:21:52.251032 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:21:52.251130 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:21:52.251236 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:21:52.251688 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:21:52.261824 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:52.262041 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:52.264422 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.266520 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:52.266663 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:21:52.266767 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:21:52.266853 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:21:52.266970 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:21:52.268903 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.270876 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.271009 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.271187 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:21:52.271340 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:21:52.271493 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.282830 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:21:52.283141 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.284210 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:21:52.284285 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.285411 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:21:52.285677 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.286802 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:21:52.287043 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:52.287138 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:21:52.287420 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:21:52.287580 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.287872 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:21:52.287982 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.288083 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.288227 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.288320 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:21:52.288395 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.288490 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:21:52.288577 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.288655 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate / 1000)::date as createDate,
--to_timestamp(dateScanned / 1000)::date as dateScanned,
--to_timestamp(finishedDate / 1000)::date as finishedDate,
--to_timestamp(modifyDate / 1000)::date as modifyDate,
--as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
--as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:21:52.288737 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.288874 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:21:52.289031 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.289140 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:21:52.289315 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.289470 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:21:52.289784 (Thread-4): Postgres error: operator does not exist: character varying / integer
LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

2021-05-19 20:21:52.289897 (Thread-4): On model.fetch_takehome.fact_receipts: ROLLBACK
2021-05-19 20:21:52.290135 (Thread-4): finished collecting timing info
2021-05-19 20:21:52.290284 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:21:52.290640 (Thread-4): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  operator does not exist: character varying / integer
  LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedFunction: operator does not exist: character varying / integer
LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  operator does not exist: character varying / integer
  LINE 10: to_timestamp(createDate / 1000)::date as createDate,
                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:21:52.298631 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7fab20>]}
2021-05-19 20:21:52.298949 (Thread-4): 16:21:52 | 4 of 7 ERROR creating table model fetch_takehome.fact_receipts....... [ERROR in 0.09s]
2021-05-19 20:21:52.299088 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:21:52.299215 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:21:52.299504 (Thread-4): 16:21:52 | 5 of 7 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:21:52.299774 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:52.299877 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:21:52.300923 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:21:52.301216 (Thread-4): finished collecting timing info
2021-05-19 20:21:52.303351 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:52.303445 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:21:52.303532 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:21:52.308404 (Thread-2): SQL status: SELECT 1167 in 0.02 seconds
2021-05-19 20:21:52.314957 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.315092 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:21:52.315538 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.317291 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.317393 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:21:52.317514 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:52.319076 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:52.319173 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:21:52.319289 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.325427 (Thread-3): SQL status: SELECT 6941 in 0.04 seconds
2021-05-19 20:21:52.325319 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:21:52.325601 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:52.327469 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.327590 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.328642 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:21:52.328745 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:21:52.328876 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:21:52.329331 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:52.329425 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:21:52.329543 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.329641 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.331376 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.331479 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:52.331563 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:21:52.331645 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:21:52.332050 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.332959 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:21:52.333056 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.333134 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:21:52.336991 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-05-19 20:21:52.340198 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:21:52.340325 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:21:52.340430 (Thread-3): SQL status: COMMIT in 0.01 seconds
2021-05-19 20:21:52.341620 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:21:52.341727 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:21:52.342508 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.343568 (Thread-2): finished collecting timing info
2021-05-19 20:21:52.343707 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:21:52.344098 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7dadc0>]}
2021-05-19 20:21:52.344197 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.344576 (Thread-2): 16:21:52 | 2 of 7 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.13s]
2021-05-19 20:21:52.345728 (Thread-3): finished collecting timing info
2021-05-19 20:21:52.345823 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-19 20:21:52.346009 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:21:52.346123 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:21:52.348227 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.348391 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:21:52.348842 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7dafd0>]}
2021-05-19 20:21:52.348923 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:21:52.349145 (Thread-2): 16:21:52 | 6 of 7 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:21:52.349423 (Thread-3): 16:21:52 | 3 of 7 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.14s]
2021-05-19 20:21:52.349873 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:52.350028 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:21:52.350197 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:21:52.350293 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.350442 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:21:52.351571 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:21:52.353832 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.354082 (Thread-3): 16:21:52 | 7 of 7 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:21:52.354329 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:21:52.354649 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.355019 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:21:52.356366 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:21:52.356526 (Thread-2): finished collecting timing info
2021-05-19 20:21:52.356652 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.359327 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:52.360805 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:21:52.361140 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:21:52.361335 (Thread-3): finished collecting timing info
2021-05-19 20:21:52.361474 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.361633 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:21:52.364440 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.364692 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:21:52.365038 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:21:52.365285 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:21:52.365651 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:52.367466 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:21:52.367614 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:21:52.370225 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.371427 (Thread-1): finished collecting timing info
2021-05-19 20:21:52.371660 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:21:52.372018 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7e60a0>]}
2021-05-19 20:21:52.372324 (Thread-1): 16:21:52 | 1 of 7 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.16s]
2021-05-19 20:21:52.372460 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:21:52.374439 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:21:52.376638 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.376763 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:21:52.376907 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:21:52.378850 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:52.378975 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:21:52.379123 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.380316 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:21:52.380551 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.383250 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:21:52.383606 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.383728 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:21:52.384036 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.384222 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:52.384344 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.384484 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:21:52.384603 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:21:52.384941 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:21:52.385098 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:52.385233 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:21:52.399790 (Thread-3): SQL status: SELECT 495 in 0.01 seconds
2021-05-19 20:21:52.401692 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.401791 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:21:52.402136 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.403880 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.403979 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:21:52.404364 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:52.405303 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:21:52.405405 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.405483 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:21:52.406012 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:52.407235 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:21:52.407326 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:21:52.408840 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:52.409756 (Thread-3): finished collecting timing info
2021-05-19 20:21:52.409883 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:21:52.410175 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8efca0>]}
2021-05-19 20:21:52.410428 (Thread-3): 16:21:52 | 7 of 7 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-19 20:21:52.410545 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:21:53.038525 (Thread-2): SQL status: SELECT 1119 in 0.65 seconds
2021-05-19 20:21:53.040577 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:53.040686 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:21:53.175624 (Thread-4): SQL status: SELECT 6941 in 0.84 seconds
2021-05-19 20:21:53.177724 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:53.177830 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:21:53.178170 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:53.179657 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:53.179745 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:21:53.180139 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:53.181076 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:21:53.181168 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:53.181240 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:21:53.181812 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:53.182873 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:21:53.182974 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:21:53.183090 (Thread-2): SQL status: ALTER TABLE in 0.14 seconds
2021-05-19 20:21:53.184741 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:53.184832 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:21:53.184947 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:53.185836 (Thread-4): finished collecting timing info
2021-05-19 20:21:53.185967 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:21:53.186086 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:21:53.186452 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8dd2e0>]}
2021-05-19 20:21:53.187362 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:21:53.187663 (Thread-4): 16:21:53 | 5 of 7 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.89s]
2021-05-19 20:21:53.187762 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:53.187936 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:21:53.188024 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:21:53.188690 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:53.189874 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:21:53.189966 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:21:53.192255 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:21:53.193535 (Thread-2): finished collecting timing info
2021-05-19 20:21:53.193682 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:21:53.193995 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65064c54-f3a6-42ae-b3ca-fa5511e94e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7dac10>]}
2021-05-19 20:21:53.194288 (Thread-2): 16:21:53 | 6 of 7 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.84s]
2021-05-19 20:21:53.194412 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:21:53.195526 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:21:53.195674 (MainThread): Using postgres connection "master".
2021-05-19 20:21:53.195762 (MainThread): On master: BEGIN
2021-05-19 20:21:53.195855 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:21:53.204144 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:21:53.204337 (MainThread): On master: COMMIT
2021-05-19 20:21:53.204445 (MainThread): Using postgres connection "master".
2021-05-19 20:21:53.204540 (MainThread): On master: COMMIT
2021-05-19 20:21:53.204748 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:21:53.204873 (MainThread): On master: Close
2021-05-19 20:21:53.205246 (MainThread): 16:21:53 | 
2021-05-19 20:21:53.205383 (MainThread): 16:21:53 | Finished running 7 table models in 1.11s.
2021-05-19 20:21:53.205529 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:21:53.205623 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 20:21:53.205707 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:21:53.205785 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:21:53.205863 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:21:53.210524 (MainThread): 
2021-05-19 20:21:53.210716 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 20:21:53.210894 (MainThread): 
2021-05-19 20:21:53.211045 (MainThread): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
2021-05-19 20:21:53.211182 (MainThread):   operator does not exist: character varying / integer
2021-05-19 20:21:53.211288 (MainThread):   LINE 10: to_timestamp(createDate / 1000)::date as createDate,
2021-05-19 20:21:53.211387 (MainThread):                                    ^
2021-05-19 20:21:53.211490 (MainThread):   HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2021-05-19 20:21:53.211586 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:21:53.211702 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-05-19 20:21:53.211898 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b92bcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4adf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7e6220>]}
2021-05-19 20:21:53.212118 (MainThread): Flushing usage events
2021-05-19 20:22:14.072831 (MainThread): Running with dbt=0.19.1
2021-05-19 20:22:14.172866 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:22:14.174301 (MainThread): Tracking: tracking
2021-05-19 20:22:14.194394 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b6bc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b885b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b88df0>]}
2021-05-19 20:22:14.209839 (MainThread): Partial parsing not enabled
2021-05-19 20:22:14.211715 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:22:14.216458 (MainThread): Parsing macros/relations.sql
2021-05-19 20:22:14.218615 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:22:14.244107 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:22:14.248442 (MainThread): Parsing macros/core.sql
2021-05-19 20:22:14.253735 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:22:14.265145 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:22:14.267476 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:22:14.288630 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:22:14.326500 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:22:14.348324 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:22:14.350505 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:22:14.357845 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:22:14.373655 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:22:14.380943 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:22:14.387808 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:22:14.393376 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:22:14.394584 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:22:14.395854 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:22:14.397715 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:22:14.408270 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:22:14.410838 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:22:14.412924 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:22:14.457241 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:22:14.459446 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:22:14.461281 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:22:14.463186 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:22:14.470718 (MainThread): Partial parsing not enabled
2021-05-19 20:22:14.526615 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.538245 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.541924 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:14.545557 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:14.549282 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.552730 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:22:14.557193 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:22:14.561460 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.615379 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dd3c70>]}
2021-05-19 20:22:14.620208 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cef910>]}
2021-05-19 20:22:14.620475 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:22:14.621215 (MainThread): 
2021-05-19 20:22:14.621521 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:22:14.622683 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:22:14.633041 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:22:14.633171 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:22:14.633270 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:22:14.669736 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-19 20:22:14.673127 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:22:14.674735 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:22:14.681507 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:22:14.681661 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:22:14.681775 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:22:14.690726 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:22:14.690946 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:22:14.691090 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:22:14.694550 (ThreadPoolExecutor-1_0): SQL status: SELECT 9 in 0.00 seconds
2021-05-19 20:22:14.695408 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:22:14.695682 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:22:14.701056 (MainThread): Using postgres connection "master".
2021-05-19 20:22:14.701212 (MainThread): On master: BEGIN
2021-05-19 20:22:14.701323 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:22:14.709638 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:22:14.709803 (MainThread): Using postgres connection "master".
2021-05-19 20:22:14.709904 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:22:14.730257 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 20:22:14.730968 (MainThread): On master: ROLLBACK
2021-05-19 20:22:14.731212 (MainThread): Using postgres connection "master".
2021-05-19 20:22:14.731314 (MainThread): On master: BEGIN
2021-05-19 20:22:14.731608 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.731732 (MainThread): On master: COMMIT
2021-05-19 20:22:14.731833 (MainThread): Using postgres connection "master".
2021-05-19 20:22:14.731916 (MainThread): On master: COMMIT
2021-05-19 20:22:14.732095 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:14.732210 (MainThread): On master: Close
2021-05-19 20:22:14.732495 (MainThread): 16:22:14 | Concurrency: 4 threads (target='dev')
2021-05-19 20:22:14.732629 (MainThread): 16:22:14 | 
2021-05-19 20:22:14.735142 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:22:14.735425 (Thread-1): 16:22:14 | 1 of 7 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:22:14.735598 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:22:14.735787 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:22:14.736004 (Thread-2): 16:22:14 | 2 of 7 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:22:14.736102 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:22:14.736380 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.736598 (Thread-3): 16:22:14 | 3 of 7 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:22:14.736883 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.737091 (Thread-4): 16:22:14 | 4 of 7 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:22:14.737225 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:22:14.737485 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.737605 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:22:14.737861 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:22:14.739166 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:22:14.739328 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:22:14.740489 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:22:14.740622 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:22:14.742089 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:22:14.743426 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:22:14.743808 (Thread-1): finished collecting timing info
2021-05-19 20:22:14.763350 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.763479 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:22:14.763570 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:22:14.763851 (Thread-4): finished collecting timing info
2021-05-19 20:22:14.763999 (Thread-2): finished collecting timing info
2021-05-19 20:22:14.766385 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:22:14.766542 (Thread-3): finished collecting timing info
2021-05-19 20:22:14.768728 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.768873 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:22:14.771063 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.771269 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:22:14.771398 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:22:14.771487 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:22:14.771577 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:22:14.771691 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:22:14.771959 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:22:14.774983 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.775316 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:22:14.775719 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.786973 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:22:14.787338 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:22:14.789510 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.789669 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:22:14.789883 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:22:14.790026 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.790121 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:22:14.791985 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.793429 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:22:14.793608 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.795537 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:22:14.795658 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:22:14.795927 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:22:14.796120 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:22:14.796392 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.796598 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.796750 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.796900 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.796999 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:22:14.798257 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:22:14.798387 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.799536 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:22:14.799864 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:22:14.799999 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.800416 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.800686 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.800878 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:22:14.800969 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:22:14.801076 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:22:14.801184 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:22:14.801482 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.801616 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.801703 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.801823 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:22:14.801950 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:22:14.802091 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate)::date as createDate,
--to_timestamp(dateScanned / 1000)::date as dateScanned,
--to_timestamp(finishedDate / 1000)::date as finishedDate,
--to_timestamp(modifyDate / 1000)::date as modifyDate,
--as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
--as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:22:14.802855 (Thread-4): Postgres error: function to_timestamp(character varying) does not exist
LINE 10: to_timestamp(createDate)::date as createDate,
         ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.

2021-05-19 20:22:14.802986 (Thread-4): On model.fetch_takehome.fact_receipts: ROLLBACK
2021-05-19 20:22:14.803229 (Thread-4): finished collecting timing info
2021-05-19 20:22:14.803374 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:22:14.803702 (Thread-4): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  function to_timestamp(character varying) does not exist
  LINE 10: to_timestamp(createDate)::date as createDate,
           ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedFunction: function to_timestamp(character varying) does not exist
LINE 10: to_timestamp(createDate)::date as createDate,
         ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
  function to_timestamp(character varying) does not exist
  LINE 10: to_timestamp(createDate)::date as createDate,
           ^
  HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:22:14.811299 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f27850>]}
2021-05-19 20:22:14.811629 (Thread-4): 16:22:14 | 4 of 7 ERROR creating table model fetch_takehome.fact_receipts....... [ERROR in 0.07s]
2021-05-19 20:22:14.811770 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:22:14.811915 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:22:14.812121 (Thread-4): 16:22:14 | 5 of 7 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:22:14.812562 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:14.812689 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:22:14.814115 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:22:14.814870 (Thread-4): finished collecting timing info
2021-05-19 20:22:14.817354 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:14.817471 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:22:14.817572 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:22:14.823812 (Thread-2): SQL status: SELECT 1167 in 0.02 seconds
2021-05-19 20:22:14.831938 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.832094 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:22:14.832252 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:22:14.834226 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:14.834345 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:22:14.834490 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.834617 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.836591 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.838048 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:22:14.838172 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:22:14.838669 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:14.838770 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:22:14.838895 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.839016 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.845318 (Thread-3): SQL status: SELECT 6941 in 0.04 seconds
2021-05-19 20:22:14.845658 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:22:14.845814 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:14.848016 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:22:14.847892 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.847760 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.848337 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:22:14.848225 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:22:14.848780 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.851308 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.851442 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:22:14.851570 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:14.854414 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:22:14.854553 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:22:14.854682 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.855895 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:22:14.856029 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.856119 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:22:14.856604 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:14.857916 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:22:14.858038 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.858151 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:22:14.859351 (Thread-2): finished collecting timing info
2021-05-19 20:22:14.859621 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:22:14.860090 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f00cd0>]}
2021-05-19 20:22:14.860415 (Thread-2): 16:22:14 | 2 of 7 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.12s]
2021-05-19 20:22:14.860563 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:22:14.860705 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:22:14.861065 (Thread-2): 16:22:14 | 6 of 7 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:22:14.861366 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:14.861486 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:22:14.862874 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:22:14.863085 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.864206 (Thread-3): finished collecting timing info
2021-05-19 20:22:14.864355 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:22:14.864759 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f00f10>]}
2021-05-19 20:22:14.865094 (Thread-3): 16:22:14 | 3 of 7 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.13s]
2021-05-19 20:22:14.865223 (Thread-2): finished collecting timing info
2021-05-19 20:22:14.865413 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:22:14.868042 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:14.868186 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-19 20:22:14.868327 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:22:14.868533 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:22:14.870556 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.870771 (Thread-3): 16:22:14 | 7 of 7 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:22:14.870885 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:22:14.870980 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:22:14.871315 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.871764 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:22:14.873020 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:22:14.873156 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.875635 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.875784 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:22:14.876133 (Thread-3): finished collecting timing info
2021-05-19 20:22:14.876269 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.878876 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.880096 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:22:14.880302 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:22:14.880441 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.880579 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:22:14.880696 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:22:14.880785 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:22:14.883078 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:14.883232 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:14.883323 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:22:14.884786 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:22:14.885002 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:22:14.885133 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.886571 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:22:14.887079 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:14.887196 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:22:14.887533 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.887663 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:14.887758 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:22:14.887931 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.889293 (Thread-1): finished collecting timing info
2021-05-19 20:22:14.889470 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:22:14.889929 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108daf790>]}
2021-05-19 20:22:14.890260 (Thread-1): 16:22:14 | 1 of 7 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.15s]
2021-05-19 20:22:14.890368 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:22:14.890609 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:22:14.894683 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.895056 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:22:14.895406 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.896665 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:22:14.897262 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.897418 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:22:14.897689 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:22:14.897800 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.897885 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:22:14.913656 (Thread-3): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 20:22:14.915637 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.915743 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:22:14.916211 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.918027 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.918138 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:22:14.918558 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:14.919654 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:22:14.919798 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.919906 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:22:14.920519 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:14.921883 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:22:14.922013 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:22:14.923733 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:14.924770 (Thread-3): finished collecting timing info
2021-05-19 20:22:14.924919 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:22:14.925331 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109043160>]}
2021-05-19 20:22:14.925804 (Thread-3): 16:22:14 | 7 of 7 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.05s]
2021-05-19 20:22:14.925981 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:22:15.575550 (Thread-2): SQL status: SELECT 1119 in 0.69 seconds
2021-05-19 20:22:15.577656 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:15.577763 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:22:15.716596 (Thread-4): SQL status: SELECT 6941 in 0.87 seconds
2021-05-19 20:22:15.718613 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:15.718711 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:22:15.719060 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:15.720574 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:15.720696 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:22:15.721099 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:15.722068 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:22:15.722159 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:15.722232 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:22:15.722945 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:15.724056 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:22:15.724156 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:22:15.724274 (Thread-2): SQL status: ALTER TABLE in 0.15 seconds
2021-05-19 20:22:15.726090 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:15.726203 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:22:15.726300 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:15.727242 (Thread-4): finished collecting timing info
2021-05-19 20:22:15.727366 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:22:15.727471 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:22:15.727796 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ee4fd0>]}
2021-05-19 20:22:15.728640 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:22:15.728936 (Thread-4): 16:22:15 | 5 of 7 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.92s]
2021-05-19 20:22:15.729033 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:15.729151 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:22:15.729247 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:22:15.734324 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:15.735515 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:22:15.735605 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:22:15.737747 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:22:15.738930 (Thread-2): finished collecting timing info
2021-05-19 20:22:15.739063 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:22:15.739367 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1165362-f10f-48b4-a2cc-c9f727510019', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f00670>]}
2021-05-19 20:22:15.739624 (Thread-2): 16:22:15 | 6 of 7 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.88s]
2021-05-19 20:22:15.739739 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:22:15.740833 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:22:15.740980 (MainThread): Using postgres connection "master".
2021-05-19 20:22:15.741059 (MainThread): On master: BEGIN
2021-05-19 20:22:15.741142 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:22:15.748586 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:22:15.748759 (MainThread): On master: COMMIT
2021-05-19 20:22:15.748854 (MainThread): Using postgres connection "master".
2021-05-19 20:22:15.748962 (MainThread): On master: COMMIT
2021-05-19 20:22:15.749172 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:22:15.749306 (MainThread): On master: Close
2021-05-19 20:22:15.749658 (MainThread): 16:22:15 | 
2021-05-19 20:22:15.749785 (MainThread): 16:22:15 | Finished running 7 table models in 1.13s.
2021-05-19 20:22:15.749915 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:22:15.750043 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 20:22:15.750129 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:22:15.750208 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:22:15.750282 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:22:15.754848 (MainThread): 
2021-05-19 20:22:15.754998 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 20:22:15.755116 (MainThread): 
2021-05-19 20:22:15.755225 (MainThread): Database Error in model fact_receipts (models/transformations/fact_receipts.sql)
2021-05-19 20:22:15.755323 (MainThread):   function to_timestamp(character varying) does not exist
2021-05-19 20:22:15.755415 (MainThread):   LINE 10: to_timestamp(createDate)::date as createDate,
2021-05-19 20:22:15.755511 (MainThread):            ^
2021-05-19 20:22:15.755601 (MainThread):   HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2021-05-19 20:22:15.755689 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_receipts.sql
2021-05-19 20:22:15.755797 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-05-19 20:22:15.755965 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cdd2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108be4e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ef9100>]}
2021-05-19 20:22:15.756152 (MainThread): Flushing usage events
2021-05-19 20:32:16.668645 (MainThread): Running with dbt=0.19.1
2021-05-19 20:32:16.772116 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:32:16.773294 (MainThread): Tracking: tracking
2021-05-19 20:32:16.789294 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a20cee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a231670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a231eb0>]}
2021-05-19 20:32:16.803655 (MainThread): Partial parsing not enabled
2021-05-19 20:32:16.805104 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:32:16.809602 (MainThread): Parsing macros/relations.sql
2021-05-19 20:32:16.811759 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:32:16.834968 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:32:16.838233 (MainThread): Parsing macros/core.sql
2021-05-19 20:32:16.842873 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:32:16.852597 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:32:16.854672 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:32:16.873756 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:32:16.907957 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:32:16.929506 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:32:16.931573 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:32:16.938090 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:32:16.952352 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:32:16.960076 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:32:16.967064 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:32:16.972817 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:32:16.974268 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:32:16.975609 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:32:16.977600 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:32:16.988227 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:32:16.990671 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:32:16.992793 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:32:17.035932 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:32:17.038037 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:32:17.039763 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:32:17.041578 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:32:17.048873 (MainThread): Partial parsing not enabled
2021-05-19 20:32:17.102674 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.113881 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.117186 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:17.120508 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:17.123975 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.127202 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.131274 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:32:17.135589 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.183320 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4b7c10>]}
2021-05-19 20:32:17.186861 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a39c640>]}
2021-05-19 20:32:17.187203 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:32:17.187824 (MainThread): 
2021-05-19 20:32:17.188076 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:32:17.189010 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:32:17.197757 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:32:17.197857 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:32:17.197974 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:32:17.225763 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 20:32:17.228887 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:32:17.230389 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:32:17.236622 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:32:17.236741 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:32:17.236842 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:32:17.244897 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:32:17.245062 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:32:17.245158 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:32:17.248062 (ThreadPoolExecutor-1_0): SQL status: SELECT 9 in 0.00 seconds
2021-05-19 20:32:17.248813 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:32:17.249026 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:32:17.253763 (MainThread): Using postgres connection "master".
2021-05-19 20:32:17.253888 (MainThread): On master: BEGIN
2021-05-19 20:32:17.253988 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:32:17.261930 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:32:17.262101 (MainThread): Using postgres connection "master".
2021-05-19 20:32:17.262199 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:32:17.280469 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 20:32:17.280999 (MainThread): On master: ROLLBACK
2021-05-19 20:32:17.281187 (MainThread): Using postgres connection "master".
2021-05-19 20:32:17.281270 (MainThread): On master: BEGIN
2021-05-19 20:32:17.281522 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.281627 (MainThread): On master: COMMIT
2021-05-19 20:32:17.281708 (MainThread): Using postgres connection "master".
2021-05-19 20:32:17.281779 (MainThread): On master: COMMIT
2021-05-19 20:32:17.281924 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:17.282021 (MainThread): On master: Close
2021-05-19 20:32:17.282264 (MainThread): 16:32:17 | Concurrency: 4 threads (target='dev')
2021-05-19 20:32:17.282378 (MainThread): 16:32:17 | 
2021-05-19 20:32:17.284557 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:32:17.284793 (Thread-1): 16:32:17 | 1 of 7 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:32:17.285046 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.285157 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:32:17.286156 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:32:17.286348 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:32:17.286559 (Thread-2): 16:32:17 | 2 of 7 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:32:17.286706 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:32:17.286906 (Thread-3): 16:32:17 | 3 of 7 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:32:17.287245 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.287350 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:32:17.288218 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:32:17.288371 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:32:17.288566 (Thread-4): 16:32:17 | 4 of 7 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:32:17.288863 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.288977 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:32:17.289945 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:32:17.290288 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.290393 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:32:17.290505 (Thread-1): finished collecting timing info
2021-05-19 20:32:17.291594 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:32:17.297260 (Thread-3): finished collecting timing info
2021-05-19 20:32:17.297408 (Thread-2): finished collecting timing info
2021-05-19 20:32:17.308966 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.311102 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.313128 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.313245 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:32:17.313319 (Thread-4): finished collecting timing info
2021-05-19 20:32:17.313450 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:32:17.313536 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:32:17.313623 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:32:17.315588 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.315701 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:32:17.315786 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:32:17.316036 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:32:17.316392 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:32:17.324664 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.326630 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.326757 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:32:17.326915 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.327074 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.328582 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.328742 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.338396 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:32:17.338490 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:32:17.338561 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:32:17.340188 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.342068 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.342178 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:32:17.342274 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.342336 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.342422 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:32:17.342567 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:32:17.342673 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.343693 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:32:17.344810 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:32:17.344991 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.345068 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.345385 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.346379 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:32:17.346580 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.346706 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:32:17.346829 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.347088 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:32:17.347334 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.347444 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.347522 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:32:17.347698 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:32:17.347799 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.347999 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:32:17.348087 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.348158 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.348313 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.348400 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.348497 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:32:17.348597 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:32:17.356899 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-19 20:32:17.362627 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.362753 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:32:17.362939 (Thread-4): SQL status: SELECT 1119 in 0.01 seconds
2021-05-19 20:32:17.365064 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.365191 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-19 20:32:17.365322 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.366985 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.367085 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:32:17.368218 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.374066 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:32:17.374182 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.374260 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:32:17.374376 (Thread-2): SQL status: ALTER TABLE in 0.01 seconds
2021-05-19 20:32:17.375296 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:32:17.375392 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.375469 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:32:17.375584 (Thread-3): SQL status: SELECT 6941 in 0.03 seconds
2021-05-19 20:32:17.377282 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.377380 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:32:17.377493 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:17.380183 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:32:17.380282 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:32:17.380400 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:17.380509 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.381626 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:32:17.381703 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.383311 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.383411 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:32:17.384250 (Thread-4): finished collecting timing info
2021-05-19 20:32:17.384401 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:32:17.384588 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:32:17.384987 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5fb460>]}
2021-05-19 20:32:17.385255 (Thread-4): 16:32:17 | 4 of 7 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.09s]
2021-05-19 20:32:17.385346 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.385550 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:32:17.386606 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:32:17.386751 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:32:17.386956 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.387144 (Thread-4): 16:32:17 | 5 of 7 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:32:17.387234 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:32:17.387499 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:17.387644 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:32:17.388645 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:32:17.388828 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:17.390095 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:32:17.390247 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.390375 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:32:17.391430 (Thread-2): finished collecting timing info
2021-05-19 20:32:17.391619 (Thread-4): finished collecting timing info
2021-05-19 20:32:17.391743 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:32:17.393848 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:17.394030 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-19 20:32:17.394289 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5de850>]}
2021-05-19 20:32:17.394385 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:32:17.396278 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.396590 (Thread-2): 16:32:17 | 2 of 7 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.11s]
2021-05-19 20:32:17.396681 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.396801 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:32:17.396888 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:32:17.397061 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:32:17.397958 (Thread-3): finished collecting timing info
2021-05-19 20:32:17.398354 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:32:17.398573 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:32:17.398690 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.398892 (Thread-2): 16:32:17 | 6 of 7 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:32:17.399288 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4e5e50>]}
2021-05-19 20:32:17.401108 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.401388 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:17.401668 (Thread-3): 16:32:17 | 3 of 7 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.11s]
2021-05-19 20:32:17.401761 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:32:17.401866 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:32:17.401986 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:32:17.403231 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:32:17.403388 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:32:17.403482 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.403840 (Thread-3): 16:32:17 | 7 of 7 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:32:17.404858 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:32:17.405330 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.405417 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.405492 (Thread-2): finished collecting timing info
2021-05-19 20:32:17.405603 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.405716 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:32:17.405886 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:32:17.408549 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:17.410598 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:17.411807 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:32:17.412050 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:32:17.412177 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:32:17.412405 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:17.412505 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:32:17.412753 (Thread-3): finished collecting timing info
2021-05-19 20:32:17.413982 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:32:17.414093 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.417879 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.418029 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:32:17.419198 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:32:17.419319 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:32:17.419664 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:32:17.420254 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:17.420435 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:32:17.420787 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.420909 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:17.421005 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:32:17.422221 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.425405 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:17.425606 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:32:17.426020 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.426151 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.427539 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:32:17.428671 (Thread-1): finished collecting timing info
2021-05-19 20:32:17.429051 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:32:17.429668 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4de100>]}
2021-05-19 20:32:17.429828 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:32:17.430228 (Thread-1): 16:32:17 | 1 of 7 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.14s]
2021-05-19 20:32:17.432339 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.432563 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:17.432703 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:32:17.432827 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:32:17.432930 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:32:17.433365 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.434617 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:32:17.434828 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.435051 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:17.435202 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:32:17.435367 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.435549 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:32:17.435808 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:32:17.435921 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.436010 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:32:17.451665 (Thread-3): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 20:32:17.453753 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.453860 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:32:17.454252 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.455850 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.455947 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:32:17.456401 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:17.457681 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:32:17.457804 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.457882 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:32:17.458480 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:17.459661 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:32:17.459753 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:32:17.461465 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:17.462448 (Thread-3): finished collecting timing info
2021-05-19 20:32:17.462576 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:32:17.462921 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a45b7f0>]}
2021-05-19 20:32:17.463188 (Thread-3): 16:32:17 | 7 of 7 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-19 20:32:17.463306 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:32:18.069625 (Thread-2): SQL status: SELECT 1119 in 0.63 seconds
2021-05-19 20:32:18.071794 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:18.071902 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:32:18.242688 (Thread-4): SQL status: SELECT 6941 in 0.82 seconds
2021-05-19 20:32:18.244616 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:18.244716 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:32:18.245121 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:18.246896 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:18.246999 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:32:18.247485 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:18.248376 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:32:18.248467 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:18.248539 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:32:18.249140 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:18.250351 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:32:18.250446 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:32:18.250565 (Thread-2): SQL status: ALTER TABLE in 0.18 seconds
2021-05-19 20:32:18.252200 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:18.252296 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:32:18.252453 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:18.253371 (Thread-4): finished collecting timing info
2021-05-19 20:32:18.253498 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:32:18.253828 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a68f5b0>]}
2021-05-19 20:32:18.254102 (Thread-4): 16:32:18 | 5 of 7 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 0.87s]
2021-05-19 20:32:18.254224 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:32:18.254374 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:32:18.255380 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:32:18.255561 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:18.255664 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:32:18.256245 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:18.257778 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:32:18.257891 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:32:18.260327 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:32:18.261492 (Thread-2): finished collecting timing info
2021-05-19 20:32:18.261643 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:32:18.261989 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '187fcd24-fe94-44ad-a272-b7b2515533fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5bef40>]}
2021-05-19 20:32:18.262304 (Thread-2): 16:32:18 | 6 of 7 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.86s]
2021-05-19 20:32:18.262444 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:32:18.263583 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:32:18.263739 (MainThread): Using postgres connection "master".
2021-05-19 20:32:18.263835 (MainThread): On master: BEGIN
2021-05-19 20:32:18.263932 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:32:18.272028 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:32:18.272199 (MainThread): On master: COMMIT
2021-05-19 20:32:18.272292 (MainThread): Using postgres connection "master".
2021-05-19 20:32:18.272376 (MainThread): On master: COMMIT
2021-05-19 20:32:18.272566 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:32:18.272682 (MainThread): On master: Close
2021-05-19 20:32:18.273030 (MainThread): 16:32:18 | 
2021-05-19 20:32:18.273160 (MainThread): 16:32:18 | Finished running 7 table models in 1.09s.
2021-05-19 20:32:18.273264 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:32:18.273345 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-19 20:32:18.273423 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:32:18.273496 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:32:18.273569 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:32:18.277857 (MainThread): 
2021-05-19 20:32:18.278014 (MainThread): Completed successfully
2021-05-19 20:32:18.278147 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2021-05-19 20:32:18.278324 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a36b400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a605670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5b41c0>]}
2021-05-19 20:32:18.278512 (MainThread): Flushing usage events
2021-05-19 20:37:55.001711 (MainThread): Running with dbt=0.19.1
2021-05-19 20:37:55.111406 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:37:55.112745 (MainThread): Tracking: tracking
2021-05-19 20:37:55.129381 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107103100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071285b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107128df0>]}
2021-05-19 20:37:55.145492 (MainThread): Partial parsing not enabled
2021-05-19 20:37:55.146730 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:37:55.151396 (MainThread): Parsing macros/relations.sql
2021-05-19 20:37:55.153572 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:37:55.181728 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:37:55.185632 (MainThread): Parsing macros/core.sql
2021-05-19 20:37:55.190928 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:37:55.202880 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:37:55.205310 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:37:55.230712 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:37:55.276164 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:37:55.304046 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:37:55.306680 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:37:55.315285 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:37:55.333212 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:37:55.342013 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:37:55.349741 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:37:55.355155 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:37:55.356229 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:37:55.357386 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:37:55.359107 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:37:55.368840 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:37:55.370890 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:37:55.372590 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:37:55.417269 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:37:55.419260 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:37:55.420826 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:37:55.422574 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:37:55.430365 (MainThread): Partial parsing not enabled
2021-05-19 20:37:55.485532 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.497405 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:55.500866 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:55.505090 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:55.509864 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.513560 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.518709 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:37:55.522434 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.581419 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107377c70>]}
2021-05-19 20:37:55.586470 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107288910>]}
2021-05-19 20:37:55.586780 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:37:55.587633 (MainThread): 
2021-05-19 20:37:55.587988 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:37:55.589406 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:37:55.603427 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:37:55.603591 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:37:55.603709 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:37:55.651576 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.05 seconds
2021-05-19 20:37:55.654366 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:37:55.656039 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:37:55.664094 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:37:55.664266 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:37:55.664439 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:37:55.673699 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:37:55.673968 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:37:55.674140 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:37:55.678226 (ThreadPoolExecutor-1_0): SQL status: SELECT 10 in 0.00 seconds
2021-05-19 20:37:55.679115 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:37:55.679376 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:37:55.685088 (MainThread): Using postgres connection "master".
2021-05-19 20:37:55.685256 (MainThread): On master: BEGIN
2021-05-19 20:37:55.685377 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:37:55.694736 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:37:55.694934 (MainThread): Using postgres connection "master".
2021-05-19 20:37:55.695040 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:37:55.720959 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-19 20:37:55.721603 (MainThread): On master: ROLLBACK
2021-05-19 20:37:55.721872 (MainThread): Using postgres connection "master".
2021-05-19 20:37:55.721984 (MainThread): On master: BEGIN
2021-05-19 20:37:55.722285 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.722483 (MainThread): On master: COMMIT
2021-05-19 20:37:55.722600 (MainThread): Using postgres connection "master".
2021-05-19 20:37:55.722703 (MainThread): On master: COMMIT
2021-05-19 20:37:55.722947 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:55.723103 (MainThread): On master: Close
2021-05-19 20:37:55.723519 (MainThread): 16:37:55 | Concurrency: 4 threads (target='dev')
2021-05-19 20:37:55.723751 (MainThread): 16:37:55 | 
2021-05-19 20:37:55.727200 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:37:55.727448 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:37:55.727720 (Thread-1): 16:37:55 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:37:55.727859 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:37:55.728104 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:37:55.728439 (Thread-2): 16:37:55 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:37:55.728976 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.729249 (Thread-3): 16:37:55 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:37:55.729502 (Thread-4): 16:37:55 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:37:55.729851 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.730014 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:37:55.730358 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.730681 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.730880 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:37:55.732909 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:37:55.733121 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:37:55.733318 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:37:55.734946 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:37:55.736502 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:37:55.739253 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:37:55.739823 (Thread-1): finished collecting timing info
2021-05-19 20:37:55.740332 (Thread-2): finished collecting timing info
2021-05-19 20:37:55.767962 (Thread-3): finished collecting timing info
2021-05-19 20:37:55.790755 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.793929 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.794081 (Thread-4): finished collecting timing info
2021-05-19 20:37:55.794644 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.794906 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:37:55.795073 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:37:55.797947 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.798112 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:37:55.798242 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:37:55.798349 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:37:55.798453 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:37:55.798557 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:37:55.799068 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:37:55.809646 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:37:55.812432 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.812605 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:37:55.812792 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:37:55.812919 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:37:55.815837 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.816068 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:37:55.818783 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.819066 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:37:55.819226 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.821568 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.821720 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:37:55.827700 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:37:55.836771 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:37:55.836903 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:37:55.838715 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:37:55.838898 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.839214 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.840725 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:37:55.841057 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.842513 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:37:55.842855 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.842988 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:37:55.843307 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.843391 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:37:55.843769 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:37:55.843920 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.844062 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.844287 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.844474 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.844579 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:37:55.844655 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.844768 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:37:55.844879 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.845043 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.845205 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.845347 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:37:55.845485 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:37:55.845607 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.845890 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:37:55.852514 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-19 20:37:55.860084 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.860253 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:37:55.860405 (Thread-4): SQL status: SELECT 1119 in 0.01 seconds
2021-05-19 20:37:55.862900 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.863069 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-19 20:37:55.863237 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:55.867893 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.868142 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:55.868302 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:37:55.870933 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.871180 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-19 20:37:55.871646 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:55.878146 (Thread-3): SQL status: SELECT 6941 in 0.03 seconds
2021-05-19 20:37:55.878330 (Thread-4): SQL status: ALTER TABLE in 0.01 seconds
2021-05-19 20:37:55.880577 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:37:55.882919 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.884358 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:37:55.884520 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.884633 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:37:55.884773 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.884896 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:37:55.885115 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:37:55.885418 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:55.887560 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.887692 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:37:55.887891 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:55.891447 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:37:55.891621 (Thread-4): SQL status: COMMIT in 0.01 seconds
2021-05-19 20:37:55.891759 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:37:55.891866 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:55.893334 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:37:55.894627 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:37:55.894787 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:37:55.894935 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.895126 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:37:55.895675 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:55.897354 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:37:55.897514 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.897628 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:37:55.897787 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.899064 (Thread-2): finished collecting timing info
2021-05-19 20:37:55.900340 (Thread-4): finished collecting timing info
2021-05-19 20:37:55.900558 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:37:55.900819 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:37:55.901391 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072827c0>]}
2021-05-19 20:37:55.901847 (Thread-2): 16:37:55 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.17s]
2021-05-19 20:37:55.902222 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074cb1c0>]}
2021-05-19 20:37:55.902393 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.902566 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:37:55.903028 (Thread-4): 16:37:55 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.17s]
2021-05-19 20:37:55.904409 (Thread-3): finished collecting timing info
2021-05-19 20:37:55.904591 (Thread-2): Began running node model.fetch_takehome.fact_users
2021-05-19 20:37:55.904894 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:37:55.905027 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:37:55.905249 (Thread-2): 16:37:55 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-19 20:37:55.905396 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:37:55.905861 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:37:55.906214 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074cb820>]}
2021-05-19 20:37:55.906309 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-19 20:37:55.906496 (Thread-4): 16:37:55 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:37:55.906641 (Thread-2): Compiling model.fetch_takehome.fact_users
2021-05-19 20:37:55.906951 (Thread-3): 16:37:55 | 3 of 8 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.18s]
2021-05-19 20:37:55.909302 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.911001 (Thread-2): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-19 20:37:55.911409 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:55.911740 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:37:55.911859 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:37:55.912153 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:37:55.912451 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:37:55.912799 (Thread-2): finished collecting timing info
2021-05-19 20:37:55.914158 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:37:55.914413 (Thread-3): 16:37:55 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:37:55.914520 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:55.917589 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:37:55.920191 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.920572 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:55.920751 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-19 20:37:55.921043 (Thread-4): finished collecting timing info
2021-05-19 20:37:55.921188 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:37:55.921352 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:37:55.921472 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:37:55.924530 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:55.926039 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:37:55.926244 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:55.926618 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:37:55.928338 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:37:55.928590 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:37:55.928790 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.928951 (Thread-3): finished collecting timing info
2021-05-19 20:37:55.929268 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:37:55.933974 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:55.934368 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:37:55.934562 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:37:55.934789 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:55.937671 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:37:55.937989 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:37:55.938609 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:37:55.942000 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:37:55.942306 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.942466 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-19 20:37:55.944409 (Thread-1): finished collecting timing info
2021-05-19 20:37:55.944644 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:37:55.944900 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:37:55.945029 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.947510 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:55.948147 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073446a0>]}
2021-05-19 20:37:55.949610 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-19 20:37:55.949869 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:37:55.950068 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:37:55.950588 (Thread-1): 16:37:55 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.22s]
2021-05-19 20:37:55.952927 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:55.977572 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:37:55.977772 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:37:55.977929 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:37:55.978078 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.978276 (Thread-2): On model.fetch_takehome.fact_users: BEGIN
2021-05-19 20:37:55.978539 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:37:55.981128 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:37:55.981376 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:55.981812 (Thread-1): 16:37:55 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:37:55.981967 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.983827 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:37:55.984367 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:55.984554 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:37:55.984733 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:55.985024 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:37:55.985257 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:37:55.985449 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:37:55.985654 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:55.986940 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:37:55.987302 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:37:55.987493 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.987765 (Thread-2): Postgres error: column "userid" does not exist
LINE 7: userId as userId,
        ^

2021-05-19 20:37:55.988040 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:55.988152 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:55.988251 (Thread-1): finished collecting timing info
2021-05-19 20:37:55.988410 (Thread-2): On model.fetch_takehome.fact_users: ROLLBACK
2021-05-19 20:37:55.988524 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:55.988663 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:37:55.991547 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:55.991803 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:37:55.992030 (Thread-2): finished collecting timing info
2021-05-19 20:37:55.992246 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:37:55.992529 (Thread-2): On model.fetch_takehome.fact_users: Close
2021-05-19 20:37:55.992696 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:37:55.993121 (Thread-2): Database Error in model fact_users (models/transformations/fact_users.sql)
  column "userid" does not exist
  LINE 7: userId as userId,
          ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_users.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "userid" does not exist
LINE 7: userId as userId,
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_users (models/transformations/fact_users.sql)
  column "userid" does not exist
  LINE 7: userId as userId,
          ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_users.sql
2021-05-19 20:37:56.001984 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074a5e50>]}
2021-05-19 20:37:56.002384 (Thread-2): 16:37:56 | 5 of 8 ERROR creating table model fetch_takehome.fact_users.......... [ERROR in 0.10s]
2021-05-19 20:37:56.002543 (Thread-2): Finished running node model.fetch_takehome.fact_users
2021-05-19 20:37:56.003449 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:37:56.005553 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:56.005675 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:37:56.006084 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:56.007522 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:37:56.008187 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:56.008319 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:37:56.008663 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:37:56.008834 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:56.008980 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:37:56.029409 (Thread-1): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 20:37:56.031949 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:56.032113 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:37:56.032617 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:56.034842 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:56.034985 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:37:56.035655 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:56.036991 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:37:56.037115 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:56.037210 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:37:56.037854 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:56.039288 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:37:56.039519 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:37:56.042375 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:56.043688 (Thread-1): finished collecting timing info
2021-05-19 20:37:56.043860 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:37:56.044245 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074bfb50>]}
2021-05-19 20:37:56.044578 (Thread-1): 16:37:56 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-19 20:37:56.044731 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:37:56.768162 (Thread-3): SQL status: SELECT 1119 in 0.78 seconds
2021-05-19 20:37:56.770155 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:56.770255 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:37:57.194079 (Thread-4): SQL status: SELECT 6941 in 1.20 seconds
2021-05-19 20:37:57.196947 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:57.197121 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:37:57.197614 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:57.200173 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:57.200341 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:37:57.201400 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:57.202734 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:37:57.202866 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:57.202963 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:37:57.203586 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:57.205165 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:37:57.205301 (Thread-3): SQL status: ALTER TABLE in 0.43 seconds
2021-05-19 20:37:57.205406 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:37:57.207429 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:57.207653 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:37:57.208210 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:37:57.209552 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:37:57.209676 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:57.209772 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:37:57.210077 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:57.211196 (Thread-4): finished collecting timing info
2021-05-19 20:37:57.211359 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:37:57.211496 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:57.212007 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074cb2e0>]}
2021-05-19 20:37:57.213516 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:37:57.213943 (Thread-4): 16:37:57 | 6 of 8 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.30s]
2021-05-19 20:37:57.214077 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:37:57.214243 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:37:57.216986 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:37:57.218325 (Thread-3): finished collecting timing info
2021-05-19 20:37:57.218499 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:37:57.218875 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '65e7c6f8-a252-4c46-8dd8-5bd94a6dd0f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074cb070>]}
2021-05-19 20:37:57.219193 (Thread-3): 16:37:57 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.30s]
2021-05-19 20:37:57.219352 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:37:57.220719 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:37:57.220903 (MainThread): Using postgres connection "master".
2021-05-19 20:37:57.221005 (MainThread): On master: BEGIN
2021-05-19 20:37:57.221106 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:37:57.229731 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:37:57.229916 (MainThread): On master: COMMIT
2021-05-19 20:37:57.230016 (MainThread): Using postgres connection "master".
2021-05-19 20:37:57.230108 (MainThread): On master: COMMIT
2021-05-19 20:37:57.230310 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:37:57.230435 (MainThread): On master: Close
2021-05-19 20:37:57.230803 (MainThread): 16:37:57 | 
2021-05-19 20:37:57.230943 (MainThread): 16:37:57 | Finished running 8 table models in 1.64s.
2021-05-19 20:37:57.231059 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:37:57.231145 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:37:57.231226 (MainThread): Connection 'model.fetch_takehome.fact_users' was properly closed.
2021-05-19 20:37:57.231304 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:37:57.231383 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:37:57.237872 (MainThread): 
2021-05-19 20:37:57.238066 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 20:37:57.238205 (MainThread): 
2021-05-19 20:37:57.238341 (MainThread): Database Error in model fact_users (models/transformations/fact_users.sql)
2021-05-19 20:37:57.238449 (MainThread):   column "userid" does not exist
2021-05-19 20:37:57.238547 (MainThread):   LINE 7: userId as userId,
2021-05-19 20:37:57.238643 (MainThread):           ^
2021-05-19 20:37:57.238739 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_users.sql
2021-05-19 20:37:57.238856 (MainThread): 
Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
2021-05-19 20:37:57.239050 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107377c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074b9cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074b9d30>]}
2021-05-19 20:37:57.239261 (MainThread): Flushing usage events
2021-05-19 20:38:25.083939 (MainThread): Running with dbt=0.19.1
2021-05-19 20:38:25.171503 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:38:25.172433 (MainThread): Tracking: tracking
2021-05-19 20:38:25.187530 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f684d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6ab5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6abe20>]}
2021-05-19 20:38:25.203756 (MainThread): Partial parsing not enabled
2021-05-19 20:38:25.204950 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:38:25.209163 (MainThread): Parsing macros/relations.sql
2021-05-19 20:38:25.211125 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:38:25.238674 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:38:25.242173 (MainThread): Parsing macros/core.sql
2021-05-19 20:38:25.247103 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:38:25.256948 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:38:25.259186 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:38:25.279414 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:38:25.314732 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:38:25.336929 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:38:25.339049 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:38:25.345550 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:38:25.360278 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:38:25.367720 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:38:25.374408 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:38:25.379558 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:38:25.380539 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:38:25.381637 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:38:25.383517 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:38:25.392639 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:38:25.394740 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:38:25.396468 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:38:25.441783 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:38:25.443753 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:38:25.445332 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:38:25.447086 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:38:25.454827 (MainThread): Partial parsing not enabled
2021-05-19 20:38:25.509618 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.521375 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:25.524821 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:25.528066 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:25.531503 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.534744 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.538707 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:38:25.541822 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.586206 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8faca0>]}
2021-05-19 20:38:25.590500 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f817a30>]}
2021-05-19 20:38:25.590832 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:38:25.591659 (MainThread): 
2021-05-19 20:38:25.591993 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:38:25.593394 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:38:25.602975 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:38:25.603099 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:38:25.603190 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:38:25.629682 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 20:38:25.633395 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:38:25.635309 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:38:25.644495 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:38:25.644666 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:38:25.644784 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:38:25.653920 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:38:25.654095 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:38:25.654199 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:38:25.657564 (ThreadPoolExecutor-1_0): SQL status: SELECT 10 in 0.00 seconds
2021-05-19 20:38:25.658454 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:38:25.658703 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:38:25.664514 (MainThread): Using postgres connection "master".
2021-05-19 20:38:25.664725 (MainThread): On master: BEGIN
2021-05-19 20:38:25.664888 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:38:25.675133 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:38:25.675307 (MainThread): Using postgres connection "master".
2021-05-19 20:38:25.675412 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:38:25.701047 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-19 20:38:25.701670 (MainThread): On master: ROLLBACK
2021-05-19 20:38:25.701894 (MainThread): Using postgres connection "master".
2021-05-19 20:38:25.701999 (MainThread): On master: BEGIN
2021-05-19 20:38:25.702286 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.702434 (MainThread): On master: COMMIT
2021-05-19 20:38:25.702543 (MainThread): Using postgres connection "master".
2021-05-19 20:38:25.702635 (MainThread): On master: COMMIT
2021-05-19 20:38:25.702813 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:25.702936 (MainThread): On master: Close
2021-05-19 20:38:25.703262 (MainThread): 16:38:25 | Concurrency: 4 threads (target='dev')
2021-05-19 20:38:25.703411 (MainThread): 16:38:25 | 
2021-05-19 20:38:25.706089 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:38:25.706279 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:38:25.706439 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:38:25.706550 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:38:25.706802 (Thread-1): 16:38:25 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:38:25.707057 (Thread-2): 16:38:25 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:38:25.707297 (Thread-3): 16:38:25 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:38:25.707541 (Thread-4): 16:38:25 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:38:25.707956 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.708523 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.708899 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.709238 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.709393 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:38:25.709519 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:38:25.709632 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:38:25.709762 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:38:25.711151 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:38:25.712278 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:38:25.713504 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:38:25.715542 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:38:25.716381 (Thread-3): finished collecting timing info
2021-05-19 20:38:25.722918 (Thread-1): finished collecting timing info
2021-05-19 20:38:25.729470 (Thread-2): finished collecting timing info
2021-05-19 20:38:25.776374 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.777934 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.778051 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:38:25.778153 (Thread-4): finished collecting timing info
2021-05-19 20:38:25.779993 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.780149 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:38:25.780276 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:38:25.783068 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.783377 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:38:25.783528 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:38:25.783900 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:38:25.784064 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:38:25.784372 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:38:25.793798 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:38:25.796299 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.796442 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:38:25.796611 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:38:25.796785 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:38:25.796881 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.799118 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.801451 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.801619 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:38:25.813872 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:38:25.814205 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:38:25.814351 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:38:25.816750 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.817153 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.817355 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:38:25.818803 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:38:25.818901 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.819030 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.820577 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:38:25.820778 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:38:25.820883 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.821010 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.822576 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:38:25.822749 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.822956 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.823057 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:38:25.823354 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.823541 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:38:25.823861 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.824027 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:38:25.824136 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.824374 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:38:25.824517 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.824712 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.824935 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.825081 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.825182 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:38:25.825299 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:38:25.825408 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.825680 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:38:25.832457 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-19 20:38:25.842851 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.843059 (Thread-4): SQL status: SELECT 1119 in 0.02 seconds
2021-05-19 20:38:25.843188 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:38:25.847261 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.847553 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-19 20:38:25.847850 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:25.850012 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.850239 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:25.850347 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:38:25.852576 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.852804 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-19 20:38:25.853161 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:25.858433 (Thread-3): SQL status: SELECT 6941 in 0.03 seconds
2021-05-19 20:38:25.861123 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:38:25.861268 (Thread-4): SQL status: ALTER TABLE in 0.01 seconds
2021-05-19 20:38:25.864062 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.864273 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.865615 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:38:25.865817 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:38:25.865988 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:38:25.866148 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.866465 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:38:25.866810 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:25.869666 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.869836 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:25.869957 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:38:25.870079 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:25.873942 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:38:25.875803 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:38:25.875987 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:25.876109 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:38:25.876251 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:38:25.877768 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:38:25.878259 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.878420 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:38:25.879067 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:25.882122 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:38:25.882362 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.882535 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.882695 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:38:25.884813 (Thread-4): finished collecting timing info
2021-05-19 20:38:25.886631 (Thread-2): finished collecting timing info
2021-05-19 20:38:25.887037 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:38:25.887278 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:38:25.887957 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa4e1c0>]}
2021-05-19 20:38:25.888519 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8209a0>]}
2021-05-19 20:38:25.889009 (Thread-4): 16:38:25 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.18s]
2021-05-19 20:38:25.889202 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-19 20:38:25.889714 (Thread-2): 16:38:25 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.18s]
2021-05-19 20:38:25.889926 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.890165 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:38:25.893847 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.894222 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:38:25.895736 (Thread-3): finished collecting timing info
2021-05-19 20:38:25.896126 (Thread-4): Began running node model.fetch_takehome.fact_users
2021-05-19 20:38:25.896482 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:38:25.896687 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:38:25.896885 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:38:25.897381 (Thread-4): 16:38:25 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-19 20:38:25.897914 (Thread-2): 16:38:25 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:38:25.898757 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:38:25.898958 (Thread-4): Compiling model.fetch_takehome.fact_users
2021-05-19 20:38:25.901418 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-19 20:38:25.902046 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8c76d0>]}
2021-05-19 20:38:25.902577 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:25.902785 (Thread-1): SQL status: ALTER TABLE in 0.01 seconds
2021-05-19 20:38:25.903369 (Thread-3): 16:38:25 | 3 of 8 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.19s]
2021-05-19 20:38:25.903617 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:38:25.907447 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.907721 (Thread-4): finished collecting timing info
2021-05-19 20:38:25.908158 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:38:25.910762 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:38:25.911042 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:38:25.915965 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:38:25.916304 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:38:25.916931 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-19 20:38:25.917417 (Thread-3): 16:38:25 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:38:25.917871 (Thread-2): finished collecting timing info
2021-05-19 20:38:25.918069 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:38:25.918622 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:25.923560 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:25.924814 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:38:25.925056 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:38:25.924488 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:38:25.923833 (Thread-1): SQL status: ALTER TABLE in 0.01 seconds
2021-05-19 20:38:25.928011 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:38:25.930128 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:38:25.930552 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.930802 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:38:25.931238 (Thread-3): finished collecting timing info
2021-05-19 20:38:25.938848 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:25.939081 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-05-19 20:38:25.939239 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:38:25.942153 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:38:25.942423 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:38:25.942613 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:38:25.945464 (Thread-4): SQL status: DROP TABLE in 0.03 seconds
2021-05-19 20:38:25.948675 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:38:25.948884 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:38:25.949000 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:38:25.949101 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-19 20:38:25.951646 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:25.952974 (Thread-1): finished collecting timing info
2021-05-19 20:38:25.953281 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:38:25.953475 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:38:25.953622 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.954155 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8be160>]}
2021-05-19 20:38:25.955847 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-19 20:38:25.955968 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.956501 (Thread-1): 16:38:25 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.25s]
2021-05-19 20:38:25.958359 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:38:25.958540 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:38:25.958805 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:38:25.962981 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:25.963308 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:38:25.963653 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:38:25.964091 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:38:25.964396 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:25.964544 (Thread-4): On model.fetch_takehome.fact_users: BEGIN
2021-05-19 20:38:25.964942 (Thread-1): 16:38:25 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:38:25.965241 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:38:25.965505 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.965685 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.966423 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:25.969027 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:38:25.969295 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.969484 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:38:25.969713 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:38:25.970097 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:25.970303 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users_json_extract
  );
2021-05-19 20:38:25.972165 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:38:25.972422 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:25.972565 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:38:25.973013 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:38:25.973393 (Thread-1): finished collecting timing info
2021-05-19 20:38:25.976688 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:25.977065 (Thread-4): Postgres error: column "createdate" does not exist
LINE 12: to_timestamp(createDate::numeric/1000) as createdDate,
                      ^
HINT:  Perhaps you meant to reference the column "users_json_extract.createddate".

2021-05-19 20:38:25.977195 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.977303 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:38:25.977442 (Thread-4): On model.fetch_takehome.fact_users: ROLLBACK
2021-05-19 20:38:25.977588 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:25.977751 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:38:25.977974 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:38:25.978206 (Thread-4): finished collecting timing info
2021-05-19 20:38:25.978765 (Thread-4): On model.fetch_takehome.fact_users: Close
2021-05-19 20:38:25.979253 (Thread-4): Database Error in model fact_users (models/transformations/fact_users.sql)
  column "createdate" does not exist
  LINE 12: to_timestamp(createDate::numeric/1000) as createdDate,
                        ^
  HINT:  Perhaps you meant to reference the column "users_json_extract.createddate".
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_users.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "createdate" does not exist
LINE 12: to_timestamp(createDate::numeric/1000) as createdDate,
                      ^
HINT:  Perhaps you meant to reference the column "users_json_extract.createddate".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_users (models/transformations/fact_users.sql)
  column "createdate" does not exist
  LINE 12: to_timestamp(createDate::numeric/1000) as createdDate,
                        ^
  HINT:  Perhaps you meant to reference the column "users_json_extract.createddate".
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_users.sql
2021-05-19 20:38:25.982735 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa27fa0>]}
2021-05-19 20:38:25.983299 (Thread-4): 16:38:25 | 5 of 8 ERROR creating table model fetch_takehome.fact_users.......... [ERROR in 0.08s]
2021-05-19 20:38:25.983547 (Thread-4): Finished running node model.fetch_takehome.fact_users
2021-05-19 20:38:25.988414 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:38:25.991668 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:25.991839 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:38:25.992169 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:25.994512 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:38:25.995217 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:25.995392 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:38:25.995772 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:38:25.995947 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:25.996093 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:38:26.043018 (Thread-1): SQL status: SELECT 495 in 0.05 seconds
2021-05-19 20:38:26.045927 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:26.046133 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:38:26.046979 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:26.050359 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:26.050520 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:38:26.051132 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:26.052497 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:38:26.052645 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:26.052748 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:38:26.053429 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:26.054863 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:38:26.054980 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:38:26.057078 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:26.059059 (Thread-1): finished collecting timing info
2021-05-19 20:38:26.059251 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:38:26.059639 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa41b50>]}
2021-05-19 20:38:26.059963 (Thread-1): 16:38:26 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.09s]
2021-05-19 20:38:26.060109 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:38:26.814060 (Thread-3): SQL status: SELECT 1119 in 0.84 seconds
2021-05-19 20:38:26.816343 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:26.816482 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:38:27.286722 (Thread-2): SQL status: SELECT 6941 in 1.31 seconds
2021-05-19 20:38:27.289966 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:27.290137 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:38:27.290674 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:27.293250 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:27.293408 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:38:27.294070 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:27.295355 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:38:27.295488 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:27.295586 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:38:27.296309 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:27.297997 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:38:27.298130 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:38:27.298249 (Thread-3): SQL status: ALTER TABLE in 0.48 seconds
2021-05-19 20:38:27.300512 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:27.300662 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:38:27.300822 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:27.302479 (Thread-2): finished collecting timing info
2021-05-19 20:38:27.302671 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:38:27.302795 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:38:27.303184 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fabb550>]}
2021-05-19 20:38:27.304358 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:38:27.304723 (Thread-2): 16:38:27 | 6 of 8 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.40s]
2021-05-19 20:38:27.304850 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:27.305053 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:38:27.305235 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:38:27.305982 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:27.307630 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:38:27.307744 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:38:27.309967 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:38:27.311229 (Thread-3): finished collecting timing info
2021-05-19 20:38:27.311394 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:38:27.311765 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '85b91ea0-5231-426b-8704-d0ef7fff40cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa27d60>]}
2021-05-19 20:38:27.312085 (Thread-3): 16:38:27 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.39s]
2021-05-19 20:38:27.312233 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:38:27.313449 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:38:27.313618 (MainThread): Using postgres connection "master".
2021-05-19 20:38:27.313720 (MainThread): On master: BEGIN
2021-05-19 20:38:27.313844 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:38:27.322764 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:38:27.322958 (MainThread): On master: COMMIT
2021-05-19 20:38:27.323065 (MainThread): Using postgres connection "master".
2021-05-19 20:38:27.323160 (MainThread): On master: COMMIT
2021-05-19 20:38:27.323365 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:38:27.323515 (MainThread): On master: Close
2021-05-19 20:38:27.323902 (MainThread): 16:38:27 | 
2021-05-19 20:38:27.324043 (MainThread): 16:38:27 | Finished running 8 table models in 1.73s.
2021-05-19 20:38:27.324200 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:38:27.324332 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:38:27.324427 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:38:27.324512 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:38:27.324593 (MainThread): Connection 'model.fetch_takehome.fact_users' was properly closed.
2021-05-19 20:38:27.330652 (MainThread): 
2021-05-19 20:38:27.330858 (MainThread): Completed with 1 error and 0 warnings:
2021-05-19 20:38:27.330992 (MainThread): 
2021-05-19 20:38:27.331114 (MainThread): Database Error in model fact_users (models/transformations/fact_users.sql)
2021-05-19 20:38:27.331246 (MainThread):   column "createdate" does not exist
2021-05-19 20:38:27.331347 (MainThread):   LINE 12: to_timestamp(createDate::numeric/1000) as createdDate,
2021-05-19 20:38:27.331452 (MainThread):                         ^
2021-05-19 20:38:27.331550 (MainThread):   HINT:  Perhaps you meant to reference the column "users_json_extract.createddate".
2021-05-19 20:38:27.331663 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_users.sql
2021-05-19 20:38:27.331790 (MainThread): 
Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
2021-05-19 20:38:27.331988 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8fa8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa4bd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa4bd60>]}
2021-05-19 20:38:27.332197 (MainThread): Flushing usage events
2021-05-19 20:39:04.331287 (MainThread): Running with dbt=0.19.1
2021-05-19 20:39:04.398829 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-19 20:39:04.400238 (MainThread): Tracking: tracking
2021-05-19 20:39:04.416921 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101cac40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101e8700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101e8f40>]}
2021-05-19 20:39:04.430723 (MainThread): Partial parsing not enabled
2021-05-19 20:39:04.432203 (MainThread): Parsing macros/catalog.sql
2021-05-19 20:39:04.435844 (MainThread): Parsing macros/relations.sql
2021-05-19 20:39:04.437395 (MainThread): Parsing macros/adapters.sql
2021-05-19 20:39:04.458615 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-19 20:39:04.462083 (MainThread): Parsing macros/core.sql
2021-05-19 20:39:04.466091 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-19 20:39:04.475174 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-19 20:39:04.477033 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-19 20:39:04.496974 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-19 20:39:04.535286 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-19 20:39:04.559699 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-19 20:39:04.561614 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-19 20:39:04.568109 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-19 20:39:04.583346 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-19 20:39:04.590516 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-19 20:39:04.597119 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-19 20:39:04.602327 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-19 20:39:04.603324 (MainThread): Parsing macros/etc/query.sql
2021-05-19 20:39:04.604404 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-19 20:39:04.606062 (MainThread): Parsing macros/etc/datetime.sql
2021-05-19 20:39:04.615252 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-19 20:39:04.617400 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-19 20:39:04.619313 (MainThread): Parsing macros/adapters/common.sql
2021-05-19 20:39:04.673259 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-19 20:39:04.675757 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-19 20:39:04.677871 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-19 20:39:04.680245 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-19 20:39:04.693090 (MainThread): Partial parsing not enabled
2021-05-19 20:39:04.757051 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:04.770284 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:04.773913 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:04.777470 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:04.781647 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:04.786206 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:04.790859 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:04.794873 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:04.856239 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110418610>]}
2021-05-19 20:39:04.861930 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11035eb50>]}
2021-05-19 20:39:04.862227 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-19 20:39:04.863061 (MainThread): 
2021-05-19 20:39:04.863392 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:39:04.864709 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-19 20:39:04.877199 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-19 20:39:04.877350 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-19 20:39:04.877462 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-19 20:39:04.907631 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-19 20:39:04.910331 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-19 20:39:04.911961 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:39:04.919660 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:39:04.919804 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-19 20:39:04.919916 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-19 20:39:04.929459 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:39:04.929632 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-19 20:39:04.929730 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-19 20:39:04.933106 (ThreadPoolExecutor-1_0): SQL status: SELECT 10 in 0.00 seconds
2021-05-19 20:39:04.933982 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-19 20:39:04.934226 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-19 20:39:04.939889 (MainThread): Using postgres connection "master".
2021-05-19 20:39:04.940039 (MainThread): On master: BEGIN
2021-05-19 20:39:04.940150 (MainThread): Opening a new connection, currently in state init
2021-05-19 20:39:04.949272 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:39:04.949432 (MainThread): Using postgres connection "master".
2021-05-19 20:39:04.949525 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-19 20:39:04.973780 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-19 20:39:04.974381 (MainThread): On master: ROLLBACK
2021-05-19 20:39:04.974612 (MainThread): Using postgres connection "master".
2021-05-19 20:39:04.974711 (MainThread): On master: BEGIN
2021-05-19 20:39:04.975013 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:04.975125 (MainThread): On master: COMMIT
2021-05-19 20:39:04.975215 (MainThread): Using postgres connection "master".
2021-05-19 20:39:04.975293 (MainThread): On master: COMMIT
2021-05-19 20:39:04.975480 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:04.975620 (MainThread): On master: Close
2021-05-19 20:39:04.975932 (MainThread): 16:39:04 | Concurrency: 4 threads (target='dev')
2021-05-19 20:39:04.976077 (MainThread): 16:39:04 | 
2021-05-19 20:39:04.978459 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-19 20:39:04.978711 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-19 20:39:04.978911 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-19 20:39:04.979288 (Thread-1): 16:39:04 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-19 20:39:04.979419 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-19 20:39:04.979668 (Thread-2): 16:39:04 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-19 20:39:04.979905 (Thread-3): 16:39:04 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-19 20:39:04.980321 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:04.980550 (Thread-4): 16:39:04 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-19 20:39:04.980945 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:04.981264 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:04.981475 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-19 20:39:04.981722 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-19 20:39:04.982252 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:04.982496 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-19 20:39:04.983961 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:39:04.985129 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:39:04.985281 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-19 20:39:04.986569 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:39:04.988229 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:39:04.989671 (Thread-1): finished collecting timing info
2021-05-19 20:39:04.989821 (Thread-2): finished collecting timing info
2021-05-19 20:39:04.990056 (Thread-3): finished collecting timing info
2021-05-19 20:39:05.024956 (Thread-4): finished collecting timing info
2021-05-19 20:39:05.056709 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.058805 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.059843 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.061676 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.061794 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-19 20:39:05.061920 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-19 20:39:05.062025 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-19 20:39:05.062121 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-19 20:39:05.062228 (Thread-2): Opening a new connection, currently in state init
2021-05-19 20:39:05.062322 (Thread-3): Opening a new connection, currently in state init
2021-05-19 20:39:05.062415 (Thread-4): Opening a new connection, currently in state init
2021-05-19 20:39:05.062506 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:39:05.073922 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:39:05.076766 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.077000 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:39:05.077250 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:39:05.077421 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:39:05.077523 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.077604 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-19 20:39:05.079914 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.082127 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.096526 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.098648 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-19 20:39:05.098798 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:39:05.098906 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:39:05.099009 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:39:05.099585 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.099787 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.099883 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.099965 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.101235 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-19 20:39:05.101353 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-19 20:39:05.102541 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-19 20:39:05.103771 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-19 20:39:05.104307 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.104589 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.104820 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.104976 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.105194 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.105326 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-19 20:39:05.105453 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-19 20:39:05.105561 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-19 20:39:05.105784 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-19 20:39:05.106293 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.106493 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.106595 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.106669 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.106774 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.106869 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-19 20:39:05.106967 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.107057 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-19 20:39:05.107238 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-19 20:39:05.112641 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-19 20:39:05.120117 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.120305 (Thread-4): SQL status: SELECT 1119 in 0.01 seconds
2021-05-19 20:39:05.120467 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-19 20:39:05.124630 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.124918 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-19 20:39:05.125227 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.125393 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.128951 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.131488 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.131654 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-19 20:39:05.131827 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-19 20:39:05.132491 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.132647 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.138367 (Thread-3): SQL status: SELECT 6941 in 0.03 seconds
2021-05-19 20:39:05.140309 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:39:05.141501 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:39:05.143755 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.143896 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.144003 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.144098 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-19 20:39:05.144198 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-19 20:39:05.144289 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-19 20:39:05.144781 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.146840 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.146999 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:05.147108 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-19 20:39:05.147185 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:05.150550 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-19 20:39:05.152118 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-19 20:39:05.152253 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-19 20:39:05.152354 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.152480 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-19 20:39:05.153698 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:39:05.153914 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.154014 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-19 20:39:05.154511 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:05.155868 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-19 20:39:05.155985 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-19 20:39:05.156315 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.156476 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.157555 (Thread-4): finished collecting timing info
2021-05-19 20:39:05.158694 (Thread-2): finished collecting timing info
2021-05-19 20:39:05.158858 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-19 20:39:05.158940 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.159058 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-19 20:39:05.159421 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110585970>]}
2021-05-19 20:39:05.160439 (Thread-3): finished collecting timing info
2021-05-19 20:39:05.160917 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105856d0>]}
2021-05-19 20:39:05.161218 (Thread-4): 16:39:05 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.18s]
2021-05-19 20:39:05.161352 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-19 20:39:05.161626 (Thread-2): 16:39:05 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.18s]
2021-05-19 20:39:05.161838 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-19 20:39:05.162082 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-19 20:39:05.162446 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11059fd00>]}
2021-05-19 20:39:05.162569 (Thread-4): Began running node model.fetch_takehome.fact_users
2021-05-19 20:39:05.162826 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-19 20:39:05.163210 (Thread-4): 16:39:05 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-19 20:39:05.163462 (Thread-3): 16:39:05 | 3 of 8 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.18s]
2021-05-19 20:39:05.163650 (Thread-2): 16:39:05 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-19 20:39:05.163732 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-19 20:39:05.164015 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.164207 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-19 20:39:05.164467 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:05.166499 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.166635 (Thread-4): Compiling model.fetch_takehome.fact_users
2021-05-19 20:39:05.166764 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:39:05.166980 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-19 20:39:05.167096 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-19 20:39:05.168349 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-19 20:39:05.168550 (Thread-3): 16:39:05 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-19 20:39:05.169623 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:39:05.170163 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:05.170338 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.170664 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-19 20:39:05.173163 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.174844 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:39:05.175058 (Thread-4): finished collecting timing info
2021-05-19 20:39:05.175192 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-19 20:39:05.175294 (Thread-2): finished collecting timing info
2021-05-19 20:39:05.178025 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.178351 (Thread-3): finished collecting timing info
2021-05-19 20:39:05.180849 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:05.180985 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-19 20:39:05.185386 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:05.185551 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-19 20:39:05.185673 (Thread-4): Opening a new connection, currently in state closed
2021-05-19 20:39:05.185766 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-19 20:39:05.185898 (Thread-2): Opening a new connection, currently in state closed
2021-05-19 20:39:05.186193 (Thread-3): Opening a new connection, currently in state closed
2021-05-19 20:39:05.189831 (Thread-1): SQL status: ALTER TABLE in 0.01 seconds
2021-05-19 20:39:05.191058 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:39:05.191177 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.191263 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-19 20:39:05.191755 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:05.193189 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-19 20:39:05.193298 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-19 20:39:05.195208 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:39:05.195372 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:39:05.197565 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.197747 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.199763 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:05.199854 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:39:05.200009 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-19 20:39:05.201085 (Thread-1): finished collecting timing info
2021-05-19 20:39:05.201216 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:39:05.203052 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:05.203289 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-19 20:39:05.203423 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.203626 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:39:05.203757 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.205033 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-19 20:39:05.205518 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11059d490>]}
2021-05-19 20:39:05.206835 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-19 20:39:05.207050 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.207403 (Thread-1): 16:39:05 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.23s]
2021-05-19 20:39:05.208930 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-19 20:39:05.209102 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.209293 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-19 20:39:05.209434 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:05.209635 (Thread-4): On model.fetch_takehome.fact_users: BEGIN
2021-05-19 20:39:05.209790 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-19 20:39:05.210120 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-19 20:39:05.210320 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:05.210576 (Thread-1): 16:39:05 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-19 20:39:05.210730 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.210839 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-19 20:39:05.210983 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.211234 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.211343 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.211512 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:05.211617 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.211763 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-19 20:39:05.211865 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createdDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users_json_extract
  );
2021-05-19 20:39:05.211964 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-19 20:39:05.212068 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:05.213234 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:39:05.213514 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-19 20:39:05.214002 (Thread-1): finished collecting timing info
2021-05-19 20:39:05.217093 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.217245 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-19 20:39:05.217354 (Thread-1): Opening a new connection, currently in state closed
2021-05-19 20:39:05.222659 (Thread-4): SQL status: SELECT 495 in 0.01 seconds
2021-05-19 20:39:05.225338 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.225484 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users__dbt_tmp" rename to "fact_users"
2021-05-19 20:39:05.226052 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.227310 (Thread-4): On model.fetch_takehome.fact_users: COMMIT
2021-05-19 20:39:05.227603 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.227758 (Thread-4): On model.fetch_takehome.fact_users: COMMIT
2021-05-19 20:39:05.228128 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-19 20:39:05.230537 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.230699 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:05.230812 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:39:05.232329 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-19 20:39:05.232557 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-19 20:39:05.232721 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.234066 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-19 20:39:05.234211 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.235534 (Thread-4): finished collecting timing info
2021-05-19 20:39:05.235732 (Thread-4): On model.fetch_takehome.fact_users: Close
2021-05-19 20:39:05.236352 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105830a0>]}
2021-05-19 20:39:05.236571 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.237058 (Thread-4): 16:39:05 | 5 of 8 OK created table model fetch_takehome.fact_users.............. [SELECT 495 in 0.07s]
2021-05-19 20:39:05.237244 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-19 20:39:05.237486 (Thread-4): Finished running node model.fetch_takehome.fact_users
2021-05-19 20:39:05.237823 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-19 20:39:05.237954 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.238048 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-19 20:39:05.256723 (Thread-1): SQL status: SELECT 495 in 0.02 seconds
2021-05-19 20:39:05.258935 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.259053 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-19 20:39:05.259479 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.261559 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.261665 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-19 20:39:05.262086 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:05.263148 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:39:05.263253 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.263338 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-19 20:39:05.266543 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:05.268214 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-19 20:39:05.268344 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-19 20:39:05.270324 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:05.272168 (Thread-1): finished collecting timing info
2021-05-19 20:39:05.272367 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-19 20:39:05.272774 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105dd730>]}
2021-05-19 20:39:05.273126 (Thread-1): 16:39:05 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-19 20:39:05.273293 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-19 20:39:06.015011 (Thread-3): SQL status: SELECT 1119 in 0.80 seconds
2021-05-19 20:39:06.017444 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:06.017591 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-19 20:39:06.234545 (Thread-2): SQL status: SELECT 6941 in 1.02 seconds
2021-05-19 20:39:06.236626 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:06.236727 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-19 20:39:06.237064 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:06.238764 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:06.238855 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-19 20:39:06.240051 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:06.241029 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:39:06.241124 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:06.241200 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-19 20:39:06.241952 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:06.243188 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-19 20:39:06.243287 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-19 20:39:06.243408 (Thread-3): SQL status: ALTER TABLE in 0.23 seconds
2021-05-19 20:39:06.246612 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:06.246725 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-19 20:39:06.246852 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:06.247837 (Thread-2): finished collecting timing info
2021-05-19 20:39:06.247970 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-19 20:39:06.248091 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-19 20:39:06.248418 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110668880>]}
2021-05-19 20:39:06.249406 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:39:06.249748 (Thread-2): 16:39:06 | 6 of 8 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.08s]
2021-05-19 20:39:06.249851 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:06.250033 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-19 20:39:06.250201 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-19 20:39:06.253567 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:06.254908 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-19 20:39:06.255008 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-19 20:39:06.257360 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-19 20:39:06.258669 (Thread-3): finished collecting timing info
2021-05-19 20:39:06.258814 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-19 20:39:06.259148 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3055daf2-7c36-47f2-83ab-fb354adcca94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11067ff40>]}
2021-05-19 20:39:06.259433 (Thread-3): 16:39:06 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.09s]
2021-05-19 20:39:06.259561 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-19 20:39:06.260812 (MainThread): Acquiring new postgres connection "master".
2021-05-19 20:39:06.260969 (MainThread): Using postgres connection "master".
2021-05-19 20:39:06.261058 (MainThread): On master: BEGIN
2021-05-19 20:39:06.261151 (MainThread): Opening a new connection, currently in state closed
2021-05-19 20:39:06.269091 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-19 20:39:06.269265 (MainThread): On master: COMMIT
2021-05-19 20:39:06.269361 (MainThread): Using postgres connection "master".
2021-05-19 20:39:06.269444 (MainThread): On master: COMMIT
2021-05-19 20:39:06.269628 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-19 20:39:06.269775 (MainThread): On master: Close
2021-05-19 20:39:06.270230 (MainThread): 16:39:06 | 
2021-05-19 20:39:06.270432 (MainThread): 16:39:06 | Finished running 8 table models in 1.41s.
2021-05-19 20:39:06.270603 (MainThread): Connection 'master' was properly closed.
2021-05-19 20:39:06.270753 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-19 20:39:06.270886 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-19 20:39:06.270997 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-19 20:39:06.271089 (MainThread): Connection 'model.fetch_takehome.fact_users' was properly closed.
2021-05-19 20:39:06.276762 (MainThread): 
2021-05-19 20:39:06.276929 (MainThread): Completed successfully
2021-05-19 20:39:06.277062 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2021-05-19 20:39:06.277242 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11040e8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11061da30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11061d550>]}
2021-05-19 20:39:06.277430 (MainThread): Flushing usage events
2021-05-20 14:47:25.368558 (MainThread): Running with dbt=0.19.1
2021-05-20 14:47:25.458388 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-20 14:47:25.459788 (MainThread): Tracking: tracking
2021-05-20 14:47:25.480811 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d1dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d396d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d39f10>]}
2021-05-20 14:47:25.495226 (MainThread): Partial parsing not enabled
2021-05-20 14:47:25.497061 (MainThread): Parsing macros/catalog.sql
2021-05-20 14:47:25.501843 (MainThread): Parsing macros/relations.sql
2021-05-20 14:47:25.504100 (MainThread): Parsing macros/adapters.sql
2021-05-20 14:47:25.526703 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-20 14:47:25.530378 (MainThread): Parsing macros/core.sql
2021-05-20 14:47:25.534725 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-20 14:47:25.544105 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-20 14:47:25.546183 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-20 14:47:25.565895 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-20 14:47:25.600602 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-20 14:47:25.623696 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-20 14:47:25.626034 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-20 14:47:25.633149 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-20 14:47:25.648419 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-20 14:47:25.655655 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-20 14:47:25.662700 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-20 14:47:25.668298 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-20 14:47:25.669527 (MainThread): Parsing macros/etc/query.sql
2021-05-20 14:47:25.670836 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-20 14:47:25.672760 (MainThread): Parsing macros/etc/datetime.sql
2021-05-20 14:47:25.682598 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-20 14:47:25.684871 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-20 14:47:25.686780 (MainThread): Parsing macros/adapters/common.sql
2021-05-20 14:47:25.733845 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-20 14:47:25.736022 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-20 14:47:25.737820 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-20 14:47:25.739757 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-20 14:47:25.747313 (MainThread): Partial parsing not enabled
2021-05-20 14:47:25.803961 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:25.815899 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:25.820011 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:25.823509 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:47:25.826877 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:47:25.830844 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:25.835367 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:25.839138 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:25.888891 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f8ba60>]}
2021-05-20 14:47:25.898823 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ea2d90>]}
2021-05-20 14:47:25.899085 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-20 14:47:25.899798 (MainThread): 
2021-05-20 14:47:25.900080 (MainThread): Acquiring new postgres connection "master".
2021-05-20 14:47:25.901216 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-20 14:47:25.910842 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-20 14:47:25.910971 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-20 14:47:25.911068 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-20 14:47:26.016402 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.11 seconds
2021-05-20 14:47:26.020369 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-20 14:47:26.021846 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:47:26.027784 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:47:26.027917 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-20 14:47:26.028087 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-20 14:47:26.037279 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:47:26.037446 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:47:26.037543 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-20 14:47:26.049138 (ThreadPoolExecutor-1_0): SQL status: SELECT 11 in 0.01 seconds
2021-05-20 14:47:26.050190 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-20 14:47:26.050485 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-20 14:47:26.055344 (MainThread): Using postgres connection "master".
2021-05-20 14:47:26.055480 (MainThread): On master: BEGIN
2021-05-20 14:47:26.055582 (MainThread): Opening a new connection, currently in state init
2021-05-20 14:47:26.063514 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:47:26.063670 (MainThread): Using postgres connection "master".
2021-05-20 14:47:26.063764 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-20 14:47:26.096257 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-20 14:47:26.096782 (MainThread): On master: ROLLBACK
2021-05-20 14:47:26.097033 (MainThread): Using postgres connection "master".
2021-05-20 14:47:26.097170 (MainThread): On master: BEGIN
2021-05-20 14:47:26.097496 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.097607 (MainThread): On master: COMMIT
2021-05-20 14:47:26.097692 (MainThread): Using postgres connection "master".
2021-05-20 14:47:26.097764 (MainThread): On master: COMMIT
2021-05-20 14:47:26.097970 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:26.098085 (MainThread): On master: Close
2021-05-20 14:47:26.098410 (MainThread): 10:47:26 | Concurrency: 4 threads (target='dev')
2021-05-20 14:47:26.098541 (MainThread): 10:47:26 | 
2021-05-20 14:47:26.101110 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-20 14:47:26.101401 (Thread-1): 10:47:26 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-20 14:47:26.101554 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-20 14:47:26.101699 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-20 14:47:26.101964 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.102053 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-20 14:47:26.102220 (Thread-2): 10:47:26 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-20 14:47:26.102396 (Thread-3): 10:47:26 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-20 14:47:26.102507 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-20 14:47:26.102690 (Thread-4): 10:47:26 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-20 14:47:26.103003 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.104327 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 14:47:26.104568 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:47:26.105032 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.105157 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-20 14:47:26.105384 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-20 14:47:26.105484 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-20 14:47:26.106721 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 14:47:26.108169 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-20 14:47:26.109924 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 14:47:26.110019 (Thread-1): finished collecting timing info
2021-05-20 14:47:26.110413 (Thread-2): finished collecting timing info
2021-05-20 14:47:26.141028 (Thread-3): finished collecting timing info
2021-05-20 14:47:26.141380 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.141494 (Thread-4): finished collecting timing info
2021-05-20 14:47:26.154562 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.158818 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:47:26.159008 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-20 14:47:26.162699 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.164642 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-20 14:47:26.165188 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-20 14:47:26.165390 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 14:47:26.165552 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-20 14:47:26.165696 (Thread-2): Opening a new connection, currently in state init
2021-05-20 14:47:26.165867 (Thread-3): Opening a new connection, currently in state init
2021-05-20 14:47:26.166237 (Thread-4): Opening a new connection, currently in state init
2021-05-20 14:47:26.182988 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:47:26.183221 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:47:26.183409 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:47:26.186367 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.186497 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:47:26.188900 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.190958 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.191115 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 14:47:26.193133 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:47:26.193262 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 14:47:26.193384 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 14:47:26.193604 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-20 14:47:26.193750 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:26.194076 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:26.199347 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.199458 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.211156 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 14:47:26.212423 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 14:47:26.213797 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 14:47:26.215131 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-20 14:47:26.216272 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.216523 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.216773 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.217051 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-20 14:47:26.217196 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-20 14:47:26.217429 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:47:26.217521 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-20 14:47:26.217841 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-20 14:47:26.218036 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.218177 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.218475 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.218659 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.218772 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.218859 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.218981 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-20 14:47:26.219104 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:47:26.219203 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-20 14:47:26.219303 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.219488 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-20 14:47:26.219712 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-20 14:47:26.224000 (Thread-3): Postgres error: column "createdate" does not exist
LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                      ^

2021-05-20 14:47:26.224182 (Thread-3): On model.fetch_takehome.fact_items: ROLLBACK
2021-05-20 14:47:26.224463 (Thread-3): finished collecting timing info
2021-05-20 14:47:26.224637 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-20 14:47:26.224990 (Thread-3): Database Error in model fact_items (models/transformations/fact_items.sql)
  column "createdate" does not exist
  LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                        ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "createdate" does not exist
LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                      ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_items (models/transformations/fact_items.sql)
  column "createdate" does not exist
  LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                        ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-20 14:47:26.232723 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120e4b80>]}
2021-05-20 14:47:26.233101 (Thread-3): 10:47:26 | 3 of 8 ERROR creating table model fetch_takehome.fact_items.......... [ERROR in 0.13s]
2021-05-20 14:47:26.233249 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-20 14:47:26.233423 (Thread-3): Began running node model.fetch_takehome.fact_users
2021-05-20 14:47:26.233882 (Thread-3): 10:47:26 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-20 14:47:26.234510 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.234652 (Thread-3): Compiling model.fetch_takehome.fact_users
2021-05-20 14:47:26.235860 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-20 14:47:26.236306 (Thread-3): finished collecting timing info
2021-05-20 14:47:26.240457 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.240616 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-20 14:47:26.240741 (Thread-3): Opening a new connection, currently in state closed
2021-05-20 14:47:26.250599 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.253110 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.253292 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 14:47:26.253712 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:26.256030 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-20 14:47:26.256541 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.256654 (Thread-3): On model.fetch_takehome.fact_users: BEGIN
2021-05-20 14:47:26.256969 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.257102 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.257199 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createdDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users_json_extract
  );
2021-05-20 14:47:26.268609 (Thread-3): SQL status: SELECT 495 in 0.01 seconds
2021-05-20 14:47:26.275833 (Thread-2): SQL status: SELECT 1167 in 0.06 seconds
2021-05-20 14:47:26.276116 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.276207 (Thread-4): SQL status: SELECT 1119 in 0.06 seconds
2021-05-20 14:47:26.278846 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.279001 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users" rename to "fact_users__dbt_backup"
2021-05-20 14:47:26.281083 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.281235 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-20 14:47:26.281478 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-20 14:47:26.283295 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.283514 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.283648 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.285732 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.287684 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.290080 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.290235 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users__dbt_tmp" rename to "fact_users"
2021-05-20 14:47:26.290345 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-20 14:47:26.290442 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-20 14:47:26.291046 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.291173 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.291251 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.304157 (Thread-3): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 14:47:26.304516 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 14:47:26.305624 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 14:47:26.305795 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.305944 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.306053 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.306149 (Thread-3): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 14:47:26.306243 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 14:47:26.306334 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 14:47:26.307521 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:26.310672 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:47:26.310842 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:26.311033 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:26.311181 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 14:47:26.312612 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:47:26.313900 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:47:26.314073 (Thread-1): SQL status: SELECT 1167 in 0.09 seconds
2021-05-20 14:47:26.314171 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 14:47:26.314257 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 14:47:26.316031 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.316284 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-20 14:47:26.316748 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.319089 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.319402 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-20 14:47:26.320105 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.321312 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 14:47:26.321428 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.321514 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 14:47:26.321706 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.321875 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.323305 (Thread-3): finished collecting timing info
2021-05-20 14:47:26.323408 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.323475 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:26.324440 (Thread-2): finished collecting timing info
2021-05-20 14:47:26.324584 (Thread-3): On model.fetch_takehome.fact_users: Close
2021-05-20 14:47:26.325512 (Thread-4): finished collecting timing info
2021-05-20 14:47:26.326825 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:47:26.326953 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-20 14:47:26.327317 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120e4a00>]}
2021-05-20 14:47:26.327419 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-20 14:47:26.327524 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 14:47:26.327905 (Thread-3): 10:47:26 | 5 of 8 OK created table model fetch_takehome.fact_users.............. [SELECT 495 in 0.09s]
2021-05-20 14:47:26.328159 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fd7430>]}
2021-05-20 14:47:26.328619 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120d5c40>]}
2021-05-20 14:47:26.328937 (Thread-3): Finished running node model.fetch_takehome.fact_users
2021-05-20 14:47:26.329266 (Thread-2): 10:47:26 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.23s]
2021-05-20 14:47:26.329550 (Thread-4): 10:47:26 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.22s]
2021-05-20 14:47:26.329773 (Thread-3): Began running node model.fetch_takehome.items_json_extract
2021-05-20 14:47:26.330115 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-20 14:47:26.330397 (Thread-3): 10:47:26 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-20 14:47:26.330490 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-20 14:47:26.330625 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-20 14:47:26.331009 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:47:26.331130 (Thread-4): Began running node model.fetch_takehome.users_json_extract
2021-05-20 14:47:26.331432 (Thread-2): 10:47:26 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-20 14:47:26.331562 (Thread-3): Compiling model.fetch_takehome.items_json_extract
2021-05-20 14:47:26.331751 (Thread-4): 10:47:26 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-20 14:47:26.332015 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:26.333632 (Thread-3): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 14:47:26.334253 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.334425 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-20 14:47:26.334702 (Thread-4): Compiling model.fetch_takehome.users_json_extract
2021-05-20 14:47:26.335905 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 14:47:26.337134 (Thread-4): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 14:47:26.337278 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.337541 (Thread-3): finished collecting timing info
2021-05-20 14:47:26.338883 (Thread-1): finished collecting timing info
2021-05-20 14:47:26.339031 (Thread-2): finished collecting timing info
2021-05-20 14:47:26.339131 (Thread-4): finished collecting timing info
2021-05-20 14:47:26.342995 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:47:26.343161 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-20 14:47:26.346297 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:26.349529 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-20 14:47:26.349036 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-20 14:47:26.349430 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120b1070>]}
2021-05-20 14:47:26.348892 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.349678 (Thread-2): Opening a new connection, currently in state closed
2021-05-20 14:47:26.349810 (Thread-3): Opening a new connection, currently in state closed
2021-05-20 14:47:26.350349 (Thread-1): 10:47:26 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.25s]
2021-05-20 14:47:26.350464 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-20 14:47:26.351054 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-20 14:47:26.351232 (Thread-4): Opening a new connection, currently in state closed
2021-05-20 14:47:26.361164 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.363517 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:26.363775 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 14:47:26.364117 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:26.365506 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 14:47:26.365757 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:47:26.368555 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.368737 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:47:26.368902 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 14:47:26.371247 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:47:26.371439 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:26.371615 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 14:47:26.371738 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-20 14:47:26.371914 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:26.372144 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:26.373346 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 14:47:26.373438 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.374884 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 14:47:26.375209 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:26.375571 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.375680 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-20 14:47:26.375856 (Thread-4): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-20 14:47:26.376097 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:47:26.376299 (Thread-3): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-20 14:47:26.376455 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.376622 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.376749 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:47:26.376835 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-20 14:47:26.376940 (Thread-3): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:47:26.377105 (Thread-3): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select receiptId, userId,
      json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
createDate,
dateScanned,
finishedDate,
modifyDate,
purchaseDate,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-20 14:47:26.378055 (Thread-3): Postgres error: column "createdate" does not exist
LINE 16: createDate,
         ^

2021-05-20 14:47:26.378248 (Thread-3): On model.fetch_takehome.items_json_extract: ROLLBACK
2021-05-20 14:47:26.378576 (Thread-3): finished collecting timing info
2021-05-20 14:47:26.378766 (Thread-3): On model.fetch_takehome.items_json_extract: Close
2021-05-20 14:47:26.379383 (Thread-3): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  column "createdate" does not exist
  LINE 16: createDate,
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "createdate" does not exist
LINE 16: createDate,
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
  column "createdate" does not exist
  LINE 16: createDate,
           ^
  compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-20 14:47:26.380112 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d7310>]}
2021-05-20 14:47:26.380499 (Thread-3): 10:47:26 | 6 of 8 ERROR creating table model fetch_takehome.items_json_extract.. [ERROR in 0.05s]
2021-05-20 14:47:26.380644 (Thread-3): Finished running node model.fetch_takehome.items_json_extract
2021-05-20 14:47:26.394638 (Thread-4): SQL status: SELECT 495 in 0.02 seconds
2021-05-20 14:47:26.396847 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.396976 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-20 14:47:26.397424 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.399489 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.399596 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-20 14:47:26.400067 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:26.401118 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 14:47:26.401230 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.401317 (Thread-4): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 14:47:26.401884 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:26.403865 (Thread-4): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:47:26.404083 (Thread-4): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 14:47:26.406887 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:26.408613 (Thread-4): finished collecting timing info
2021-05-20 14:47:26.408873 (Thread-4): On model.fetch_takehome.users_json_extract: Close
2021-05-20 14:47:26.409422 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112123850>]}
2021-05-20 14:47:26.409813 (Thread-4): 10:47:26 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.08s]
2021-05-20 14:47:26.409973 (Thread-4): Finished running node model.fetch_takehome.users_json_extract
2021-05-20 14:47:27.121955 (Thread-2): SQL status: SELECT 1119 in 0.75 seconds
2021-05-20 14:47:27.124371 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:27.124529 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-20 14:47:27.125065 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:27.127543 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:27.127689 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-20 14:47:27.128224 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:47:27.129476 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 14:47:27.129612 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:27.129707 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 14:47:27.130382 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:27.131944 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:47:27.132099 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 14:47:27.136725 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:47:27.138145 (Thread-2): finished collecting timing info
2021-05-20 14:47:27.138310 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-20 14:47:27.138701 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '42846410-3e16-43f2-8b87-8ae3c7e3230e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120b1f10>]}
2021-05-20 14:47:27.139010 (Thread-2): 10:47:27 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 0.81s]
2021-05-20 14:47:27.139146 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-20 14:47:27.140357 (MainThread): Acquiring new postgres connection "master".
2021-05-20 14:47:27.140519 (MainThread): Using postgres connection "master".
2021-05-20 14:47:27.140612 (MainThread): On master: BEGIN
2021-05-20 14:47:27.140724 (MainThread): Opening a new connection, currently in state closed
2021-05-20 14:47:27.150229 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:47:27.150418 (MainThread): On master: COMMIT
2021-05-20 14:47:27.150521 (MainThread): Using postgres connection "master".
2021-05-20 14:47:27.150613 (MainThread): On master: COMMIT
2021-05-20 14:47:27.150823 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:47:27.150977 (MainThread): On master: Close
2021-05-20 14:47:27.151373 (MainThread): 10:47:27 | 
2021-05-20 14:47:27.151530 (MainThread): 10:47:27 | Finished running 8 table models in 1.25s.
2021-05-20 14:47:27.151681 (MainThread): Connection 'master' was properly closed.
2021-05-20 14:47:27.151805 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-20 14:47:27.151927 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-20 14:47:27.152045 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-20 14:47:27.152163 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-20 14:47:27.157972 (MainThread): 
2021-05-20 14:47:27.158157 (MainThread): Completed with 2 errors and 0 warnings:
2021-05-20 14:47:27.158296 (MainThread): 
2021-05-20 14:47:27.158433 (MainThread): Database Error in model fact_items (models/transformations/fact_items.sql)
2021-05-20 14:47:27.158556 (MainThread):   column "createdate" does not exist
2021-05-20 14:47:27.158679 (MainThread):   LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
2021-05-20 14:47:27.158871 (MainThread):                         ^
2021-05-20 14:47:27.159025 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-20 14:47:27.159254 (MainThread): 
2021-05-20 14:47:27.159465 (MainThread): Database Error in model items_json_extract (models/json_extract/items_json_extract.sql)
2021-05-20 14:47:27.159628 (MainThread):   column "createdate" does not exist
2021-05-20 14:47:27.159786 (MainThread):   LINE 16: createDate,
2021-05-20 14:47:27.159901 (MainThread):            ^
2021-05-20 14:47:27.160010 (MainThread):   compiled SQL at target/run/fetch_takehome/models/json_extract/items_json_extract.sql
2021-05-20 14:47:27.160159 (MainThread): 
Done. PASS=6 WARN=0 ERROR=2 SKIP=0 TOTAL=8
2021-05-20 14:47:27.160359 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f8ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ea7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112109d60>]}
2021-05-20 14:47:27.160563 (MainThread): Flushing usage events
2021-05-20 14:48:31.498218 (MainThread): Running with dbt=0.19.1
2021-05-20 14:48:31.565883 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-20 14:48:31.566685 (MainThread): Tracking: tracking
2021-05-20 14:48:31.579364 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111853d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11187a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11187a790>]}
2021-05-20 14:48:31.592349 (MainThread): Partial parsing not enabled
2021-05-20 14:48:31.593458 (MainThread): Parsing macros/catalog.sql
2021-05-20 14:48:31.597273 (MainThread): Parsing macros/relations.sql
2021-05-20 14:48:31.598954 (MainThread): Parsing macros/adapters.sql
2021-05-20 14:48:31.621340 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-20 14:48:31.624390 (MainThread): Parsing macros/core.sql
2021-05-20 14:48:31.628822 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-20 14:48:31.638674 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-20 14:48:31.640606 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-20 14:48:31.661408 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-20 14:48:31.697407 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-20 14:48:31.719868 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-20 14:48:31.721926 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-20 14:48:31.728808 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-20 14:48:31.744004 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-20 14:48:31.751611 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-20 14:48:31.758579 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-20 14:48:31.764075 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-20 14:48:31.765216 (MainThread): Parsing macros/etc/query.sql
2021-05-20 14:48:31.766372 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-20 14:48:31.768286 (MainThread): Parsing macros/etc/datetime.sql
2021-05-20 14:48:31.778209 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-20 14:48:31.780365 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-20 14:48:31.782292 (MainThread): Parsing macros/adapters/common.sql
2021-05-20 14:48:31.828527 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-20 14:48:31.830605 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-20 14:48:31.832236 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-20 14:48:31.834068 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-20 14:48:31.841931 (MainThread): Partial parsing not enabled
2021-05-20 14:48:31.894059 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:31.904725 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:31.907855 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:31.911015 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:31.914287 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:48:31.917235 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:31.920981 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:31.923930 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:31.966990 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ac9c10>]}
2021-05-20 14:48:31.971130 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119f69a0>]}
2021-05-20 14:48:31.971345 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-20 14:48:31.971992 (MainThread): 
2021-05-20 14:48:31.972255 (MainThread): Acquiring new postgres connection "master".
2021-05-20 14:48:31.973255 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-20 14:48:31.982186 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-20 14:48:31.982311 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-20 14:48:31.982398 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-20 14:48:32.005194 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.02 seconds
2021-05-20 14:48:32.008238 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-20 14:48:32.009797 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:48:32.016496 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:48:32.016637 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-20 14:48:32.016744 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-20 14:48:32.024665 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:48:32.024827 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:48:32.024924 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-20 14:48:32.028021 (ThreadPoolExecutor-1_0): SQL status: SELECT 11 in 0.00 seconds
2021-05-20 14:48:32.028842 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-20 14:48:32.029052 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-20 14:48:32.034047 (MainThread): Using postgres connection "master".
2021-05-20 14:48:32.034198 (MainThread): On master: BEGIN
2021-05-20 14:48:32.034297 (MainThread): Opening a new connection, currently in state init
2021-05-20 14:48:32.042240 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:48:32.042399 (MainThread): Using postgres connection "master".
2021-05-20 14:48:32.042491 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-20 14:48:32.065617 (MainThread): SQL status: SELECT 1 in 0.02 seconds
2021-05-20 14:48:32.066154 (MainThread): On master: ROLLBACK
2021-05-20 14:48:32.066344 (MainThread): Using postgres connection "master".
2021-05-20 14:48:32.066430 (MainThread): On master: BEGIN
2021-05-20 14:48:32.066688 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.066799 (MainThread): On master: COMMIT
2021-05-20 14:48:32.066890 (MainThread): Using postgres connection "master".
2021-05-20 14:48:32.066966 (MainThread): On master: COMMIT
2021-05-20 14:48:32.067130 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:32.067231 (MainThread): On master: Close
2021-05-20 14:48:32.067488 (MainThread): 10:48:32 | Concurrency: 4 threads (target='dev')
2021-05-20 14:48:32.067603 (MainThread): 10:48:32 | 
2021-05-20 14:48:32.069658 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-20 14:48:32.069902 (Thread-1): 10:48:32 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-20 14:48:32.070165 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.070281 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-20 14:48:32.071337 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 14:48:32.071472 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-20 14:48:32.071680 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-20 14:48:32.071939 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-20 14:48:32.072176 (Thread-2): 10:48:32 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-20 14:48:32.072418 (Thread-3): 10:48:32 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-20 14:48:32.072535 (Thread-1): finished collecting timing info
2021-05-20 14:48:32.072723 (Thread-4): 10:48:32 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-20 14:48:32.072996 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.073314 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:48:32.085478 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.091848 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-20 14:48:32.093824 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.093984 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-20 14:48:32.094126 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-20 14:48:32.095234 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 14:48:32.095349 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-20 14:48:32.096450 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-20 14:48:32.097409 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 14:48:32.097660 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 14:48:32.098145 (Thread-2): finished collecting timing info
2021-05-20 14:48:32.098434 (Thread-3): finished collecting timing info
2021-05-20 14:48:32.101068 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.104925 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:48:32.105165 (Thread-4): finished collecting timing info
2021-05-20 14:48:32.105309 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-20 14:48:32.105458 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-20 14:48:32.108617 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.108906 (Thread-2): Opening a new connection, currently in state init
2021-05-20 14:48:32.109105 (Thread-3): Opening a new connection, currently in state init
2021-05-20 14:48:32.109282 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-20 14:48:32.109463 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:48:32.109976 (Thread-4): Opening a new connection, currently in state init
2021-05-20 14:48:32.112975 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.113355 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 14:48:32.113720 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.128142 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 14:48:32.128421 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:48:32.130773 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.130899 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 14:48:32.131059 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:48:32.131182 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:48:32.133184 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:48:32.133275 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.133401 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.135222 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.135342 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-20 14:48:32.136504 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 14:48:32.136620 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-20 14:48:32.136725 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 14:48:32.137098 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.137280 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.138631 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-20 14:48:32.138897 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.138986 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.139064 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.139304 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-20 14:48:32.140488 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 14:48:32.140601 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-20 14:48:32.140756 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:48:32.141100 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.141362 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-20 14:48:32.141511 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.141589 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.141770 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-20 14:48:32.141862 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.141987 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-20 14:48:32.142235 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:48:32.142346 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.142487 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-20 14:48:32.142612 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.142774 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-20 14:48:32.143260 (Thread-3): Postgres error: column "createdate" does not exist
LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                      ^

2021-05-20 14:48:32.143385 (Thread-3): On model.fetch_takehome.fact_items: ROLLBACK
2021-05-20 14:48:32.143614 (Thread-3): finished collecting timing info
2021-05-20 14:48:32.143797 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-20 14:48:32.144114 (Thread-3): Database Error in model fact_items (models/transformations/fact_items.sql)
  column "createdate" does not exist
  LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                        ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "createdate" does not exist
LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                      ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_items (models/transformations/fact_items.sql)
  column "createdate" does not exist
  LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
                        ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-20 14:48:32.146000 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b3ee20>]}
2021-05-20 14:48:32.146304 (Thread-3): 10:48:32 | 3 of 8 ERROR creating table model fetch_takehome.fact_items.......... [ERROR in 0.07s]
2021-05-20 14:48:32.146430 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-20 14:48:32.146557 (Thread-3): Began running node model.fetch_takehome.fact_users
2021-05-20 14:48:32.146910 (Thread-3): 10:48:32 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-20 14:48:32.147202 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.147310 (Thread-3): Compiling model.fetch_takehome.fact_users
2021-05-20 14:48:32.148646 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-20 14:48:32.148765 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-20 14:48:32.154865 (Thread-4): SQL status: SELECT 1119 in 0.01 seconds
2021-05-20 14:48:32.162899 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.163120 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-20 14:48:32.163674 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.163852 (Thread-3): finished collecting timing info
2021-05-20 14:48:32.164124 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-20 14:48:32.169157 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.169324 (Thread-2): SQL status: ALTER TABLE in 0.01 seconds
2021-05-20 14:48:32.169492 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-20 14:48:32.171686 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.171838 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.171966 (Thread-3): Opening a new connection, currently in state closed
2021-05-20 14:48:32.172095 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-20 14:48:32.174216 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.174664 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-20 14:48:32.175149 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.181019 (Thread-4): SQL status: ALTER TABLE in 0.01 seconds
2021-05-20 14:48:32.192243 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 14:48:32.192413 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:48:32.192528 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.194003 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 14:48:32.196447 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.196618 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 14:48:32.196780 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.196912 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 14:48:32.197135 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 14:48:32.197470 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.199025 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-20 14:48:32.199200 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:32.199350 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:32.204586 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:48:32.207090 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:48:32.207345 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 14:48:32.207648 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.207797 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 14:48:32.208165 (Thread-3): On model.fetch_takehome.fact_users: BEGIN
2021-05-20 14:48:32.208679 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.208861 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.209020 (Thread-1): SQL status: SELECT 1167 in 0.07 seconds
2021-05-20 14:48:32.209200 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createdDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users_json_extract
  );
2021-05-20 14:48:32.213086 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.213437 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:48:32.213607 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-20 14:48:32.213758 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:48:32.215748 (Thread-2): finished collecting timing info
2021-05-20 14:48:32.217950 (Thread-4): finished collecting timing info
2021-05-20 14:48:32.218201 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.218387 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-20 14:48:32.218647 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-20 14:48:32.220975 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.221152 (Thread-3): SQL status: SELECT 495 in 0.01 seconds
2021-05-20 14:48:32.221784 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c1c5b0>]}
2021-05-20 14:48:32.222216 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c10f70>]}
2021-05-20 14:48:32.222340 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-20 14:48:32.224903 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.225313 (Thread-2): 10:48:32 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.15s]
2021-05-20 14:48:32.225631 (Thread-4): 10:48:32 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.14s]
2021-05-20 14:48:32.225846 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users" rename to "fact_users__dbt_backup"
2021-05-20 14:48:32.226026 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-20 14:48:32.226285 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-20 14:48:32.226529 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.226661 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-20 14:48:32.226837 (Thread-4): Began running node model.fetch_takehome.receipts_json_extract
2021-05-20 14:48:32.227077 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.228281 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 14:48:32.228512 (Thread-2): 10:48:32 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-20 14:48:32.228706 (Thread-4): 10:48:32 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-20 14:48:32.230762 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.230887 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.231225 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:32.231472 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:32.231587 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users__dbt_tmp" rename to "fact_users"
2021-05-20 14:48:32.231691 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 14:48:32.231808 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-20 14:48:32.231912 (Thread-4): Compiling model.fetch_takehome.receipts_json_extract
2021-05-20 14:48:32.233338 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 14:48:32.233498 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.233621 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:32.234873 (Thread-4): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 14:48:32.236136 (Thread-3): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 14:48:32.237617 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:48:32.237869 (Thread-2): finished collecting timing info
2021-05-20 14:48:32.238022 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.238233 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 14:48:32.238386 (Thread-4): finished collecting timing info
2021-05-20 14:48:32.240847 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:32.240987 (Thread-3): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 14:48:32.243655 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:32.243837 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-20 14:48:32.243969 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.244376 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-20 14:48:32.244525 (Thread-2): Opening a new connection, currently in state closed
2021-05-20 14:48:32.247096 (Thread-1): finished collecting timing info
2021-05-20 14:48:32.247249 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:32.247351 (Thread-4): Opening a new connection, currently in state closed
2021-05-20 14:48:32.247695 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-20 14:48:32.249025 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:48:32.249697 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c31bb0>]}
2021-05-20 14:48:32.249833 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 14:48:32.250215 (Thread-1): 10:48:32 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.18s]
2021-05-20 14:48:32.250534 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-20 14:48:32.250755 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-20 14:48:32.251210 (Thread-1): 10:48:32 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-20 14:48:32.251705 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.251908 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-20 14:48:32.253915 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 14:48:32.254092 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.255939 (Thread-3): finished collecting timing info
2021-05-20 14:48:32.256119 (Thread-3): On model.fetch_takehome.fact_users: Close
2021-05-20 14:48:32.256634 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d4e4f0>]}
2021-05-20 14:48:32.256787 (Thread-1): finished collecting timing info
2021-05-20 14:48:32.257264 (Thread-3): 10:48:32 | 5 of 8 OK created table model fetch_takehome.fact_users.............. [SELECT 495 in 0.11s]
2021-05-20 14:48:32.260557 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.260849 (Thread-3): Finished running node model.fetch_takehome.fact_users
2021-05-20 14:48:32.260995 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:48:32.261264 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-20 14:48:32.264158 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:32.264381 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:48:32.264515 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 14:48:32.264666 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 14:48:32.267265 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:32.267798 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 14:48:32.268073 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.269596 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 14:48:32.269840 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.271460 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 14:48:32.271649 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:32.271881 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-20 14:48:32.272191 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.272375 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:32.272490 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select
    receiptId,
    userId,
    createDate,
    dateScanned,
    finishedDate,
    modifyDate,
    purchaseDate,
    json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
createDate,
dateScanned,
finishedDate,
modifyDate,
purchaseDate,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-20 14:48:32.272733 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:32.272854 (Thread-4): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-20 14:48:32.273105 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.273239 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:32.273333 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-20 14:48:32.276228 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:48:32.278439 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.278587 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 14:48:32.278914 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.280393 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 14:48:32.280908 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.281025 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-20 14:48:32.281303 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:48:32.281454 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.281586 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-20 14:48:32.297615 (Thread-1): SQL status: SELECT 495 in 0.02 seconds
2021-05-20 14:48:32.299801 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.299913 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-20 14:48:32.300274 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.302932 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.303124 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-20 14:48:32.303650 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:32.304795 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 14:48:32.304901 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.304976 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 14:48:32.305650 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:32.307406 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:48:32.307517 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 14:48:32.309212 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:32.310791 (Thread-1): finished collecting timing info
2021-05-20 14:48:32.310994 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-20 14:48:32.311360 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ae63a0>]}
2021-05-20 14:48:32.311763 (Thread-1): 10:48:32 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-20 14:48:32.311929 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-20 14:48:33.010947 (Thread-4): SQL status: SELECT 1119 in 0.74 seconds
2021-05-20 14:48:33.013540 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:33.013904 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-20 14:48:33.219260 (Thread-2): SQL status: SELECT 6941 in 0.95 seconds
2021-05-20 14:48:33.221257 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:33.221366 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-20 14:48:33.221750 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:33.223439 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:33.223529 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-20 14:48:33.224014 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:33.224917 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 14:48:33.225013 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:33.225088 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 14:48:33.225916 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:33.227206 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:48:33.227303 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 14:48:33.227420 (Thread-4): SQL status: ALTER TABLE in 0.21 seconds
2021-05-20 14:48:33.229205 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:33.229316 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-20 14:48:33.229415 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:33.230600 (Thread-2): finished collecting timing info
2021-05-20 14:48:33.230756 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:48:33.230890 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-20 14:48:33.231936 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 14:48:33.232287 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c291c0>]}
2021-05-20 14:48:33.232368 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:33.232655 (Thread-2): 10:48:33 | 6 of 8 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.00s]
2021-05-20 14:48:33.232755 (Thread-4): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 14:48:33.232938 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-20 14:48:33.233447 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:33.235007 (Thread-4): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:48:33.235110 (Thread-4): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 14:48:33.237109 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:48:33.238174 (Thread-4): finished collecting timing info
2021-05-20 14:48:33.238321 (Thread-4): On model.fetch_takehome.receipts_json_extract: Close
2021-05-20 14:48:33.238644 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd73678-e571-4740-9d2c-1c14e6f115b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c29520>]}
2021-05-20 14:48:33.238932 (Thread-4): 10:48:33 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.01s]
2021-05-20 14:48:33.239062 (Thread-4): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-20 14:48:33.240247 (MainThread): Acquiring new postgres connection "master".
2021-05-20 14:48:33.240399 (MainThread): Using postgres connection "master".
2021-05-20 14:48:33.240488 (MainThread): On master: BEGIN
2021-05-20 14:48:33.240577 (MainThread): Opening a new connection, currently in state closed
2021-05-20 14:48:33.248888 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:48:33.249067 (MainThread): On master: COMMIT
2021-05-20 14:48:33.249164 (MainThread): Using postgres connection "master".
2021-05-20 14:48:33.249246 (MainThread): On master: COMMIT
2021-05-20 14:48:33.249422 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:48:33.249535 (MainThread): On master: Close
2021-05-20 14:48:33.249881 (MainThread): 10:48:33 | 
2021-05-20 14:48:33.250005 (MainThread): 10:48:33 | Finished running 8 table models in 1.28s.
2021-05-20 14:48:33.250105 (MainThread): Connection 'master' was properly closed.
2021-05-20 14:48:33.250182 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-20 14:48:33.250259 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-20 14:48:33.250370 (MainThread): Connection 'model.fetch_takehome.fact_users' was properly closed.
2021-05-20 14:48:33.250463 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-20 14:48:33.255265 (MainThread): 
2021-05-20 14:48:33.255453 (MainThread): Completed with 1 error and 0 warnings:
2021-05-20 14:48:33.255618 (MainThread): 
2021-05-20 14:48:33.255779 (MainThread): Database Error in model fact_items (models/transformations/fact_items.sql)
2021-05-20 14:48:33.255923 (MainThread):   column "createdate" does not exist
2021-05-20 14:48:33.256055 (MainThread):   LINE 10: to_timestamp(createDate::numeric/1000)::date as createDate,
2021-05-20 14:48:33.256188 (MainThread):                         ^
2021-05-20 14:48:33.256318 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-20 14:48:33.256551 (MainThread): 
Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
2021-05-20 14:48:33.256776 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d4e820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a89910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d399d0>]}
2021-05-20 14:48:33.256975 (MainThread): Flushing usage events
2021-05-20 14:51:59.908258 (MainThread): Running with dbt=0.19.1
2021-05-20 14:51:59.991724 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-20 14:51:59.992734 (MainThread): Tracking: tracking
2021-05-20 14:52:00.009031 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d0ee80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d34670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d34eb0>]}
2021-05-20 14:52:00.023236 (MainThread): Partial parsing not enabled
2021-05-20 14:52:00.024661 (MainThread): Parsing macros/catalog.sql
2021-05-20 14:52:00.029286 (MainThread): Parsing macros/relations.sql
2021-05-20 14:52:00.031434 (MainThread): Parsing macros/adapters.sql
2021-05-20 14:52:00.055014 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-20 14:52:00.058167 (MainThread): Parsing macros/core.sql
2021-05-20 14:52:00.062536 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-20 14:52:00.072119 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-20 14:52:00.074053 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-20 14:52:00.093667 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-20 14:52:00.128710 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-20 14:52:00.150850 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-20 14:52:00.153136 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-20 14:52:00.159874 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-20 14:52:00.174708 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-20 14:52:00.182567 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-20 14:52:00.190163 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-20 14:52:00.196140 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-20 14:52:00.197383 (MainThread): Parsing macros/etc/query.sql
2021-05-20 14:52:00.198709 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-20 14:52:00.200682 (MainThread): Parsing macros/etc/datetime.sql
2021-05-20 14:52:00.211727 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-20 14:52:00.214017 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-20 14:52:00.215887 (MainThread): Parsing macros/adapters/common.sql
2021-05-20 14:52:00.261562 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-20 14:52:00.263703 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-20 14:52:00.265427 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-20 14:52:00.267340 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-20 14:52:00.275097 (MainThread): Partial parsing not enabled
2021-05-20 14:52:00.329363 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.340535 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.343911 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:00.347259 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:00.350679 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.353987 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.358145 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.361357 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.407263 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fb9c10>]}
2021-05-20 14:52:00.411582 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e9a640>]}
2021-05-20 14:52:00.411830 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-20 14:52:00.412489 (MainThread): 
2021-05-20 14:52:00.412755 (MainThread): Acquiring new postgres connection "master".
2021-05-20 14:52:00.413760 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-20 14:52:00.424228 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-20 14:52:00.424373 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-20 14:52:00.424478 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-20 14:52:00.454628 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.03 seconds
2021-05-20 14:52:00.459082 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-20 14:52:00.461619 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:52:00.468623 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:52:00.468776 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-20 14:52:00.468886 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-20 14:52:00.477537 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:52:00.477702 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 14:52:00.477805 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-20 14:52:00.480838 (ThreadPoolExecutor-1_0): SQL status: SELECT 11 in 0.00 seconds
2021-05-20 14:52:00.481651 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-20 14:52:00.481863 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-20 14:52:00.487160 (MainThread): Using postgres connection "master".
2021-05-20 14:52:00.487311 (MainThread): On master: BEGIN
2021-05-20 14:52:00.487422 (MainThread): Opening a new connection, currently in state init
2021-05-20 14:52:00.495741 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:52:00.495956 (MainThread): Using postgres connection "master".
2021-05-20 14:52:00.496107 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-20 14:52:00.528309 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-20 14:52:00.528897 (MainThread): On master: ROLLBACK
2021-05-20 14:52:00.529178 (MainThread): Using postgres connection "master".
2021-05-20 14:52:00.529289 (MainThread): On master: BEGIN
2021-05-20 14:52:00.529599 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.529721 (MainThread): On master: COMMIT
2021-05-20 14:52:00.529817 (MainThread): Using postgres connection "master".
2021-05-20 14:52:00.529897 (MainThread): On master: COMMIT
2021-05-20 14:52:00.530092 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:00.530230 (MainThread): On master: Close
2021-05-20 14:52:00.530569 (MainThread): 10:52:00 | Concurrency: 4 threads (target='dev')
2021-05-20 14:52:00.530707 (MainThread): 10:52:00 | 
2021-05-20 14:52:00.533424 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-20 14:52:00.533614 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-20 14:52:00.533852 (Thread-1): 10:52:00 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-20 14:52:00.533946 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-20 14:52:00.534112 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-20 14:52:00.534324 (Thread-2): 10:52:00 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-20 14:52:00.534646 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.534851 (Thread-3): 10:52:00 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-20 14:52:00.535057 (Thread-4): 10:52:00 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-20 14:52:00.535501 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.535659 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-20 14:52:00.535974 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.536298 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.536444 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-20 14:52:00.537774 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 14:52:00.537906 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-20 14:52:00.538017 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-20 14:52:00.539060 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 14:52:00.540352 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-20 14:52:00.542208 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 14:52:00.542380 (Thread-1): finished collecting timing info
2021-05-20 14:52:00.548271 (Thread-2): finished collecting timing info
2021-05-20 14:52:00.553736 (Thread-3): finished collecting timing info
2021-05-20 14:52:00.571934 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.579050 (Thread-4): finished collecting timing info
2021-05-20 14:52:00.581807 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.587423 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.587589 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-20 14:52:00.590145 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.590286 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-20 14:52:00.590391 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-20 14:52:00.590502 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 14:52:00.590594 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-20 14:52:00.590696 (Thread-3): Opening a new connection, currently in state init
2021-05-20 14:52:00.590786 (Thread-2): Opening a new connection, currently in state init
2021-05-20 14:52:00.591073 (Thread-4): Opening a new connection, currently in state init
2021-05-20 14:52:00.601078 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.601287 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.603899 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.606018 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.606170 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:52:00.606275 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 14:52:00.606359 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 14:52:00.606465 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 14:52:00.608457 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.610430 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.610741 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 14:52:00.610867 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.610960 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.611114 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-20 14:52:00.617119 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.622107 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 14:52:00.623243 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 14:52:00.624565 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 14:52:00.624726 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.625330 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.626338 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-20 14:52:00.626438 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.626586 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-20 14:52:00.626813 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.626917 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-20 14:52:00.627224 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-20 14:52:00.627314 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.627426 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.627676 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.627760 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.627818 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.627906 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-20 14:52:00.627986 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.628061 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-20 14:52:00.628142 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.628306 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-20 14:52:00.628417 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.628557 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-20 14:52:00.628700 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.628870 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
--to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-20 14:52:00.633716 (Thread-2): SQL status: SELECT 1167 in 0.00 seconds
2021-05-20 14:52:00.639544 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.639678 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-20 14:52:00.640084 (Thread-4): SQL status: SELECT 1119 in 0.01 seconds
2021-05-20 14:52:00.640275 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.642321 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.645285 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.645435 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-20 14:52:00.645586 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-20 14:52:00.646082 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.646222 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.648034 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.655619 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 14:52:00.655728 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-20 14:52:00.655855 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.656021 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 14:52:00.656432 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.658220 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 14:52:00.658398 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:00.658530 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.661463 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 14:52:00.661597 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 14:52:00.661724 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 14:52:00.662474 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:00.663981 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 14:52:00.664095 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 14:52:00.664268 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.665288 (Thread-2): finished collecting timing info
2021-05-20 14:52:00.665423 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-20 14:52:00.665779 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f440d0>]}
2021-05-20 14:52:00.666166 (Thread-2): 10:52:00 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.13s]
2021-05-20 14:52:00.666357 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-20 14:52:00.666573 (Thread-2): Began running node model.fetch_takehome.fact_users
2021-05-20 14:52:00.666809 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.667007 (Thread-2): 10:52:00 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-20 14:52:00.668174 (Thread-4): finished collecting timing info
2021-05-20 14:52:00.668599 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.668711 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-20 14:52:00.668851 (Thread-2): Compiling model.fetch_takehome.fact_users
2021-05-20 14:52:00.669306 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112127790>]}
2021-05-20 14:52:00.670429 (Thread-2): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-20 14:52:00.671035 (Thread-4): 10:52:00 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.13s]
2021-05-20 14:52:00.671156 (Thread-2): finished collecting timing info
2021-05-20 14:52:00.671331 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-20 14:52:00.673966 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.674120 (Thread-3): SQL status: SELECT 6941 in 0.05 seconds
2021-05-20 14:52:00.674245 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-20 14:52:00.674385 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-20 14:52:00.676296 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.676538 (Thread-4): 10:52:00 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-20 14:52:00.676642 (Thread-2): Opening a new connection, currently in state closed
2021-05-20 14:52:00.676724 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-20 14:52:00.677013 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:00.677395 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-20 14:52:00.678763 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 14:52:00.678893 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.680886 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.681001 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-20 14:52:00.681299 (Thread-4): finished collecting timing info
2021-05-20 14:52:00.683602 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:00.683726 (Thread-1): SQL status: SELECT 1167 in 0.06 seconds
2021-05-20 14:52:00.683820 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.683895 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-20 14:52:00.685887 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.687302 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-20 14:52:00.687438 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.687561 (Thread-4): Opening a new connection, currently in state closed
2021-05-20 14:52:00.687661 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-20 14:52:00.687764 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.689623 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.689974 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-20 14:52:00.690096 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 14:52:00.690226 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.692528 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.692675 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.692787 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:00.692882 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-20 14:52:00.694062 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-20 14:52:00.695379 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 14:52:00.695679 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-20 14:52:00.695966 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.696170 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.697312 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 14:52:00.697489 (Thread-2): On model.fetch_takehome.fact_users: BEGIN
2021-05-20 14:52:00.697673 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.697840 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 14:52:00.697984 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.698090 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.698171 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createdDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users_json_extract
  );
2021-05-20 14:52:00.698290 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.700352 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:00.700503 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 14:52:00.700845 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.702431 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 14:52:00.702571 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:00.702669 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.706148 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 14:52:00.706369 (Thread-2): SQL status: SELECT 495 in 0.01 seconds
2021-05-20 14:52:00.707648 (Thread-3): finished collecting timing info
2021-05-20 14:52:00.707978 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 14:52:00.708230 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:00.710448 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.710623 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-20 14:52:00.710859 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-20 14:52:00.711041 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users" rename to "fact_users__dbt_backup"
2021-05-20 14:52:00.711561 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121c6ca0>]}
2021-05-20 14:52:00.711706 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.712207 (Thread-3): 10:52:00 | 3 of 8 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.18s]
2021-05-20 14:52:00.712371 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:00.712492 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.712717 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-20 14:52:00.712891 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select
    receiptId,
    userId,
    createDate,
    dateScanned,
    finishedDate,
    modifyDate,
    purchaseDate,
    json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
createDate,
dateScanned,
finishedDate,
modifyDate,
purchaseDate,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-20 14:52:00.715440 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.715582 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.715725 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-20 14:52:00.716019 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users__dbt_tmp" rename to "fact_users"
2021-05-20 14:52:00.717147 (Thread-1): finished collecting timing info
2021-05-20 14:52:00.717411 (Thread-3): 10:52:00 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-20 14:52:00.717702 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-20 14:52:00.718113 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:00.718267 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.718498 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-20 14:52:00.718929 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120deb20>]}
2021-05-20 14:52:00.720098 (Thread-2): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 14:52:00.721425 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 14:52:00.721762 (Thread-1): 10:52:00 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.18s]
2021-05-20 14:52:00.721886 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.722335 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-20 14:52:00.722442 (Thread-2): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 14:52:00.722625 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-20 14:52:00.722767 (Thread-3): finished collecting timing info
2021-05-20 14:52:00.723189 (Thread-1): 10:52:00 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-20 14:52:00.725930 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:00.726413 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.726510 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-20 14:52:00.726645 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-20 14:52:00.726753 (Thread-3): Opening a new connection, currently in state closed
2021-05-20 14:52:00.728020 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 14:52:00.728186 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-05-20 14:52:00.729975 (Thread-2): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 14:52:00.730167 (Thread-2): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 14:52:00.730558 (Thread-1): finished collecting timing info
2021-05-20 14:52:00.733197 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.733326 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-20 14:52:00.733430 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 14:52:00.736036 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.737528 (Thread-2): finished collecting timing info
2021-05-20 14:52:00.737757 (Thread-2): On model.fetch_takehome.fact_users: Close
2021-05-20 14:52:00.738140 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f9d490>]}
2021-05-20 14:52:00.738292 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.738712 (Thread-2): 10:52:00 | 5 of 8 OK created table model fetch_takehome.fact_users.............. [SELECT 495 in 0.07s]
2021-05-20 14:52:00.740909 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:00.741193 (Thread-2): Finished running node model.fetch_takehome.fact_users
2021-05-20 14:52:00.741312 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 14:52:00.741787 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.743059 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 14:52:00.743505 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:00.743619 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-20 14:52:00.743855 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.743970 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:00.744064 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-20 14:52:00.744207 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 14:52:00.746479 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.746618 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 14:52:00.746956 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.749179 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 14:52:00.749664 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.749772 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-20 14:52:00.750110 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 14:52:00.750234 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.750325 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-20 14:52:00.769059 (Thread-1): SQL status: SELECT 495 in 0.02 seconds
2021-05-20 14:52:00.771323 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.771436 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-20 14:52:00.771884 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.773704 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.773815 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-20 14:52:00.774318 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:00.775286 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 14:52:00.775387 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.775464 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 14:52:00.776036 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:00.777242 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 14:52:00.777347 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 14:52:00.779064 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:00.780059 (Thread-1): finished collecting timing info
2021-05-20 14:52:00.780189 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-20 14:52:00.780530 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e9a4f0>]}
2021-05-20 14:52:00.780814 (Thread-1): 10:52:00 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.05s]
2021-05-20 14:52:00.780933 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-20 14:52:01.896462 (Thread-3): SQL status: SELECT 1119 in 1.15 seconds
2021-05-20 14:52:01.898922 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:01.899060 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-20 14:52:02.112804 (Thread-4): SQL status: SELECT 6941 in 1.40 seconds
2021-05-20 14:52:02.115180 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:02.115322 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-20 14:52:02.115824 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:02.118136 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:02.118322 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-20 14:52:02.119142 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:02.120517 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 14:52:02.120662 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:02.120762 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 14:52:02.121403 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:02.123067 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 14:52:02.123201 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 14:52:02.123358 (Thread-3): SQL status: ALTER TABLE in 0.22 seconds
2021-05-20 14:52:02.126927 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:02.127108 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:02.127214 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-20 14:52:02.128357 (Thread-4): finished collecting timing info
2021-05-20 14:52:02.128687 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-20 14:52:02.129192 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121aec40>]}
2021-05-20 14:52:02.129344 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 14:52:02.129750 (Thread-4): 10:52:02 | 6 of 8 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.45s]
2021-05-20 14:52:02.130969 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 14:52:02.131159 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-20 14:52:02.131321 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:02.131608 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 14:52:02.132227 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:02.133752 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 14:52:02.133890 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 14:52:02.136537 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 14:52:02.137775 (Thread-3): finished collecting timing info
2021-05-20 14:52:02.137937 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-20 14:52:02.138303 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68c552c2-1faa-423d-bf14-717f2c9b9086', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121e1f40>]}
2021-05-20 14:52:02.138619 (Thread-3): 10:52:02 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.42s]
2021-05-20 14:52:02.138762 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-20 14:52:02.140124 (MainThread): Acquiring new postgres connection "master".
2021-05-20 14:52:02.140297 (MainThread): Using postgres connection "master".
2021-05-20 14:52:02.140394 (MainThread): On master: BEGIN
2021-05-20 14:52:02.140492 (MainThread): Opening a new connection, currently in state closed
2021-05-20 14:52:02.149052 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-20 14:52:02.149237 (MainThread): On master: COMMIT
2021-05-20 14:52:02.149338 (MainThread): Using postgres connection "master".
2021-05-20 14:52:02.149425 (MainThread): On master: COMMIT
2021-05-20 14:52:02.149615 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 14:52:02.149734 (MainThread): On master: Close
2021-05-20 14:52:02.150100 (MainThread): 10:52:02 | 
2021-05-20 14:52:02.150236 (MainThread): 10:52:02 | Finished running 8 table models in 1.74s.
2021-05-20 14:52:02.150345 (MainThread): Connection 'master' was properly closed.
2021-05-20 14:52:02.150429 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-20 14:52:02.150532 (MainThread): Connection 'model.fetch_takehome.fact_users' was properly closed.
2021-05-20 14:52:02.150616 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-20 14:52:02.150692 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-20 14:52:02.155673 (MainThread): 
2021-05-20 14:52:02.155869 (MainThread): Completed successfully
2021-05-20 14:52:02.156016 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2021-05-20 14:52:02.156232 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fd6070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ea4e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121645e0>]}
2021-05-20 14:52:02.156450 (MainThread): Flushing usage events
2021-05-20 15:11:23.153297 (MainThread): Running with dbt=0.19.1
2021-05-20 15:11:24.153541 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-20 15:11:24.157846 (MainThread): Tracking: tracking
2021-05-20 15:11:24.342845 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e607ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e626700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e626f40>]}
2021-05-20 15:11:24.505329 (MainThread): Partial parsing not enabled
2021-05-20 15:11:24.520912 (MainThread): Parsing macros/catalog.sql
2021-05-20 15:11:24.559389 (MainThread): Parsing macros/relations.sql
2021-05-20 15:11:24.588293 (MainThread): Parsing macros/adapters.sql
2021-05-20 15:11:24.875054 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-20 15:11:24.922183 (MainThread): Parsing macros/core.sql
2021-05-20 15:11:24.975245 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-20 15:11:25.108442 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-20 15:11:25.139076 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-20 15:11:25.407979 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-20 15:11:25.875134 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-20 15:11:26.175852 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-20 15:11:26.207035 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-20 15:11:26.293321 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-20 15:11:26.493708 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-20 15:11:26.594507 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-20 15:11:26.691707 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-20 15:11:26.760751 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-20 15:11:26.776841 (MainThread): Parsing macros/etc/query.sql
2021-05-20 15:11:26.793274 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-20 15:11:26.812884 (MainThread): Parsing macros/etc/datetime.sql
2021-05-20 15:11:26.944464 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-20 15:11:26.976269 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-20 15:11:26.996264 (MainThread): Parsing macros/adapters/common.sql
2021-05-20 15:11:27.611811 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-20 15:11:27.643218 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-20 15:11:27.662314 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-20 15:11:27.692679 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-20 15:11:27.793559 (MainThread): Partial parsing not enabled
2021-05-20 15:11:28.312891 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:28.430984 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:28.465988 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:28.511435 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:28.547668 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:11:28.582467 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:28.630152 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:28.664894 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:29.266886 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e856610>]}
2021-05-20 15:11:29.316196 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e79cb50>]}
2021-05-20 15:11:29.317155 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-20 15:11:29.332469 (MainThread): 
2021-05-20 15:11:29.333799 (MainThread): Acquiring new postgres connection "master".
2021-05-20 15:11:29.362114 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-20 15:11:29.511445 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-20 15:11:29.512040 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-20 15:11:29.512494 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-20 15:11:29.983157 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.47 seconds
2021-05-20 15:11:30.028537 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-20 15:11:30.048902 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-20 15:11:30.134027 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 15:11:30.134524 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-20 15:11:30.145552 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-20 15:11:30.263080 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.12 seconds
2021-05-20 15:11:30.263750 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 15:11:30.264362 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-20 15:11:30.329076 (ThreadPoolExecutor-1_0): SQL status: SELECT 11 in 0.06 seconds
2021-05-20 15:11:30.334426 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-20 15:11:30.347302 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-20 15:11:30.431108 (MainThread): Using postgres connection "master".
2021-05-20 15:11:30.431821 (MainThread): On master: BEGIN
2021-05-20 15:11:30.432491 (MainThread): Opening a new connection, currently in state init
2021-05-20 15:11:30.565295 (MainThread): SQL status: BEGIN in 0.13 seconds
2021-05-20 15:11:30.566275 (MainThread): Using postgres connection "master".
2021-05-20 15:11:30.566867 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-20 15:11:31.081855 (MainThread): SQL status: SELECT 1 in 0.51 seconds
2021-05-20 15:11:31.084506 (MainThread): On master: ROLLBACK
2021-05-20 15:11:31.086067 (MainThread): Using postgres connection "master".
2021-05-20 15:11:31.097197 (MainThread): On master: BEGIN
2021-05-20 15:11:31.098915 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:11:31.099663 (MainThread): On master: COMMIT
2021-05-20 15:11:31.100260 (MainThread): Using postgres connection "master".
2021-05-20 15:11:31.100795 (MainThread): On master: COMMIT
2021-05-20 15:11:31.101938 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:11:31.102625 (MainThread): On master: Close
2021-05-20 15:11:31.114963 (MainThread): 11:11:31 | Concurrency: 4 threads (target='dev')
2021-05-20 15:11:31.115799 (MainThread): 11:11:31 | 
2021-05-20 15:11:31.149533 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-20 15:11:31.150461 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-20 15:11:31.151477 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-20 15:11:31.164308 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-20 15:11:31.152800 (Thread-1): 11:11:31 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-20 15:11:31.165553 (Thread-2): 11:11:31 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-20 15:11:31.166753 (Thread-3): 11:11:31 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-20 15:11:31.167723 (Thread-4): 11:11:31 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-20 15:11:31.169392 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:31.181691 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:31.183522 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:11:31.185927 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:31.197423 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-20 15:11:31.198261 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-20 15:11:31.198873 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-20 15:11:31.199412 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-20 15:11:31.216856 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 15:11:31.233979 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 15:11:31.250943 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-20 15:11:31.282697 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 15:11:31.298939 (Thread-1): finished collecting timing info
2021-05-20 15:11:31.336101 (Thread-4): finished collecting timing info
2021-05-20 15:11:31.364483 (Thread-3): finished collecting timing info
2021-05-20 15:11:31.365304 (Thread-2): finished collecting timing info
2021-05-20 15:11:32.218154 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:32.237738 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-20 15:11:32.269249 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:32.269596 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:32.269928 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 15:11:32.284384 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:11:32.285034 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-20 15:11:32.285711 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-20 15:11:32.287197 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-20 15:11:32.288096 (Thread-2): Opening a new connection, currently in state init
2021-05-20 15:11:32.299587 (Thread-4): Opening a new connection, currently in state init
2021-05-20 15:11:32.300211 (Thread-3): Opening a new connection, currently in state init
2021-05-20 15:11:32.399900 (Thread-1): SQL status: DROP TABLE in 0.13 seconds
2021-05-20 15:11:32.433769 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:32.434523 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 15:11:32.435861 (Thread-3): SQL status: DROP TABLE in 0.14 seconds
2021-05-20 15:11:32.449654 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:11:32.466121 (Thread-2): SQL status: DROP TABLE in 0.18 seconds
2021-05-20 15:11:32.466817 (Thread-4): SQL status: DROP TABLE in 0.17 seconds
2021-05-20 15:11:32.485068 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:11:32.550669 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:32.554228 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:32.571452 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-20 15:11:32.616070 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 15:11:32.666198 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 15:11:32.684957 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 15:11:32.686401 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:11:32.687126 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:11:32.687956 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:11:32.705520 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 15:11:32.721393 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-20 15:11:32.737424 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 15:11:32.750229 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:32.750998 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:32.752052 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-20 15:11:32.752802 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:11:32.753419 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-20 15:11:32.754317 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:32.754825 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:11:32.755152 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-20 15:11:32.766759 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-20 15:11:32.767431 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-05-20 15:11:32.767946 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:32.769390 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:32.770021 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:11:32.770386 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:11:32.770701 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-20 15:11:32.771137 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-20 15:11:32.771557 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:11:32.772052 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:32.784033 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
--to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteDescription as originalMetaBriteDescription,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-20 15:11:32.784631 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-20 15:11:32.801017 (Thread-3): Postgres error: column "originalmetabritedescription" does not exist
LINE 28: originalMetaBriteDescription as originalMetaBriteDescription...
         ^

2021-05-20 15:11:32.801785 (Thread-3): On model.fetch_takehome.fact_items: ROLLBACK
2021-05-20 15:11:32.803120 (Thread-3): finished collecting timing info
2021-05-20 15:11:32.803979 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-20 15:11:32.816636 (Thread-3): Database Error in model fact_items (models/transformations/fact_items.sql)
  column "originalmetabritedescription" does not exist
  LINE 28: originalMetaBriteDescription as originalMetaBriteDescription...
           ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 47, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "originalmetabritedescription" does not exist
LINE 28: originalMetaBriteDescription as originalMetaBriteDescription...
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 63, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 124, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.8/3.8.9/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.1_1/libexec/lib/python3.8/site-packages/dbt/adapters/postgres/connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fact_items (models/transformations/fact_items.sql)
  column "originalmetabritedescription" does not exist
  LINE 28: originalMetaBriteDescription as originalMetaBriteDescription...
           ^
  compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-20 15:11:32.867884 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea51190>]}
2021-05-20 15:11:32.869261 (Thread-3): 11:11:32 | 3 of 8 ERROR creating table model fetch_takehome.fact_items.......... [ERROR in 1.69s]
2021-05-20 15:11:32.869856 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-20 15:11:32.870418 (Thread-3): Began running node model.fetch_takehome.fact_users
2021-05-20 15:11:32.871629 (Thread-3): 11:11:32 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-20 15:11:32.883723 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:32.884308 (Thread-3): Compiling model.fetch_takehome.fact_users
2021-05-20 15:11:32.888989 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-20 15:11:32.902725 (Thread-3): finished collecting timing info
2021-05-20 15:11:32.933346 (Thread-2): SQL status: SELECT 1167 in 0.15 seconds
2021-05-20 15:11:32.968723 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:32.983656 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-20 15:11:32.984278 (Thread-4): SQL status: SELECT 1119 in 0.20 seconds
2021-05-20 15:11:33.005303 (Thread-3): Opening a new connection, currently in state closed
2021-05-20 15:11:33.039097 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:33.086092 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:33.086640 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-20 15:11:33.087372 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-20 15:11:33.101349 (Thread-2): SQL status: ALTER TABLE in 0.01 seconds
2021-05-20 15:11:33.102032 (Thread-4): SQL status: ALTER TABLE in 0.01 seconds
2021-05-20 15:11:33.154485 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:33.167166 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-20 15:11:33.184237 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:33.185130 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-20 15:11:33.201098 (Thread-2): SQL status: ALTER TABLE in 0.03 seconds
2021-05-20 15:11:33.367957 (Thread-4): SQL status: ALTER TABLE in 0.18 seconds
2021-05-20 15:11:33.451950 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 15:11:33.467639 (Thread-3): SQL status: DROP TABLE in 0.46 seconds
2021-05-20 15:11:33.484215 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:33.522115 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:33.522511 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 15:11:33.538019 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 15:11:33.538842 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 15:11:33.540090 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:33.551851 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 15:11:33.552881 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:11:33.572004 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-20 15:11:33.572766 (Thread-2): SQL status: COMMIT in 0.03 seconds
2021-05-20 15:11:33.634893 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:33.623457 (Thread-4): SQL status: COMMIT in 0.07 seconds
2021-05-20 15:11:33.653640 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:11:33.654116 (Thread-3): On model.fetch_takehome.fact_users: BEGIN
2021-05-20 15:11:33.684835 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 15:11:33.687927 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:11:33.689527 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 15:11:33.690251 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:11:33.702020 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:33.702680 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createdDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users_json_extract
  );
2021-05-20 15:11:33.801488 (Thread-4): SQL status: DROP TABLE in 0.10 seconds
2021-05-20 15:11:33.802138 (Thread-2): SQL status: DROP TABLE in 0.10 seconds
2021-05-20 15:11:33.820198 (Thread-4): finished collecting timing info
2021-05-20 15:11:33.835004 (Thread-3): SQL status: SELECT 495 in 0.13 seconds
2021-05-20 15:11:33.838146 (Thread-2): finished collecting timing info
2021-05-20 15:11:33.838977 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-20 15:11:33.868436 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-20 15:11:33.872304 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:33.885200 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea138b0>]}
2021-05-20 15:11:33.887100 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea55ee0>]}
2021-05-20 15:11:33.887669 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users" rename to "fact_users__dbt_backup"
2021-05-20 15:11:33.889433 (Thread-4): 11:11:33 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 2.69s]
2021-05-20 15:11:33.902428 (Thread-2): 11:11:33 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 2.71s]
2021-05-20 15:11:33.903790 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-20 15:11:33.904709 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-20 15:11:33.905224 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:11:33.906249 (Thread-4): Began running node model.fetch_takehome.items_json_extract
2021-05-20 15:11:33.907398 (Thread-2): Began running node model.fetch_takehome.receipts_json_extract
2021-05-20 15:11:33.953167 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:33.954139 (Thread-4): 11:11:33 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-20 15:11:33.954941 (Thread-2): 11:11:33 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-20 15:11:33.955636 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users__dbt_tmp" rename to "fact_users"
2021-05-20 15:11:33.956865 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:33.970077 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:33.970919 (Thread-4): Compiling model.fetch_takehome.items_json_extract
2021-05-20 15:11:33.971646 (Thread-2): Compiling model.fetch_takehome.receipts_json_extract
2021-05-20 15:11:33.972118 (Thread-3): SQL status: ALTER TABLE in 0.01 seconds
2021-05-20 15:11:34.002866 (Thread-4): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 15:11:34.003503 (Thread-1): SQL status: SELECT 1167 in 1.22 seconds
2021-05-20 15:11:34.019898 (Thread-2): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 15:11:34.024196 (Thread-3): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 15:11:34.071249 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:34.072204 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:34.072869 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-20 15:11:34.073278 (Thread-4): finished collecting timing info
2021-05-20 15:11:34.073768 (Thread-3): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 15:11:34.090895 (Thread-1): SQL status: ALTER TABLE in 0.02 seconds
2021-05-20 15:11:34.135545 (Thread-2): finished collecting timing info
2021-05-20 15:11:34.138051 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:34.119009 (Thread-3): SQL status: COMMIT in 0.02 seconds
2021-05-20 15:11:34.187098 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:34.187991 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-20 15:11:34.224010 (Thread-3): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:11:34.224452 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-20 15:11:34.237691 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:34.238320 (Thread-4): Opening a new connection, currently in state closed
2021-05-20 15:11:34.238747 (Thread-3): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 15:11:34.239743 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-20 15:11:34.240987 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:11:34.252591 (Thread-2): Opening a new connection, currently in state closed
2021-05-20 15:11:34.270807 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 15:11:34.272215 (Thread-3): SQL status: DROP TABLE in 0.03 seconds
2021-05-20 15:11:34.273044 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:34.286001 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 15:11:34.303032 (Thread-3): finished collecting timing info
2021-05-20 15:11:34.304080 (Thread-3): On model.fetch_takehome.fact_users: Close
2021-05-20 15:11:34.306703 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9c01c0>]}
2021-05-20 15:11:34.319260 (Thread-3): 11:11:34 | 5 of 8 OK created table model fetch_takehome.fact_users.............. [SELECT 495 in 1.43s]
2021-05-20 15:11:34.320222 (Thread-3): Finished running node model.fetch_takehome.fact_users
2021-05-20 15:11:34.321097 (Thread-3): Began running node model.fetch_takehome.users_json_extract
2021-05-20 15:11:34.322797 (Thread-3): 11:11:34 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-20 15:11:34.324512 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:34.335676 (Thread-3): Compiling model.fetch_takehome.users_json_extract
2021-05-20 15:11:34.354567 (Thread-3): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 15:11:34.355410 (Thread-1): SQL status: COMMIT in 0.05 seconds
2021-05-20 15:11:34.387485 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:11:34.388215 (Thread-3): finished collecting timing info
2021-05-20 15:11:34.389386 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 15:11:34.390195 (Thread-4): SQL status: DROP TABLE in 0.15 seconds
2021-05-20 15:11:34.439141 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:34.472547 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:34.473089 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-20 15:11:34.473599 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2021-05-20 15:11:34.474411 (Thread-2): SQL status: DROP TABLE in 0.22 seconds
2021-05-20 15:11:34.475133 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 15:11:34.486573 (Thread-3): Opening a new connection, currently in state closed
2021-05-20 15:11:34.504914 (Thread-1): finished collecting timing info
2021-05-20 15:11:34.537211 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:34.538237 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:11:34.539898 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-20 15:11:34.540715 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 15:11:34.571399 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 15:11:34.573620 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9993a0>]}
2021-05-20 15:11:34.588788 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:11:34.591213 (Thread-1): 11:11:34 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 3.40s]
2021-05-20 15:11:34.620108 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:34.621363 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 15:11:34.622201 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-20 15:11:34.622882 (Thread-4): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-20 15:11:34.636761 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:34.637644 (Thread-4): SQL status: BEGIN in 0.01 seconds
2021-05-20 15:11:34.638282 (Thread-2): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-20 15:11:34.638995 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:34.640230 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select
    receiptId,
    userId,
    createDate,
    dateScanned,
    finishedDate,
    modifyDate,
    purchaseDate,
    json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
createDate,
dateScanned,
finishedDate,
modifyDate,
purchaseDate,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteDescription')::varchar as originalMetaBriteDescription,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-20 15:11:34.641573 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:11:34.642262 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:34.653622 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-20 15:11:34.671724 (Thread-3): SQL status: DROP TABLE in 0.19 seconds
2021-05-20 15:11:34.706595 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:34.707312 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 15:11:34.708716 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:11:34.738306 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 15:11:34.740651 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:34.741259 (Thread-3): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-20 15:11:34.752955 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:11:34.753900 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:34.754528 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-20 15:11:35.270720 (Thread-3): SQL status: SELECT 495 in 0.52 seconds
2021-05-20 15:11:35.305802 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:35.306629 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-20 15:11:35.442978 (Thread-3): SQL status: ALTER TABLE in 0.14 seconds
2021-05-20 15:11:35.499740 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:35.501027 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-20 15:11:35.504834 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:11:35.511895 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 15:11:35.512530 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:35.523721 (Thread-3): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 15:11:35.550291 (Thread-3): SQL status: COMMIT in 0.03 seconds
2021-05-20 15:11:35.574120 (Thread-3): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:11:35.575261 (Thread-3): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 15:11:35.604189 (Thread-3): SQL status: DROP TABLE in 0.03 seconds
2021-05-20 15:11:35.610263 (Thread-3): finished collecting timing info
2021-05-20 15:11:35.611035 (Thread-3): On model.fetch_takehome.users_json_extract: Close
2021-05-20 15:11:35.623542 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e99deb0>]}
2021-05-20 15:11:35.625826 (Thread-3): 11:11:35 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 1.29s]
2021-05-20 15:11:35.626542 (Thread-3): Finished running node model.fetch_takehome.users_json_extract
2021-05-20 15:11:39.652763 (Thread-2): SQL status: SELECT 1119 in 5.00 seconds
2021-05-20 15:11:39.660554 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:39.660954 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-20 15:11:40.850637 (Thread-4): SQL status: SELECT 6941 in 6.21 seconds
2021-05-20 15:11:40.856944 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:40.857307 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-20 15:11:40.858378 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:11:40.863985 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:40.864308 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-20 15:11:40.865692 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:11:40.870201 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 15:11:40.870706 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:40.871074 (Thread-4): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 15:11:40.872771 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:11:40.881105 (Thread-2): SQL status: ALTER TABLE in 1.22 seconds
2021-05-20 15:11:40.881816 (Thread-4): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:11:40.887069 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:40.887423 (Thread-4): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 15:11:40.887808 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-20 15:11:40.889324 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:11:40.892623 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 15:11:40.892959 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:40.893230 (Thread-2): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 15:11:40.894224 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:11:40.894576 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:11:40.897310 (Thread-4): finished collecting timing info
2021-05-20 15:11:40.901270 (Thread-2): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:11:40.901652 (Thread-4): On model.fetch_takehome.items_json_extract: Close
2021-05-20 15:11:40.901949 (Thread-2): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 15:11:40.902875 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb48d30>]}
2021-05-20 15:11:40.903896 (Thread-4): 11:11:40 | 6 of 8 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 6.95s]
2021-05-20 15:11:40.904438 (Thread-4): Finished running node model.fetch_takehome.items_json_extract
2021-05-20 15:11:40.909448 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:11:40.912367 (Thread-2): finished collecting timing info
2021-05-20 15:11:40.912761 (Thread-2): On model.fetch_takehome.receipts_json_extract: Close
2021-05-20 15:11:40.913676 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55b9ce4a-998b-4819-83c6-48652764e395', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaf9460>]}
2021-05-20 15:11:40.914439 (Thread-2): 11:11:40 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 6.95s]
2021-05-20 15:11:40.914799 (Thread-2): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-20 15:11:40.918892 (MainThread): Acquiring new postgres connection "master".
2021-05-20 15:11:40.919452 (MainThread): Using postgres connection "master".
2021-05-20 15:11:40.919751 (MainThread): On master: BEGIN
2021-05-20 15:11:40.920097 (MainThread): Opening a new connection, currently in state closed
2021-05-20 15:11:40.943806 (MainThread): SQL status: BEGIN in 0.02 seconds
2021-05-20 15:11:40.944228 (MainThread): On master: COMMIT
2021-05-20 15:11:40.944494 (MainThread): Using postgres connection "master".
2021-05-20 15:11:40.944730 (MainThread): On master: COMMIT
2021-05-20 15:11:40.945360 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:11:40.945736 (MainThread): On master: Close
2021-05-20 15:11:40.946666 (MainThread): 11:11:40 | 
2021-05-20 15:11:40.947034 (MainThread): 11:11:40 | Finished running 8 table models in 11.61s.
2021-05-20 15:11:40.947364 (MainThread): Connection 'master' was properly closed.
2021-05-20 15:11:40.947698 (MainThread): Connection 'model.fetch_takehome.brands_json_extract' was properly closed.
2021-05-20 15:11:40.948030 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-20 15:11:40.948350 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-20 15:11:40.948663 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-20 15:11:40.962549 (MainThread): 
2021-05-20 15:11:40.962965 (MainThread): Completed with 1 error and 0 warnings:
2021-05-20 15:11:40.963289 (MainThread): 
2021-05-20 15:11:40.963597 (MainThread): Database Error in model fact_items (models/transformations/fact_items.sql)
2021-05-20 15:11:40.963891 (MainThread):   column "originalmetabritedescription" does not exist
2021-05-20 15:11:40.964407 (MainThread):   LINE 28: originalMetaBriteDescription as originalMetaBriteDescription...
2021-05-20 15:11:40.964728 (MainThread):            ^
2021-05-20 15:11:40.965004 (MainThread):   compiled SQL at target/run/fetch_takehome/models/transformations/fact_items.sql
2021-05-20 15:11:40.965364 (MainThread): 
Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
2021-05-20 15:11:40.966228 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6884f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e79ca60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9aec10>]}
2021-05-20 15:11:40.967026 (MainThread): Flushing usage events
2021-05-20 15:12:25.196077 (MainThread): Running with dbt=0.19.1
2021-05-20 15:12:25.274653 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/amy/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-05-20 15:12:25.275705 (MainThread): Tracking: tracking
2021-05-20 15:12:25.290148 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b8c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134e4550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134e4790>]}
2021-05-20 15:12:25.303250 (MainThread): Partial parsing not enabled
2021-05-20 15:12:25.304676 (MainThread): Parsing macros/catalog.sql
2021-05-20 15:12:25.308567 (MainThread): Parsing macros/relations.sql
2021-05-20 15:12:25.310416 (MainThread): Parsing macros/adapters.sql
2021-05-20 15:12:25.331434 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-05-20 15:12:25.334641 (MainThread): Parsing macros/core.sql
2021-05-20 15:12:25.339199 (MainThread): Parsing macros/materializations/helpers.sql
2021-05-20 15:12:25.348636 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-05-20 15:12:25.350613 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-05-20 15:12:25.371067 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-05-20 15:12:25.408263 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-05-20 15:12:25.431859 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-05-20 15:12:25.434084 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-05-20 15:12:25.441799 (MainThread): Parsing macros/materializations/common/merge.sql
2021-05-20 15:12:25.456776 (MainThread): Parsing macros/materializations/table/table.sql
2021-05-20 15:12:25.464291 (MainThread): Parsing macros/materializations/view/view.sql
2021-05-20 15:12:25.471550 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-05-20 15:12:25.476959 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-05-20 15:12:25.478110 (MainThread): Parsing macros/etc/query.sql
2021-05-20 15:12:25.479337 (MainThread): Parsing macros/etc/is_incremental.sql
2021-05-20 15:12:25.481554 (MainThread): Parsing macros/etc/datetime.sql
2021-05-20 15:12:25.490812 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-05-20 15:12:25.493217 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-05-20 15:12:25.495111 (MainThread): Parsing macros/adapters/common.sql
2021-05-20 15:12:25.540481 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-05-20 15:12:25.542524 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-05-20 15:12:25.544215 (MainThread): Parsing macros/schema_tests/unique.sql
2021-05-20 15:12:25.546113 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-05-20 15:12:25.554002 (MainThread): Partial parsing not enabled
2021-05-20 15:12:25.609177 (MainThread): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.620428 (MainThread): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:25.623787 (MainThread): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:25.627313 (MainThread): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:25.630746 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.633726 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.637556 (MainThread): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:25.640647 (MainThread): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.685207 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113733c10>]}
2021-05-20 15:12:25.690013 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113652fa0>]}
2021-05-20 15:12:25.690261 (MainThread): Found 8 models, 0 tests, 0 snapshots, 0 analyses, 138 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-05-20 15:12:25.690938 (MainThread): 
2021-05-20 15:12:25.691211 (MainThread): Acquiring new postgres connection "master".
2021-05-20 15:12:25.692244 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2021-05-20 15:12:25.701052 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2021-05-20 15:12:25.701159 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2021-05-20 15:12:25.701244 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-05-20 15:12:25.738609 (ThreadPoolExecutor-0_0): SQL status: SELECT 6 in 0.04 seconds
2021-05-20 15:12:25.741599 (ThreadPoolExecutor-0_0): On list_postgres: Close
2021-05-20 15:12:25.743103 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_fetch_takehome".
2021-05-20 15:12:25.749298 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 15:12:25.749436 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: BEGIN
2021-05-20 15:12:25.749543 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-05-20 15:12:25.757817 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-05-20 15:12:25.757979 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_fetch_takehome".
2021-05-20 15:12:25.758074 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "list_postgres_fetch_takehome"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'fetch_takehome'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'fetch_takehome'
  
2021-05-20 15:12:25.761062 (ThreadPoolExecutor-1_0): SQL status: SELECT 11 in 0.00 seconds
2021-05-20 15:12:25.761873 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: ROLLBACK
2021-05-20 15:12:25.762073 (ThreadPoolExecutor-1_0): On list_postgres_fetch_takehome: Close
2021-05-20 15:12:25.767392 (MainThread): Using postgres connection "master".
2021-05-20 15:12:25.767547 (MainThread): On master: BEGIN
2021-05-20 15:12:25.767701 (MainThread): Opening a new connection, currently in state init
2021-05-20 15:12:25.777552 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-05-20 15:12:25.777731 (MainThread): Using postgres connection "master".
2021-05-20 15:12:25.777833 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-05-20 15:12:25.807079 (MainThread): SQL status: SELECT 1 in 0.03 seconds
2021-05-20 15:12:25.807662 (MainThread): On master: ROLLBACK
2021-05-20 15:12:25.807966 (MainThread): Using postgres connection "master".
2021-05-20 15:12:25.808093 (MainThread): On master: BEGIN
2021-05-20 15:12:25.808416 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.808531 (MainThread): On master: COMMIT
2021-05-20 15:12:25.808615 (MainThread): Using postgres connection "master".
2021-05-20 15:12:25.808686 (MainThread): On master: COMMIT
2021-05-20 15:12:25.808863 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:25.808964 (MainThread): On master: Close
2021-05-20 15:12:25.809239 (MainThread): 11:12:25 | Concurrency: 4 threads (target='dev')
2021-05-20 15:12:25.809366 (MainThread): 11:12:25 | 
2021-05-20 15:12:25.812029 (Thread-1): Began running node model.fetch_takehome.brands_json_extract
2021-05-20 15:12:25.812307 (Thread-1): 11:12:25 | 1 of 8 START table model fetch_takehome.brands_json_extract.......... [RUN]
2021-05-20 15:12:25.812590 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.812739 (Thread-1): Compiling model.fetch_takehome.brands_json_extract
2021-05-20 15:12:25.813885 (Thread-1): Writing injected SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 15:12:25.814108 (Thread-2): Began running node model.fetch_takehome.dim_brands
2021-05-20 15:12:25.814270 (Thread-3): Began running node model.fetch_takehome.fact_items
2021-05-20 15:12:25.814612 (Thread-2): 11:12:25 | 2 of 8 START table model fetch_takehome.dim_brands................... [RUN]
2021-05-20 15:12:25.814714 (Thread-4): Began running node model.fetch_takehome.fact_receipts
2021-05-20 15:12:25.814941 (Thread-3): 11:12:25 | 3 of 8 START table model fetch_takehome.fact_items................... [RUN]
2021-05-20 15:12:25.815387 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.815534 (Thread-1): finished collecting timing info
2021-05-20 15:12:25.815969 (Thread-4): 11:12:25 | 4 of 8 START table model fetch_takehome.fact_receipts................ [RUN]
2021-05-20 15:12:25.816364 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.816472 (Thread-2): Compiling model.fetch_takehome.dim_brands
2021-05-20 15:12:25.822333 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.828674 (Thread-3): Compiling model.fetch_takehome.fact_items
2021-05-20 15:12:25.837723 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.838926 (Thread-2): Writing injected SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 15:12:25.839070 (Thread-4): Compiling model.fetch_takehome.fact_receipts
2021-05-20 15:12:25.840210 (Thread-3): Writing injected SQL for node "model.fetch_takehome.fact_items"
2021-05-20 15:12:25.840322 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" cascade
2021-05-20 15:12:25.841333 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 15:12:25.841594 (Thread-2): finished collecting timing info
2021-05-20 15:12:25.841686 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 15:12:25.841993 (Thread-3): finished collecting timing info
2021-05-20 15:12:25.844371 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.844787 (Thread-4): finished collecting timing info
2021-05-20 15:12:25.847538 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.847693 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_tmp" cascade
2021-05-20 15:12:25.850266 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.850414 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_tmp" cascade
2021-05-20 15:12:25.850525 (Thread-2): Opening a new connection, currently in state init
2021-05-20 15:12:25.850658 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" cascade
2021-05-20 15:12:25.850784 (Thread-3): Opening a new connection, currently in state init
2021-05-20 15:12:25.851103 (Thread-4): Opening a new connection, currently in state init
2021-05-20 15:12:25.854235 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:25.856737 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.856941 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 15:12:25.857301 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.868933 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.brands_json_extract"
2021-05-20 15:12:25.869195 (Thread-2): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 15:12:25.871361 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.871483 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 15:12:25.871617 (Thread-4): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 15:12:25.871728 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.871796 (Thread-3): SQL status: DROP TABLE in 0.02 seconds
2021-05-20 15:12:25.873643 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.874719 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.dim_brands"
2021-05-20 15:12:25.876302 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.876401 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.876492 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 15:12:25.876702 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-20 15:12:25.876858 (Thread-1): On model.fetch_takehome.brands_json_extract: BEGIN
2021-05-20 15:12:25.877063 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.877191 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.877412 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.877503 (Thread-2): On model.fetch_takehome.dim_brands: BEGIN
2021-05-20 15:12:25.877567 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.878593 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_receipts"
2021-05-20 15:12:25.879645 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.fact_items"
2021-05-20 15:12:25.879847 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.879954 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.880328 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */


  create  table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as brandId,
json_extract_path_text (to_json(json_txt), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(json_txt), 'category')::varchar as category,
json_extract_path_text (to_json(json_txt), 'categoryCode')::varchar as categoryCode,
json_extract_path_text (to_json(json_txt), 'cpg', '$id', '$oid')::varchar as cpgId,
json_extract_path_text (to_json(json_txt), 'cpg', '$ref')::varchar as cpgRef,
json_extract_path_text (to_json(json_txt), 'name')::varchar as brandName,
json_extract_path_text (to_json(json_txt), 'brandCode')::varchar as brandCode,
json_extract_path_text (to_json(json_txt), 'topBrand')::varchar as topBrand
from fetch_takehome.brands
  );
2021-05-20 15:12:25.880496 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.880690 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.880963 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.881049 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */


  create  table "postgres"."fetch_takehome"."dim_brands__dbt_tmp"
  as (
    select
brandId as brandId,
barcode as barcode,
category as category,
categoryCode as categoryCode,
cpgId as cpgId,
cpgRef as cpgRef,
brandName as brandName,
brandCode as brandCode,
topBrand::boolean as topBrand
from fetch_takehome.brands_json_extract
  );
2021-05-20 15:12:25.881170 (Thread-4): On model.fetch_takehome.fact_receipts: BEGIN
2021-05-20 15:12:25.881282 (Thread-3): On model.fetch_takehome.fact_items: BEGIN
2021-05-20 15:12:25.881605 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.881744 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.881832 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.881933 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.882040 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */


  create  table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp"
  as (
    select
receiptId as receiptId,
bonusPointsEarned::numeric as bonusPointsEarned,
bonusPointsEarnedReason as bonusPointsEarnedReason,
to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(pointsAwardedDate::numeric/1000) as pointsAwardedDate,
pointsEarned::numeric as pointsEarned,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
purchasedItemCount::numeric as purchasedItemCount,
rewardsReceiptStatus as rewardsReceiptStatus,
totalSpent::numeric as totalSpent,
userId as userId
from fetch_takehome.receipts_json_extract
  );
2021-05-20 15:12:25.882169 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */


  create  table "postgres"."fetch_takehome"."fact_items__dbt_tmp"
  as (
    select
receiptId as receiptId,
userId as userId,
barcode as barcode,
--to_timestamp(createDate::numeric/1000)::date as createDate,
to_timestamp(dateScanned::numeric / 1000)::date as dateScanned,
to_timestamp(finishedDate::numeric / 1000)::date as finishedDate,
to_timestamp(modifyDate::numeric / 1000)::date as modifyDate,
to_timestamp(purchaseDate::numeric/1000) as purchaseDate,
finalPrice::numeric as finalPrice,
itemPrice::numeric as itemPrice,
partnerItemId as partnerItemId,
pointsEarned::numeric as pointsEarned,
pointsPayerId as pointsPayerId,
quantityPurchased::numeric as quantityPurchased,
rewardsGroup as rewardsGroup,
rewardsProductPartnerId as rewardsProductPartnerId,
targetPrice::numeric as targetPrice,
competitiveProduct::boolean as competitiveProduct,
needsFetchReview as needsFetchReview,
originalFinalPrice::numeric as originalFinalPrice,
originalMetaBriteBarcode as originalMetaBriteBarcode,
originalMetaBriteDescription as originalMetaBriteDescription,
originalMetaBriteItemPrice::numeric as originalMetaBriteItemPrice,
originalMetaBriteQuantityPurchased::numeric as originalMetaBriteQuantityPurchased,
preventTargetGapPoints as preventTargetGapPoints,
userFlaggedBarcode as userFlaggedBarcode,
userFlaggedNewItem as userFlaggedNewItem,
userFlaggedPrice::numeric as userFlaggedPrice,
userFlaggedQuantity::integer as userFlaggedQuantity,
itemNumber as itemNumber,
priceAfterCoupon::numeric as priceAfterCoupon,
needsFetchReviewReason as needsFetchReviewReason,
metabriteCampaignId as metabriteCampaignId,
discountedItemPrice::numeric as discountedItemPrice,
competitorRewardsGroup as competitorRewardsGroup,
originalReceiptItemText as originalReceiptItemText,
pointsNotAwardedReason as pointsNotAwardedReason
from fetch_takehome.items_json_extract
  );
2021-05-20 15:12:25.888118 (Thread-2): SQL status: SELECT 1167 in 0.01 seconds
2021-05-20 15:12:25.894246 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.894392 (Thread-4): SQL status: SELECT 1119 in 0.01 seconds
2021-05-20 15:12:25.894499 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands" rename to "dim_brands__dbt_backup"
2021-05-20 15:12:25.896549 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.896742 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts" rename to "fact_receipts__dbt_backup"
2021-05-20 15:12:25.897020 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.897127 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.899007 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.901786 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.901915 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
alter table "postgres"."fetch_takehome"."dim_brands__dbt_tmp" rename to "dim_brands"
2021-05-20 15:12:25.902052 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
alter table "postgres"."fetch_takehome"."fact_receipts__dbt_tmp" rename to "fact_receipts"
2021-05-20 15:12:25.902611 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.902746 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.913738 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 15:12:25.914574 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 15:12:25.914668 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.914784 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.914895 (Thread-4): On model.fetch_takehome.fact_receipts: COMMIT
2021-05-20 15:12:25.915003 (Thread-2): On model.fetch_takehome.dim_brands: COMMIT
2021-05-20 15:12:25.917494 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:25.921038 (Thread-4): Using postgres connection "model.fetch_takehome.fact_receipts".
2021-05-20 15:12:25.921188 (Thread-3): SQL status: SELECT 6941 in 0.04 seconds
2021-05-20 15:12:25.921275 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-05-20 15:12:25.921349 (Thread-4): On model.fetch_takehome.fact_receipts: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_receipts"} */
drop table if exists "postgres"."fetch_takehome"."fact_receipts__dbt_backup" cascade
2021-05-20 15:12:25.923205 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.924536 (Thread-2): Using postgres connection "model.fetch_takehome.dim_brands".
2021-05-20 15:12:25.924746 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items" rename to "fact_items__dbt_backup"
2021-05-20 15:12:25.924903 (Thread-2): On model.fetch_takehome.dim_brands: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.dim_brands"} */
drop table if exists "postgres"."fetch_takehome"."dim_brands__dbt_backup" cascade
2021-05-20 15:12:25.925430 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.927637 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.927792 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.927896 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.927988 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
alter table "postgres"."fetch_takehome"."fact_items__dbt_tmp" rename to "fact_items"
2021-05-20 15:12:25.929051 (Thread-4): finished collecting timing info
2021-05-20 15:12:25.930133 (Thread-2): finished collecting timing info
2021-05-20 15:12:25.930375 (Thread-4): On model.fetch_takehome.fact_receipts: Close
2021-05-20 15:12:25.930520 (Thread-2): On model.fetch_takehome.dim_brands: Close
2021-05-20 15:12:25.930994 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113887ca0>]}
2021-05-20 15:12:25.931401 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136fdf10>]}
2021-05-20 15:12:25.931788 (Thread-4): 11:12:25 | 4 of 8 OK created table model fetch_takehome.fact_receipts........... [SELECT 1119 in 0.11s]
2021-05-20 15:12:25.931945 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.932051 (Thread-1): SQL status: SELECT 1167 in 0.05 seconds
2021-05-20 15:12:25.932275 (Thread-4): Finished running node model.fetch_takehome.fact_receipts
2021-05-20 15:12:25.932647 (Thread-2): 11:12:25 | 2 of 8 OK created table model fetch_takehome.dim_brands.............. [SELECT 1167 in 0.12s]
2021-05-20 15:12:25.933749 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-20 15:12:25.935604 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.935753 (Thread-4): Began running node model.fetch_takehome.fact_users
2021-05-20 15:12:25.935988 (Thread-2): Finished running node model.fetch_takehome.dim_brands
2021-05-20 15:12:25.936139 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.936240 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract" rename to "brands_json_extract__dbt_backup"
2021-05-20 15:12:25.936445 (Thread-4): 11:12:25 | 5 of 8 START table model fetch_takehome.fact_users................... [RUN]
2021-05-20 15:12:25.936580 (Thread-2): Began running node model.fetch_takehome.items_json_extract
2021-05-20 15:12:25.936785 (Thread-3): On model.fetch_takehome.fact_items: COMMIT
2021-05-20 15:12:25.937369 (Thread-4): Acquiring new postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:25.937575 (Thread-2): 11:12:25 | 6 of 8 START table model fetch_takehome.items_json_extract........... [RUN]
2021-05-20 15:12:25.937760 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.937908 (Thread-4): Compiling model.fetch_takehome.fact_users
2021-05-20 15:12:25.938194 (Thread-2): Acquiring new postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:25.940232 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.940313 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:25.941474 (Thread-4): Writing injected SQL for node "model.fetch_takehome.fact_users"
2021-05-20 15:12:25.941609 (Thread-2): Compiling model.fetch_takehome.items_json_extract
2021-05-20 15:12:25.941707 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
alter table "postgres"."fetch_takehome"."brands_json_extract__dbt_tmp" rename to "brands_json_extract"
2021-05-20 15:12:25.942894 (Thread-3): Using postgres connection "model.fetch_takehome.fact_items".
2021-05-20 15:12:25.944164 (Thread-2): Writing injected SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 15:12:25.944460 (Thread-3): On model.fetch_takehome.fact_items: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_items"} */
drop table if exists "postgres"."fetch_takehome"."fact_items__dbt_backup" cascade
2021-05-20 15:12:25.944608 (Thread-4): finished collecting timing info
2021-05-20 15:12:25.944765 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:25.947959 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:25.948116 (Thread-2): finished collecting timing info
2021-05-20 15:12:25.949267 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 15:12:25.949383 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_tmp" cascade
2021-05-20 15:12:25.951719 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:25.951874 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.952000 (Thread-4): Opening a new connection, currently in state closed
2021-05-20 15:12:25.952110 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" cascade
2021-05-20 15:12:25.952307 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:25.952391 (Thread-1): On model.fetch_takehome.brands_json_extract: COMMIT
2021-05-20 15:12:25.952679 (Thread-2): Opening a new connection, currently in state closed
2021-05-20 15:12:25.953855 (Thread-3): finished collecting timing info
2021-05-20 15:12:25.954364 (Thread-3): On model.fetch_takehome.fact_items: Close
2021-05-20 15:12:25.954568 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:25.955018 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113887f70>]}
2021-05-20 15:12:25.956812 (Thread-1): Using postgres connection "model.fetch_takehome.brands_json_extract".
2021-05-20 15:12:25.957356 (Thread-3): 11:12:25 | 3 of 8 OK created table model fetch_takehome.fact_items.............. [SELECT 6941 in 0.14s]
2021-05-20 15:12:25.957486 (Thread-1): On model.fetch_takehome.brands_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.brands_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."brands_json_extract__dbt_backup" cascade
2021-05-20 15:12:25.957677 (Thread-3): Finished running node model.fetch_takehome.fact_items
2021-05-20 15:12:25.958009 (Thread-3): Began running node model.fetch_takehome.receipts_json_extract
2021-05-20 15:12:25.958440 (Thread-3): 11:12:25 | 7 of 8 START table model fetch_takehome.receipts_json_extract........ [RUN]
2021-05-20 15:12:25.958770 (Thread-3): Acquiring new postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:25.958888 (Thread-3): Compiling model.fetch_takehome.receipts_json_extract
2021-05-20 15:12:25.960019 (Thread-3): Writing injected SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 15:12:25.960348 (Thread-3): finished collecting timing info
2021-05-20 15:12:25.963934 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:25.964070 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" cascade
2021-05-20 15:12:25.964164 (Thread-3): Opening a new connection, currently in state closed
2021-05-20 15:12:25.964977 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:25.965112 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:25.968145 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:25.968352 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:25.971702 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:25.971926 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 15:12:25.973567 (Thread-1): finished collecting timing info
2021-05-20 15:12:25.973806 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 15:12:25.974150 (Thread-1): On model.fetch_takehome.brands_json_extract: Close
2021-05-20 15:12:25.974319 (Thread-4): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.974661 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.975185 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11389bd60>]}
2021-05-20 15:12:25.977148 (Thread-4): Writing runtime SQL for node "model.fetch_takehome.fact_users"
2021-05-20 15:12:25.977270 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:25.978798 (Thread-2): Writing runtime SQL for node "model.fetch_takehome.items_json_extract"
2021-05-20 15:12:25.979401 (Thread-1): 11:12:25 | 1 of 8 OK created table model fetch_takehome.brands_json_extract..... [SELECT 1167 in 0.16s]
2021-05-20 15:12:25.981972 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:25.982387 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:25.982617 (Thread-1): Finished running node model.fetch_takehome.brands_json_extract
2021-05-20 15:12:25.982786 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 15:12:25.982951 (Thread-4): On model.fetch_takehome.fact_users: BEGIN
2021-05-20 15:12:25.983097 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:25.983258 (Thread-1): Began running node model.fetch_takehome.users_json_extract
2021-05-20 15:12:25.983677 (Thread-2): On model.fetch_takehome.items_json_extract: BEGIN
2021-05-20 15:12:25.983923 (Thread-1): 11:12:25 | 8 of 8 START table model fetch_takehome.users_json_extract........... [RUN]
2021-05-20 15:12:25.984008 (Thread-4): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.984167 (Thread-3): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:25.984311 (Thread-2): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.984488 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:25.984746 (Thread-1): Acquiring new postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:25.986189 (Thread-3): Writing runtime SQL for node "model.fetch_takehome.receipts_json_extract"
2021-05-20 15:12:25.986332 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:25.986448 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */


  create  table "postgres"."fetch_takehome"."fact_users__dbt_tmp"
  as (
    select
userId as userId,
role as role,
state as state,
active::boolean as active,
to_timestamp(lastLogin::numeric/1000) as lastLogin,
to_timestamp(createdDate::numeric/1000) as createdDate,
signUpSource as signUpSource
from fetch_takehome.users_json_extract
  );
2021-05-20 15:12:25.986585 (Thread-1): Compiling model.fetch_takehome.users_json_extract
2021-05-20 15:12:25.986801 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */


  create  table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp"
  as (
    with a as (

    select
    receiptId,
    userId,
    createDate,
    dateScanned,
    finishedDate,
    modifyDate,
    purchaseDate,
    json_array_elements_text (rewardsreceiptitemlist::json) as items
    from fetch_takehome.receipts_json_extract
)

select
receiptId,
userId,
createDate,
dateScanned,
finishedDate,
modifyDate,
purchaseDate,
json_extract_path_text (to_json(items::json), 'barcode')::varchar as barcode,
json_extract_path_text (to_json(items::json), 'description')::varchar as description,
json_extract_path_text (to_json(items::json), 'finalPrice')::varchar as finalPrice,
json_extract_path_text (to_json(items::json), 'itemPrice')::varchar as itemPrice,
json_extract_path_text (to_json(items::json), 'partnerItemId')::varchar as partnerItemId,
json_extract_path_text (to_json(items::json), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(items::json), 'pointsPayerId')::varchar as pointsPayerId,
json_extract_path_text (to_json(items::json), 'quantityPurchased')::varchar as quantityPurchased,
json_extract_path_text (to_json(items::json), 'rewardsGroup')::varchar as rewardsGroup,
json_extract_path_text (to_json(items::json), 'rewardsProductPartnerId')::varchar as rewardsProductPartnerId,
json_extract_path_text (to_json(items::json), 'targetPrice')::varchar as targetPrice,
json_extract_path_text (to_json(items::json), 'competitiveProduct')::varchar as competitiveProduct,
json_extract_path_text (to_json(items::json), 'needsFetchReview')::varchar as needsFetchReview,
json_extract_path_text (to_json(items::json), 'originalFinalPrice')::varchar as originalFinalPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteBarcode')::varchar as originalMetaBriteBarcode,
json_extract_path_text (to_json(items::json), 'originalMetaBriteDescription')::varchar as originalMetaBriteDescription,
json_extract_path_text (to_json(items::json), 'originalMetaBriteItemPrice')::varchar as originalMetaBriteItemPrice,
json_extract_path_text (to_json(items::json), 'originalMetaBriteQuantityPurchased')::varchar as originalMetaBriteQuantityPurchased,
json_extract_path_text (to_json(items::json), 'preventTargetGapPoints')::varchar as preventTargetGapPoints,
json_extract_path_text (to_json(items::json), 'userFlaggedBarcode')::varchar as userFlaggedBarcode,
json_extract_path_text (to_json(items::json), 'userFlaggedNewItem')::varchar as userFlaggedNewItem,
json_extract_path_text (to_json(items::json), 'userFlaggedPrice')::varchar as userFlaggedPrice,
json_extract_path_text (to_json(items::json), 'userFlaggedQuantity')::varchar as userFlaggedQuantity,
json_extract_path_text (to_json(items::json), 'itemNumber')::varchar as itemNumber,
json_extract_path_text (to_json(items::json), 'priceAfterCoupon')::varchar as priceAfterCoupon,
json_extract_path_text (to_json(items::json), 'needsFetchReviewReason')::varchar as needsFetchReviewReason,
json_extract_path_text (to_json(items::json), 'metabriteCampaignId')::varchar as metabriteCampaignId,
json_extract_path_text (to_json(items::json), 'discountedItemPrice')::varchar as discountedItemPrice,
json_extract_path_text (to_json(items::json), 'competitorRewardsGroup')::varchar as competitorRewardsGroup,
json_extract_path_text (to_json(items::json), 'originalReceiptItemText')::varchar as originalReceiptItemText,
json_extract_path_text (to_json(items::json), 'pointsNotAwardedReason')::varchar as pointsNotAwardedReason
from a
  );
2021-05-20 15:12:25.988909 (Thread-1): Writing injected SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 15:12:25.989210 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:25.989598 (Thread-3): On model.fetch_takehome.receipts_json_extract: BEGIN
2021-05-20 15:12:25.990005 (Thread-3): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:25.990223 (Thread-1): finished collecting timing info
2021-05-20 15:12:25.990361 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:25.993738 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:25.993912 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */


  create  table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as receiptId,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarned')::varchar as bonusPointsEarned,
json_extract_path_text (to_json(json_txt), 'bonusPointsEarnedReason')::varchar as bonusPointsEarnedReason,
json_extract_path_text (to_json(json_txt), 'createDate', '$date')::varchar as createDate,
json_extract_path_text (to_json(json_txt), 'dateScanned', '$date')::varchar as dateScanned,
json_extract_path_text (to_json(json_txt), 'finishedDate', '$date')::varchar as finishedDate,
json_extract_path_text (to_json(json_txt), 'modifyDate', '$date')::varchar as modifyDate,
json_extract_path_text (to_json(json_txt), 'pointsAwardedDate', '$date')::varchar as pointsAwardedDate,
json_extract_path_text (to_json(json_txt), 'pointsEarned')::varchar as pointsEarned,
json_extract_path_text (to_json(json_txt), 'purchaseDate', '$date')::varchar as purchaseDate,
json_extract_path_text (to_json(json_txt), 'purchasedItemCount')::varchar as purchasedItemCount,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptItemList')::varchar as rewardsReceiptItemList,
json_extract_path_text (to_json(json_txt), 'rewardsReceiptStatus')::varchar as rewardsReceiptStatus,
json_extract_path_text (to_json(json_txt), 'totalSpent')::varchar as totalSpent,
json_extract_path_text (to_json(json_txt), 'userId')::varchar as userId
from fetch_takehome.receipts
  );
2021-05-20 15:12:25.994026 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" cascade
2021-05-20 15:12:25.994265 (Thread-1): Opening a new connection, currently in state closed
2021-05-20 15:12:25.996642 (Thread-4): SQL status: SELECT 495 in 0.01 seconds
2021-05-20 15:12:25.999182 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:25.999323 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users" rename to "fact_users__dbt_backup"
2021-05-20 15:12:25.999783 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:26.003068 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:26.003273 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
alter table "postgres"."fetch_takehome"."fact_users__dbt_tmp" rename to "fact_users"
2021-05-20 15:12:26.003704 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:26.003872 (Thread-4): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:26.005803 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:26.006892 (Thread-4): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 15:12:26.007025 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 15:12:26.007167 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:26.007356 (Thread-4): On model.fetch_takehome.fact_users: COMMIT
2021-05-20 15:12:26.007497 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:26.009120 (Thread-1): Writing runtime SQL for node "model.fetch_takehome.users_json_extract"
2021-05-20 15:12:26.009244 (Thread-4): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:26.010684 (Thread-4): Using postgres connection "model.fetch_takehome.fact_users".
2021-05-20 15:12:26.010917 (Thread-4): On model.fetch_takehome.fact_users: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.fact_users"} */
drop table if exists "postgres"."fetch_takehome"."fact_users__dbt_backup" cascade
2021-05-20 15:12:26.011249 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:26.011392 (Thread-1): On model.fetch_takehome.users_json_extract: BEGIN
2021-05-20 15:12:26.011698 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-05-20 15:12:26.011846 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:26.011940 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */


  create  table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp"
  as (
    select
json_extract_path_text (to_json(json_txt), '_id', '$oid')::varchar as userId,
json_extract_path_text (to_json(json_txt), 'role')::varchar as role,
json_extract_path_text (to_json(json_txt), 'state')::varchar as state,
json_extract_path_text (to_json(json_txt), 'active')::varchar as active,
json_extract_path_text (to_json(json_txt), 'lastLogin', '$date')::varchar as lastLogin,
json_extract_path_text (to_json(json_txt), 'createdDate', '$date')::varchar as createdDate,
json_extract_path_text (to_json(json_txt), 'signUpSource')::varchar as signUpSource
from fetch_takehome.users
  );
2021-05-20 15:12:26.016818 (Thread-4): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:26.018424 (Thread-4): finished collecting timing info
2021-05-20 15:12:26.018620 (Thread-4): On model.fetch_takehome.fact_users: Close
2021-05-20 15:12:26.019088 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113887ca0>]}
2021-05-20 15:12:26.019485 (Thread-4): 11:12:26 | 5 of 8 OK created table model fetch_takehome.fact_users.............. [SELECT 495 in 0.08s]
2021-05-20 15:12:26.019654 (Thread-4): Finished running node model.fetch_takehome.fact_users
2021-05-20 15:12:26.030520 (Thread-1): SQL status: SELECT 495 in 0.02 seconds
2021-05-20 15:12:26.033582 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:26.033718 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract" rename to "users_json_extract__dbt_backup"
2021-05-20 15:12:26.034187 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:26.035986 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:26.036086 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
alter table "postgres"."fetch_takehome"."users_json_extract__dbt_tmp" rename to "users_json_extract"
2021-05-20 15:12:26.036571 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:26.038253 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 15:12:26.038374 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:26.038456 (Thread-1): On model.fetch_takehome.users_json_extract: COMMIT
2021-05-20 15:12:26.039034 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:26.040294 (Thread-1): Using postgres connection "model.fetch_takehome.users_json_extract".
2021-05-20 15:12:26.040388 (Thread-1): On model.fetch_takehome.users_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.users_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."users_json_extract__dbt_backup" cascade
2021-05-20 15:12:26.042095 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:26.043200 (Thread-1): finished collecting timing info
2021-05-20 15:12:26.043342 (Thread-1): On model.fetch_takehome.users_json_extract: Close
2021-05-20 15:12:26.043712 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136f1eb0>]}
2021-05-20 15:12:26.043998 (Thread-1): 11:12:26 | 8 of 8 OK created table model fetch_takehome.users_json_extract...... [SELECT 495 in 0.06s]
2021-05-20 15:12:26.044142 (Thread-1): Finished running node model.fetch_takehome.users_json_extract
2021-05-20 15:12:26.741900 (Thread-3): SQL status: SELECT 1119 in 0.75 seconds
2021-05-20 15:12:26.744062 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:26.744170 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract" rename to "receipts_json_extract__dbt_backup"
2021-05-20 15:12:26.979251 (Thread-2): SQL status: SELECT 6941 in 0.99 seconds
2021-05-20 15:12:26.981476 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:26.981606 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract" rename to "items_json_extract__dbt_backup"
2021-05-20 15:12:26.981997 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:26.984126 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:26.984244 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
alter table "postgres"."fetch_takehome"."items_json_extract__dbt_tmp" rename to "items_json_extract"
2021-05-20 15:12:26.984705 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:26.985796 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 15:12:26.985911 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:26.986001 (Thread-2): On model.fetch_takehome.items_json_extract: COMMIT
2021-05-20 15:12:26.986721 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:26.986862 (Thread-3): SQL status: ALTER TABLE in 0.24 seconds
2021-05-20 15:12:26.988449 (Thread-2): Using postgres connection "model.fetch_takehome.items_json_extract".
2021-05-20 15:12:26.990473 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:26.990632 (Thread-2): On model.fetch_takehome.items_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.items_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."items_json_extract__dbt_backup" cascade
2021-05-20 15:12:26.990754 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
alter table "postgres"."fetch_takehome"."receipts_json_extract__dbt_tmp" rename to "receipts_json_extract"
2021-05-20 15:12:26.991416 (Thread-3): SQL status: ALTER TABLE in 0.00 seconds
2021-05-20 15:12:26.994632 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 15:12:26.994891 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-05-20 15:12:26.995072 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:26.996389 (Thread-2): finished collecting timing info
2021-05-20 15:12:26.996571 (Thread-3): On model.fetch_takehome.receipts_json_extract: COMMIT
2021-05-20 15:12:26.996755 (Thread-2): On model.fetch_takehome.items_json_extract: Close
2021-05-20 15:12:26.997394 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11395e3d0>]}
2021-05-20 15:12:26.997573 (Thread-3): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:26.998016 (Thread-2): 11:12:26 | 6 of 8 OK created table model fetch_takehome.items_json_extract...... [SELECT 6941 in 1.06s]
2021-05-20 15:12:26.999834 (Thread-3): Using postgres connection "model.fetch_takehome.receipts_json_extract".
2021-05-20 15:12:27.000158 (Thread-2): Finished running node model.fetch_takehome.items_json_extract
2021-05-20 15:12:27.000325 (Thread-3): On model.fetch_takehome.receipts_json_extract: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "postgres-db-fetch", "target_name": "dev", "node_id": "model.fetch_takehome.receipts_json_extract"} */
drop table if exists "postgres"."fetch_takehome"."receipts_json_extract__dbt_backup" cascade
2021-05-20 15:12:27.006661 (Thread-3): SQL status: DROP TABLE in 0.01 seconds
2021-05-20 15:12:27.008478 (Thread-3): finished collecting timing info
2021-05-20 15:12:27.008759 (Thread-3): On model.fetch_takehome.receipts_json_extract: Close
2021-05-20 15:12:27.009411 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f4e25ef-77c5-4579-b3cf-584457523813', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113980490>]}
2021-05-20 15:12:27.009924 (Thread-3): 11:12:27 | 7 of 8 OK created table model fetch_takehome.receipts_json_extract... [SELECT 1119 in 1.05s]
2021-05-20 15:12:27.010153 (Thread-3): Finished running node model.fetch_takehome.receipts_json_extract
2021-05-20 15:12:27.011825 (MainThread): Acquiring new postgres connection "master".
2021-05-20 15:12:27.012055 (MainThread): Using postgres connection "master".
2021-05-20 15:12:27.012171 (MainThread): On master: BEGIN
2021-05-20 15:12:27.012276 (MainThread): Opening a new connection, currently in state closed
2021-05-20 15:12:27.031694 (MainThread): SQL status: BEGIN in 0.02 seconds
2021-05-20 15:12:27.031998 (MainThread): On master: COMMIT
2021-05-20 15:12:27.032146 (MainThread): Using postgres connection "master".
2021-05-20 15:12:27.032297 (MainThread): On master: COMMIT
2021-05-20 15:12:27.032597 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-05-20 15:12:27.032792 (MainThread): On master: Close
2021-05-20 15:12:27.033406 (MainThread): 11:12:27 | 
2021-05-20 15:12:27.033659 (MainThread): 11:12:27 | Finished running 8 table models in 1.34s.
2021-05-20 15:12:27.033857 (MainThread): Connection 'master' was properly closed.
2021-05-20 15:12:27.034006 (MainThread): Connection 'model.fetch_takehome.users_json_extract' was properly closed.
2021-05-20 15:12:27.034143 (MainThread): Connection 'model.fetch_takehome.items_json_extract' was properly closed.
2021-05-20 15:12:27.034282 (MainThread): Connection 'model.fetch_takehome.receipts_json_extract' was properly closed.
2021-05-20 15:12:27.034421 (MainThread): Connection 'model.fetch_takehome.fact_users' was properly closed.
2021-05-20 15:12:27.041776 (MainThread): 
2021-05-20 15:12:27.042052 (MainThread): Completed successfully
2021-05-20 15:12:27.042294 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2021-05-20 15:12:27.042583 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136524f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11397f6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113947eb0>]}
2021-05-20 15:12:27.042933 (MainThread): Flushing usage events
